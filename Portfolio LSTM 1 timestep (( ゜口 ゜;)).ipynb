{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'quandl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-69bd411a50e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mquandl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mquandl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApiConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'YOUR_API_KEY_REPLACE_THIS'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'quandl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import quandl\n",
    "from matplotlib import pyplot \n",
    "quandl.ApiConfig.api_key = 'YOUR_API_KEY_REPLACE_THIS'\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's construct an imaginary tech portfolio split evenly between Apple, Amazon, Microsoft, Facebook, Google and Netflix. We will grab data from the beginning of 2015 to min(now, end_of_2018). That will give us 3-4 years worth of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quandl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-793d815860b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtckr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticker_symbols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     closing_prices = pd.concat([closing_prices, \n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mquandl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WIKI/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtckr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2014-12-31\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2018-12-31\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollapse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"daily\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         .rename(tckr)], axis=1)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'quandl' is not defined"
     ]
    }
   ],
   "source": [
    "ticker_symbols = [\"AAPL\",\"AMZN\",\"MSFT\",\"FB\",\"GOOGL\",\"NFLX\"]\n",
    "closing_prices = pd.DataFrame()\n",
    "\n",
    "for tckr in ticker_symbols:\n",
    "    closing_prices = pd.concat([closing_prices, \n",
    "        quandl.get(\"WIKI/\" + tckr, start_date=\"2014-12-31\", end_date=\"2018-12-31\", collapse=\"daily\")['Close']\n",
    "        .rename(tckr)], axis=1)\n",
    "    \n",
    "    #Might as well calculate price as we go\n",
    "    if 'portfolio' in closing_prices:\n",
    "        closing_prices['portfolio'] += closing_prices[tckr] * 1 / len(ticker_symbols)\n",
    "    else:\n",
    "        closing_prices['portfolio'] = closing_prices[tckr] * 1 / len(ticker_symbols)\n",
    "        \n",
    "closing_prices = closing_prices[ticker_symbols + ['portfolio']] #reorder columns\n",
    "closing_prices.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL         1\n",
       "AMZN         1\n",
       "MSFT         0\n",
       "FB           0\n",
       "GOOGL        0\n",
       "NFLX         0\n",
       "portfolio    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closing_prices.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not bad. Unfortunately, the missing value appears to take place on a Monday, so we will impute with the midpoint between the  preceding Friday and the following Tuesday (open to suggestions on a more elegant way to code this...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL         0\n",
       "AMZN         0\n",
       "MSFT         0\n",
       "FB           0\n",
       "GOOGL        0\n",
       "NFLX         0\n",
       "portfolio    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in ['AAPL','AMZN','portfolio']:\n",
    "    missing_date = closing_prices.index[closing_prices[key].isnull()]\n",
    "    closing_prices[key][missing_date] = \\\n",
    "    (closing_prices[key][missing_date + timedelta(days=1)][0] + \\\n",
    "    closing_prices[key][missing_date - timedelta(days=3)][0]) / 2\n",
    "\n",
    "closing_prices.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's split off the last ~1 year as test data. Assume a year has 52 * 5 trading days. The rest will be training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((795, 7), (535, 7), (260, 7))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = closing_prices[:-260], closing_prices[-260:]\n",
    "closing_prices.shape, train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/Library/Python/3.6/lib/python/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((534, 8), (259, 8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make moving window prediction\n",
    "def create_pred_col(df, shift = -1):\n",
    "    df['preds'] = df['portfolio'].shift(shift)\n",
    "    df = df[:-1]\n",
    "    return df\n",
    "    \n",
    "train = create_pred_col(train)\n",
    "test = create_pred_col(test)\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"f672e498-3bdc-4a68-a06b-a9ec77aedab5\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"f672e498-3bdc-4a68-a06b-a9ec77aedab5\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"f672e498-3bdc-4a68-a06b-a9ec77aedab5\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'f672e498-3bdc-4a68-a06b-a9ec77aedab5' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"f672e498-3bdc-4a68-a06b-a9ec77aedab5\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"f672e498-3bdc-4a68-a06b-a9ec77aedab5\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"f672e498-3bdc-4a68-a06b-a9ec77aedab5\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'f672e498-3bdc-4a68-a06b-a9ec77aedab5' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.14.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.14.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.14.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"f672e498-3bdc-4a68-a06b-a9ec77aedab5\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/bokeh/models/sources.py:138: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 50), ('y', 534)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/usr/local/lib/python3.6/site-packages/bokeh/models/sources.py:138: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 50), ('y', 534)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"7c5c8635-e03f-42e8-a513-1926e86a4464\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"b74aea84-bca7-4bad-9e24-7f1b41b90fdd\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"e4ef1675-f43e-4ff6-a90a-0e1b04eaf735\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"80ce39b5-b475-4b44-aa39-e5ef34dcf6c3\",\"type\":\"LinearAxis\"}],\"plot_height\":250,\"plot_width\":500,\"renderers\":[{\"id\":\"e4ef1675-f43e-4ff6-a90a-0e1b04eaf735\",\"type\":\"LinearAxis\"},{\"id\":\"604a8c18-8598-467a-8e2b-da386763716e\",\"type\":\"Grid\"},{\"id\":\"80ce39b5-b475-4b44-aa39-e5ef34dcf6c3\",\"type\":\"LinearAxis\"},{\"id\":\"be139698-3faa-4758-9bc6-41e861ebda1e\",\"type\":\"Grid\"},{\"id\":\"7a2fdb38-84a9-4701-a2cb-a7e9079e4013\",\"type\":\"BoxAnnotation\"},{\"id\":\"3cf3af83-d9fe-4e7f-8380-63200f20a3b9\",\"type\":\"GlyphRenderer\"},{\"id\":\"89999574-3d6a-45d3-ad30-ed720cfdd97b\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"4bfd61bb-4b31-4fbb-b731-69f20946f247\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"b46159b6-447e-450d-a26a-2359e6f3c7d9\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"4def64ee-89a9-4450-b1ae-de5946266d72\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"3e65b980-7ba3-434c-b2d8-26327c4818ea\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"84df0feb-e69b-4ee0-af54-5cfe652ad7db\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"6defbecf-14da-47b7-bb89-f77139e627f8\",\"type\":\"LinearScale\"}},\"id\":\"9ba2c599-293e-47b4-a9da-fd65ca0b19b4\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"ca37603b-2d93-498b-b172-99fd45497da6\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"7066e859-c6a1-4dc2-b196-8ee0fa16b5a6\",\"type\":\"PanTool\"},{\"id\":\"6510f9a1-e791-4ae0-b04d-b3236eda4f43\",\"type\":\"WheelZoomTool\"},{\"id\":\"fcf15d2a-e174-4496-a736-f0c65ed038c2\",\"type\":\"BoxZoomTool\"},{\"id\":\"f8af6864-29bd-4ef9-9ee2-91c65d8fd1b4\",\"type\":\"SaveTool\"},{\"id\":\"2bc08f03-c409-4e2a-aa79-123a0027f17c\",\"type\":\"ResetTool\"},{\"id\":\"fcc65726-b4f2-4a9d-9126-d2140e262782\",\"type\":\"HelpTool\"}]},\"id\":\"b46159b6-447e-450d-a26a-2359e6f3c7d9\",\"type\":\"Toolbar\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"ee5e5b6d-983e-4131-ba03-536142f4fa40\",\"type\":\"Line\"},{\"attributes\":{\"callback\":null},\"id\":\"4def64ee-89a9-4450-b1ae-de5946266d72\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null},\"id\":\"84df0feb-e69b-4ee0-af54-5cfe652ad7db\",\"type\":\"DataRange1d\"},{\"attributes\":{\"formatter\":{\"id\":\"c1261aea-99d3-4153-b453-ad7c531fef41\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"9ba2c599-293e-47b4-a9da-fd65ca0b19b4\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b741e07a-02af-4801-99f5-bf114811a0fb\",\"type\":\"BasicTicker\"}},\"id\":\"e4ef1675-f43e-4ff6-a90a-0e1b04eaf735\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"b741e07a-02af-4801-99f5-bf114811a0fb\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"9ba2c599-293e-47b4-a9da-fd65ca0b19b4\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b741e07a-02af-4801-99f5-bf114811a0fb\",\"type\":\"BasicTicker\"}},\"id\":\"604a8c18-8598-467a-8e2b-da386763716e\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"bfd2051e-cb9a-435c-80d1-f80a3f765280\",\"type\":\"BasicTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"ca37603b-2d93-498b-b172-99fd45497da6\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"9ba2c599-293e-47b4-a9da-fd65ca0b19b4\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"bfd2051e-cb9a-435c-80d1-f80a3f765280\",\"type\":\"BasicTicker\"}},\"id\":\"80ce39b5-b475-4b44-aa39-e5ef34dcf6c3\",\"type\":\"LinearAxis\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"9ba2c599-293e-47b4-a9da-fd65ca0b19b4\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"bfd2051e-cb9a-435c-80d1-f80a3f765280\",\"type\":\"BasicTicker\"}},\"id\":\"be139698-3faa-4758-9bc6-41e861ebda1e\",\"type\":\"Grid\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"7a2fdb38-84a9-4701-a2cb-a7e9079e4013\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"source\":{\"id\":\"aba77c2f-97c7-46ad-bd2d-83e40a83c195\",\"type\":\"ColumnDataSource\"}},\"id\":\"95641787-e68c-41ca-99bd-2a084619582b\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":{\"__ndarray__\":\"AAAAAAAA8D/wcgpeTsEnQPByCl5OwTZANNaHxvrQQEDwcgpeTkFGQKwPjfWhsUtANNaHxvqQUECSJEmSJElTQPByCl5OAVZATsHLKXi5WECsD431oXFbQApeTsHLKV5ANNaHxvpwYEBjfWisD81hQJIkSZIkKWNAwcspeDmFZEDwcgpeTuFlQB8a60NjPWdATsHLKXiZaEB9aKwPjfVpQKwPjfWhUWtA27Zt27atbEAKXk7BywluQDkFL6fgZW9ANNaHxvpgcEDMKXg5BQ9xQGN9aKwPvXFA+tBYHxprckCSJEmSJBlzQCp4OQUvx3NAwcspeDl1dEBYHxrrQyN1QPByCl5O0XVAiMb60Fh/dkAfGutDYy13QLZt27Zt23dATsHLKXiJeEDmFLycgjd5QH1orA+N5XlAFLycgpeTekCsD431oUF7QERjfWis73tA27Zt27adfEByCl5OwUt9QApeTsHL+X1AorE+NNanfkA5BS+n4FV/QGisD431AYBANNaHxvpYgEAAAAAAALCAQA==\",\"dtype\":\"float64\",\"shape\":[50]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[534]}}},\"id\":\"aba77c2f-97c7-46ad-bd2d-83e40a83c195\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"7066e859-c6a1-4dc2-b196-8ee0fa16b5a6\",\"type\":\"PanTool\"},{\"attributes\":{\"data_source\":{\"id\":\"aba77c2f-97c7-46ad-bd2d-83e40a83c195\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"36061b60-870b-4dee-ac2b-e66764891b0b\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"7da81f58-fa42-449c-802c-cf7bc154455b\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"95641787-e68c-41ca-99bd-2a084619582b\",\"type\":\"CDSView\"}},\"id\":\"3cf3af83-d9fe-4e7f-8380-63200f20a3b9\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"6510f9a1-e791-4ae0-b04d-b3236eda4f43\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"overlay\":{\"id\":\"7a2fdb38-84a9-4701-a2cb-a7e9079e4013\",\"type\":\"BoxAnnotation\"}},\"id\":\"fcf15d2a-e174-4496-a736-f0c65ed038c2\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"f8af6864-29bd-4ef9-9ee2-91c65d8fd1b4\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"2bc08f03-c409-4e2a-aa79-123a0027f17c\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"fcc65726-b4f2-4a9d-9126-d2140e262782\",\"type\":\"HelpTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":{\"__ndarray__\":\"AAAAAAAA8D/wcgpeTsEnQPByCl5OwTZANNaHxvrQQEDwcgpeTkFGQKwPjfWhsUtANNaHxvqQUECSJEmSJElTQPByCl5OAVZATsHLKXi5WECsD431oXFbQApeTsHLKV5ANNaHxvpwYEBjfWisD81hQJIkSZIkKWNAwcspeDmFZEDwcgpeTuFlQB8a60NjPWdATsHLKXiZaEB9aKwPjfVpQKwPjfWhUWtA27Zt27atbEAKXk7BywluQDkFL6fgZW9ANNaHxvpgcEDMKXg5BQ9xQGN9aKwPvXFA+tBYHxprckCSJEmSJBlzQCp4OQUvx3NAwcspeDl1dEBYHxrrQyN1QPByCl5O0XVAiMb60Fh/dkAfGutDYy13QLZt27Zt23dATsHLKXiJeEDmFLycgjd5QH1orA+N5XlAFLycgpeTekCsD431oUF7QERjfWis73tA27Zt27adfEByCl5OwUt9QApeTsHL+X1AorE+NNanfkA5BS+n4FV/QGisD431AYBANNaHxvpYgEAAAAAAALCAQA==\",\"dtype\":\"float64\",\"shape\":[50]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[534]}}},\"id\":\"8fd6ddba-a5b8-493a-9aba-f8cc0f874399\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"7da81f58-fa42-449c-802c-cf7bc154455b\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"c1261aea-99d3-4153-b453-ad7c531fef41\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"line_color\":\"red\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1b4bbc65-57d4-48fe-9d18-dbca0ba91077\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"3e65b980-7ba3-434c-b2d8-26327c4818ea\",\"type\":\"LinearScale\"},{\"attributes\":{\"source\":{\"id\":\"8fd6ddba-a5b8-493a-9aba-f8cc0f874399\",\"type\":\"ColumnDataSource\"}},\"id\":\"d1112f05-cda6-47b5-b08f-610a2b838814\",\"type\":\"CDSView\"},{\"attributes\":{\"line_color\":\"blue\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"36061b60-870b-4dee-ac2b-e66764891b0b\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"6defbecf-14da-47b7-bb89-f77139e627f8\",\"type\":\"LinearScale\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"4bfd61bb-4b31-4fbb-b731-69f20946f247\",\"type\":\"Title\"},{\"attributes\":{\"data_source\":{\"id\":\"8fd6ddba-a5b8-493a-9aba-f8cc0f874399\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1b4bbc65-57d4-48fe-9d18-dbca0ba91077\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"ee5e5b6d-983e-4131-ba03-536142f4fa40\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"d1112f05-cda6-47b5-b08f-610a2b838814\",\"type\":\"CDSView\"}},\"id\":\"89999574-3d6a-45d3-ad30-ed720cfdd97b\",\"type\":\"GlyphRenderer\"}],\"root_ids\":[\"9ba2c599-293e-47b4-a9da-fd65ca0b19b4\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.14\"}};\n",
       "  var render_items = [{\"docid\":\"b74aea84-bca7-4bad-9e24-7f1b41b90fdd\",\"elementid\":\"7c5c8635-e03f-42e8-a513-1926e86a4464\",\"modelid\":\"9ba2c599-293e-47b4-a9da-fd65ca0b19b4\"}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "9ba2c599-293e-47b4-a9da-fd65ca0b19b4"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = figure(plot_width=500, plot_height=250)\n",
    "x = np.linspace(1,train.shape[0])\n",
    "p.line(x, train['portfolio'].values, color='blue')\n",
    "p.line(x, train['preds'].values, color='red')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape train/test set for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['portfolio'], axis=1)\n",
    "test = test.drop(['portfolio'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train.loc[:,train.columns != 'preds'], train['preds']\n",
    "train_x = train_x.values.reshape(train_x.shape[0],1,train_x.shape[1])\n",
    "train_y = train_y.values.reshape(train_y.shape[0],1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = test.loc[:,test.columns != 'preds'], test['preds']\n",
    "test_x = test_x.values.reshape(test_x.shape[0],1,test_x.shape[1])\n",
    "test_y = test_y.values.reshape(test_y.shape[0],1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((534, 1, 6), (534, 1, 1), (259, 1, 6), (259, 1, 1))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.reset_states() #Resets state in case you are running more than one different model with the same name in this notebook; feel free to comment out this line\n",
    "\n",
    "model.add(LSTM(20, input_shape = (train_x.shape[1],train_x.shape[2]), return_sequences = True))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam') #mse numbers are far too big here, and there doesn't seem to be much performance loss from using mae instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534 samples, validate on 259 samples\n",
      "Epoch 1/2000\n",
      "534/534 [==============================] - 2s 3ms/step - loss: 88902.7161 - val_loss: 191536.2791\n",
      "Epoch 2/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 88858.3210 - val_loss: 191466.7762\n",
      "Epoch 3/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 88814.3217 - val_loss: 191397.6868\n",
      "Epoch 4/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 88770.5566 - val_loss: 191328.9336\n",
      "Epoch 5/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 88727.0169 - val_loss: 191260.4772\n",
      "Epoch 6/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 88683.6205 - val_loss: 191192.1958\n",
      "Epoch 7/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 88640.2949 - val_loss: 191123.9975\n",
      "Epoch 8/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 88597.0215 - val_loss: 191055.9082\n",
      "Epoch 9/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 88553.8077 - val_loss: 190987.8756\n",
      "Epoch 10/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 88510.6437 - val_loss: 190919.9029\n",
      "Epoch 11/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 88467.4909 - val_loss: 190851.9698\n",
      "Epoch 12/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 88424.3783 - val_loss: 190784.0923\n",
      "Epoch 13/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 88381.3013 - val_loss: 190716.2523\n",
      "Epoch 14/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 88338.2551 - val_loss: 190648.4878\n",
      "Epoch 15/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 88295.2429 - val_loss: 190580.7488\n",
      "Epoch 16/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 88252.2465 - val_loss: 190513.0159\n",
      "Epoch 17/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 88209.2668 - val_loss: 190445.3159\n",
      "Epoch 18/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 88166.3200 - val_loss: 190377.6834\n",
      "Epoch 19/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 88123.3923 - val_loss: 190310.0385\n",
      "Epoch 20/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 88080.4811 - val_loss: 190242.4461\n",
      "Epoch 21/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 88037.5951 - val_loss: 190174.8795\n",
      "Epoch 22/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 87994.7369 - val_loss: 190107.3495\n",
      "Epoch 23/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 87951.8900 - val_loss: 190039.8389\n",
      "Epoch 24/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 87909.0563 - val_loss: 189972.3445\n",
      "Epoch 25/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 87866.2454 - val_loss: 189904.8871\n",
      "Epoch 26/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 87823.4580 - val_loss: 189837.4555\n",
      "Epoch 27/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 87780.6888 - val_loss: 189770.0312\n",
      "Epoch 28/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 87737.9374 - val_loss: 189702.6560\n",
      "Epoch 29/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 87695.2048 - val_loss: 189635.2962\n",
      "Epoch 30/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 87652.4925 - val_loss: 189567.9391\n",
      "Epoch 31/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 87609.7841 - val_loss: 189500.6140\n",
      "Epoch 32/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 87567.0999 - val_loss: 189433.3171\n",
      "Epoch 33/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 87524.4320 - val_loss: 189366.0541\n",
      "Epoch 34/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 87481.7842 - val_loss: 189298.7957\n",
      "Epoch 35/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 87439.1569 - val_loss: 189231.5594\n",
      "Epoch 36/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 87396.5374 - val_loss: 189164.3565\n",
      "Epoch 37/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 87353.9366 - val_loss: 189097.1649\n",
      "Epoch 38/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 87311.3615 - val_loss: 189030.0049\n",
      "Epoch 39/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 87268.7951 - val_loss: 188962.8727\n",
      "Epoch 40/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 87226.2447 - val_loss: 188895.7378\n",
      "Epoch 41/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 87183.7130 - val_loss: 188828.6558\n",
      "Epoch 42/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 87141.1986 - val_loss: 188761.5725\n",
      "Epoch 43/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 87098.6993 - val_loss: 188694.5136\n",
      "Epoch 44/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 87056.2112 - val_loss: 188627.4659\n",
      "Epoch 45/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 87013.7424 - val_loss: 188560.4389\n",
      "Epoch 46/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 86971.2864 - val_loss: 188493.4462\n",
      "Epoch 47/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 86928.8421 - val_loss: 188426.4531\n",
      "Epoch 48/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 86886.4236 - val_loss: 188359.5025\n",
      "Epoch 49/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 86844.0138 - val_loss: 188292.5574\n",
      "Epoch 50/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 86801.6223 - val_loss: 188225.6513\n",
      "Epoch 51/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 86759.2494 - val_loss: 188158.7501\n",
      "Epoch 52/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 86716.8852 - val_loss: 188091.8646\n",
      "Epoch 53/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 86674.5393 - val_loss: 188024.9986\n",
      "Epoch 54/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 86632.2040 - val_loss: 187958.1661\n",
      "Epoch 55/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 86589.8932 - val_loss: 187891.3281\n",
      "Epoch 56/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 86547.5897 - val_loss: 187824.5280\n",
      "Epoch 57/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 86505.3025 - val_loss: 187757.7578\n",
      "Epoch 58/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 86463.0287 - val_loss: 187690.9849\n",
      "Epoch 59/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 86420.7718 - val_loss: 187624.2373\n",
      "Epoch 60/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 86378.5289 - val_loss: 187557.5071\n",
      "Epoch 61/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 86336.3022 - val_loss: 187490.7921\n",
      "Epoch 62/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 86294.0890 - val_loss: 187424.1145\n",
      "Epoch 63/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 86251.8902 - val_loss: 187357.4311\n",
      "Epoch 64/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 86209.7040 - val_loss: 187290.7767\n",
      "Epoch 65/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 86167.5360 - val_loss: 187224.1348\n",
      "Epoch 66/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 86125.3798 - val_loss: 187157.5251\n",
      "Epoch 67/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 86083.2409 - val_loss: 187090.9270\n",
      "Epoch 68/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 86041.1171 - val_loss: 187024.3538\n",
      "Epoch 69/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 85999.0026 - val_loss: 186957.7786\n",
      "Epoch 70/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 85956.9073 - val_loss: 186891.2279\n",
      "Epoch 71/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 85914.8255 - val_loss: 186824.7124\n",
      "Epoch 72/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 85872.7560 - val_loss: 186758.2016\n",
      "Epoch 73/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 85830.7019 - val_loss: 186691.7144\n",
      "Epoch 74/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 85788.6583 - val_loss: 186625.2288\n",
      "Epoch 75/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 85746.6304 - val_loss: 186558.7574\n",
      "Epoch 76/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 85704.6190 - val_loss: 186492.3326\n",
      "Epoch 77/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 85662.6249 - val_loss: 186425.9079\n",
      "Epoch 78/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 85620.6401 - val_loss: 186359.4971\n",
      "Epoch 79/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 85578.6670 - val_loss: 186293.1172\n",
      "Epoch 80/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 85536.7083 - val_loss: 186226.7482\n",
      "Epoch 81/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 85494.7679 - val_loss: 186160.4021\n",
      "Epoch 82/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 85452.8371 - val_loss: 186094.0708\n",
      "Epoch 83/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 85410.9228 - val_loss: 186027.7489\n",
      "Epoch 84/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 85369.0200 - val_loss: 185961.4373\n",
      "Epoch 85/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 85327.1349 - val_loss: 185895.1678\n",
      "Epoch 86/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 85285.2599 - val_loss: 185828.8827\n",
      "Epoch 87/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 85243.4011 - val_loss: 185762.6365\n",
      "Epoch 88/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 85201.5518 - val_loss: 185696.4116\n",
      "Epoch 89/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 85159.7211 - val_loss: 185630.1994\n",
      "Epoch 90/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 85117.9011 - val_loss: 185563.9890\n",
      "Epoch 91/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 85076.0966 - val_loss: 185497.8179\n",
      "Epoch 92/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 85034.3063 - val_loss: 185431.6529\n",
      "Epoch 93/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 84992.5268 - val_loss: 185365.5156\n",
      "Epoch 94/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 84950.7614 - val_loss: 185299.3705\n",
      "Epoch 95/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 84909.0104 - val_loss: 185233.2728\n",
      "Epoch 96/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 84867.2724 - val_loss: 185167.1597\n",
      "Epoch 97/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 84825.5504 - val_loss: 185101.0811\n",
      "Epoch 98/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 84783.8387 - val_loss: 185035.0201\n",
      "Epoch 99/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 84742.1411 - val_loss: 184968.9695\n",
      "Epoch 100/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 84700.4543 - val_loss: 184902.9595\n",
      "Epoch 101/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 84658.7819 - val_loss: 184836.9301\n",
      "Epoch 102/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 84617.1266 - val_loss: 184770.9348\n",
      "Epoch 103/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 84575.4837 - val_loss: 184704.9542\n",
      "Epoch 104/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 84533.8508 - val_loss: 184638.9885\n",
      "Epoch 105/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 84492.2342 - val_loss: 184573.0391\n",
      "Epoch 106/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 84450.6240 - val_loss: 184507.1039\n",
      "Epoch 107/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 84409.0388 - val_loss: 184441.2008\n",
      "Epoch 108/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 84367.4573 - val_loss: 184375.2774\n",
      "Epoch 109/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 84325.8932 - val_loss: 184309.4008\n",
      "Epoch 110/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 84284.3412 - val_loss: 184243.5309\n",
      "Epoch 111/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 84242.7994 - val_loss: 184177.6746\n",
      "Epoch 112/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 84201.2749 - val_loss: 184111.8562\n",
      "Epoch 113/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 84159.7597 - val_loss: 184046.0279\n",
      "Epoch 114/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 84118.2591 - val_loss: 183980.2321\n",
      "Epoch 115/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 84076.7745 - val_loss: 183914.4274\n",
      "Epoch 116/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 84035.2973 - val_loss: 183848.6635\n",
      "Epoch 117/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 83993.8347 - val_loss: 183782.8977\n",
      "Epoch 118/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 83952.3849 - val_loss: 183717.1593\n",
      "Epoch 119/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 83910.9503 - val_loss: 183651.4402\n",
      "Epoch 120/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 83869.5257 - val_loss: 183585.7168\n",
      "Epoch 121/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 83828.1167 - val_loss: 183520.0309\n",
      "Epoch 122/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 83786.7170 - val_loss: 183454.3634\n",
      "Epoch 123/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 83745.3296 - val_loss: 183388.6852\n",
      "Epoch 124/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 83703.9609 - val_loss: 183323.0438\n",
      "Epoch 125/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 83662.6011 - val_loss: 183257.4142\n",
      "Epoch 126/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 83621.2555 - val_loss: 183191.7890\n",
      "Epoch 127/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 83579.9185 - val_loss: 183126.2093\n",
      "Epoch 128/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 83538.5999 - val_loss: 183060.6073\n",
      "Epoch 129/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 83497.2906 - val_loss: 182995.0402\n",
      "Epoch 130/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 83455.9937 - val_loss: 182929.4902\n",
      "Epoch 131/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 83414.7110 - val_loss: 182863.9503\n",
      "Epoch 132/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 83373.4403 - val_loss: 182798.4248\n",
      "Epoch 133/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 83332.1815 - val_loss: 182732.9117\n",
      "Epoch 134/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 83290.9365 - val_loss: 182667.4233\n",
      "Epoch 135/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 83249.7034 - val_loss: 182601.9391\n",
      "Epoch 136/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 83208.4837 - val_loss: 182536.4835\n",
      "Epoch 137/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 83167.2741 - val_loss: 182471.0328\n",
      "Epoch 138/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 83126.0787 - val_loss: 182405.5872\n",
      "Epoch 139/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 83084.8975 - val_loss: 182340.1678\n",
      "Epoch 140/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 83043.7219 - val_loss: 182274.7732\n",
      "Epoch 141/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 83002.5633 - val_loss: 182209.3972\n",
      "Epoch 142/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 82961.4189 - val_loss: 182144.0148\n",
      "Epoch 143/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 82920.2832 - val_loss: 182078.6665\n",
      "Epoch 144/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 82879.1654 - val_loss: 182013.3135\n",
      "Epoch 145/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 82838.0542 - val_loss: 181947.9917\n",
      "Epoch 146/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 82796.9542 - val_loss: 181882.6801\n",
      "Epoch 147/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 82755.8697 - val_loss: 181817.3854\n",
      "Epoch 148/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 82714.7994 - val_loss: 181752.1012\n",
      "Epoch 149/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 82673.7358 - val_loss: 181686.8242\n",
      "Epoch 150/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 82632.6893 - val_loss: 181621.5674\n",
      "Epoch 151/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 82591.6553 - val_loss: 181556.3425\n",
      "Epoch 152/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 82550.6291 - val_loss: 181491.1133\n",
      "Epoch 153/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 82509.6160 - val_loss: 181425.9019\n",
      "Epoch 154/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 82468.6189 - val_loss: 181360.6970\n",
      "Epoch 155/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 82427.6296 - val_loss: 181295.5180\n",
      "Epoch 156/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 82386.6529 - val_loss: 181230.3479\n",
      "Epoch 157/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 82345.6918 - val_loss: 181165.2043\n",
      "Epoch 158/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 82304.7443 - val_loss: 181100.0638\n",
      "Epoch 159/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 82263.8043 - val_loss: 181034.9610\n",
      "Epoch 160/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 82222.8773 - val_loss: 180969.8393\n",
      "Epoch 161/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 82181.9615 - val_loss: 180904.7356\n",
      "Epoch 162/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 82141.0610 - val_loss: 180839.6712\n",
      "Epoch 163/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 82100.1692 - val_loss: 180774.6100\n",
      "Epoch 164/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 82059.2915 - val_loss: 180709.5541\n",
      "Epoch 165/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 82018.4241 - val_loss: 180644.5122\n",
      "Epoch 166/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 81977.5717 - val_loss: 180579.4912\n",
      "Epoch 167/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 81936.7260 - val_loss: 180514.4848\n",
      "Epoch 168/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 81895.8927 - val_loss: 180449.4926\n",
      "Epoch 169/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 81855.0770 - val_loss: 180384.5059\n",
      "Epoch 170/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 81814.2668 - val_loss: 180319.5597\n",
      "Epoch 171/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 81773.4734 - val_loss: 180254.6087\n",
      "Epoch 172/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 81732.6914 - val_loss: 180189.6480\n",
      "Epoch 173/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 81691.9175 - val_loss: 180124.7441\n",
      "Epoch 174/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 81651.1570 - val_loss: 180059.8505\n",
      "Epoch 175/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 81610.4134 - val_loss: 179994.9317\n",
      "Epoch 176/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 81569.6761 - val_loss: 179930.0632\n",
      "Epoch 177/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 81528.9488 - val_loss: 179865.1973\n",
      "Epoch 178/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 81488.2365 - val_loss: 179800.3465\n",
      "Epoch 179/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 81447.5371 - val_loss: 179735.5105\n",
      "Epoch 180/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 81406.8501 - val_loss: 179670.6987\n",
      "Epoch 181/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 81366.1721 - val_loss: 179605.8862\n",
      "Epoch 182/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 81325.5066 - val_loss: 179541.0860\n",
      "Epoch 183/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 81284.8538 - val_loss: 179476.3088\n",
      "Epoch 184/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 81244.2097 - val_loss: 179411.5420\n",
      "Epoch 185/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 81203.5814 - val_loss: 179346.7827\n",
      "Epoch 186/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 81162.9587 - val_loss: 179282.0411\n",
      "Epoch 187/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 81122.3548 - val_loss: 179217.3308\n",
      "Epoch 188/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 81081.7603 - val_loss: 179152.6186\n",
      "Epoch 189/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 81041.1801 - val_loss: 179087.9218\n",
      "Epoch 190/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 81000.6073 - val_loss: 179023.2379\n",
      "Epoch 191/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 80960.0491 - val_loss: 178958.5614\n",
      "Epoch 192/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 80919.4966 - val_loss: 178893.9136\n",
      "Epoch 193/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 80878.9593 - val_loss: 178829.2619\n",
      "Epoch 194/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 80838.4340 - val_loss: 178764.6296\n",
      "Epoch 195/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 80797.9204 - val_loss: 178700.0281\n",
      "Epoch 196/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 80757.4192 - val_loss: 178635.4210\n",
      "Epoch 197/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 80716.9299 - val_loss: 178570.8459\n",
      "Epoch 198/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 80676.4489 - val_loss: 178506.2529\n",
      "Epoch 199/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 80635.9817 - val_loss: 178441.7108\n",
      "Epoch 200/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 80595.5269 - val_loss: 178377.1683\n",
      "Epoch 201/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 80555.0818 - val_loss: 178312.6409\n",
      "Epoch 202/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 80514.6499 - val_loss: 178248.1015\n",
      "Epoch 203/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 80474.2287 - val_loss: 178183.5938\n",
      "Epoch 204/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 80433.8161 - val_loss: 178119.1097\n",
      "Epoch 205/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 80393.4178 - val_loss: 178054.6313\n",
      "Epoch 206/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 80353.0309 - val_loss: 177990.1632\n",
      "Epoch 207/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 80312.6555 - val_loss: 177925.7229\n",
      "Epoch 208/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 80272.2875 - val_loss: 177861.2858\n",
      "Epoch 209/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 80231.9367 - val_loss: 177796.8549\n",
      "Epoch 210/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 80191.5972 - val_loss: 177732.4531\n",
      "Epoch 211/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 80151.2646 - val_loss: 177668.0444\n",
      "Epoch 212/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 80110.9505 - val_loss: 177603.6782\n",
      "Epoch 213/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 80070.6385 - val_loss: 177539.2968\n",
      "Epoch 214/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 80030.3447 - val_loss: 177474.9444\n",
      "Epoch 215/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 79990.0597 - val_loss: 177410.5979\n",
      "Epoch 216/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 79949.7868 - val_loss: 177346.2683\n",
      "Epoch 217/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 79909.5214 - val_loss: 177281.9546\n",
      "Epoch 218/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 79869.2736 - val_loss: 177217.6525\n",
      "Epoch 219/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 79829.0341 - val_loss: 177153.3623\n",
      "Epoch 220/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 79788.8085 - val_loss: 177089.0853\n",
      "Epoch 221/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 79748.5904 - val_loss: 177024.8258\n",
      "Epoch 222/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 79708.3854 - val_loss: 176960.5684\n",
      "Epoch 223/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 79668.1909 - val_loss: 176896.3282\n",
      "Epoch 224/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 79628.0095 - val_loss: 176832.1262\n",
      "Epoch 225/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 79587.8400 - val_loss: 176767.9082\n",
      "Epoch 226/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 79547.6777 - val_loss: 176703.7096\n",
      "Epoch 227/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 79507.5289 - val_loss: 176639.5354\n",
      "Epoch 228/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 79467.3916 - val_loss: 176575.3592\n",
      "Epoch 229/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 79427.2662 - val_loss: 176511.2085\n",
      "Epoch 230/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 79387.1501 - val_loss: 176447.0585\n",
      "Epoch 231/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 79347.0454 - val_loss: 176382.9397\n",
      "Epoch 232/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 79306.9529 - val_loss: 176318.7996\n",
      "Epoch 233/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 79266.8723 - val_loss: 176254.7050\n",
      "Epoch 234/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 79226.8009 - val_loss: 176190.6181\n",
      "Epoch 235/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 79186.7406 - val_loss: 176126.5421\n",
      "Epoch 236/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 79146.6919 - val_loss: 176062.4840\n",
      "Epoch 237/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 79106.6557 - val_loss: 175998.4305\n",
      "Epoch 238/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 79066.6317 - val_loss: 175934.3984\n",
      "Epoch 239/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 79026.6160 - val_loss: 175870.3717\n",
      "Epoch 240/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 78986.6139 - val_loss: 175806.3638\n",
      "Epoch 241/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 78946.6186 - val_loss: 175742.3545\n",
      "Epoch 242/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 78906.6412 - val_loss: 175678.3666\n",
      "Epoch 243/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 78866.6690 - val_loss: 175614.3931\n",
      "Epoch 244/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 78826.7085 - val_loss: 175550.4237\n",
      "Epoch 245/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 78786.7604 - val_loss: 175486.4941\n",
      "Epoch 246/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 78746.8265 - val_loss: 175422.5503\n",
      "Epoch 247/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 78706.8983 - val_loss: 175358.6147\n",
      "Epoch 248/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 78666.9865 - val_loss: 175294.7273\n",
      "Epoch 249/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 78627.0820 - val_loss: 175230.8218\n",
      "Epoch 250/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 78587.1899 - val_loss: 175166.9452\n",
      "Epoch 251/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 78547.3088 - val_loss: 175103.0887\n",
      "Epoch 252/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 78507.4386 - val_loss: 175039.2186\n",
      "Epoch 253/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 78467.5835 - val_loss: 174975.3847\n",
      "Epoch 254/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 78427.7338 - val_loss: 174911.5584\n",
      "Epoch 255/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 78387.8987 - val_loss: 174847.7476\n",
      "Epoch 256/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 78348.0760 - val_loss: 174783.9275\n",
      "Epoch 257/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 78308.2600 - val_loss: 174720.1425\n",
      "Epoch 258/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 78268.4555 - val_loss: 174656.3701\n",
      "Epoch 259/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 78228.6628 - val_loss: 174592.5966\n",
      "Epoch 260/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 78188.8769 - val_loss: 174528.8428\n",
      "Epoch 261/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 78149.1031 - val_loss: 174465.1061\n",
      "Epoch 262/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 78109.3426 - val_loss: 174401.3755\n",
      "Epoch 263/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 78069.5915 - val_loss: 174337.6636\n",
      "Epoch 264/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 78029.8543 - val_loss: 174273.9598\n",
      "Epoch 265/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 77990.1234 - val_loss: 174210.2624\n",
      "Epoch 266/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 77950.4044 - val_loss: 174146.5805\n",
      "Epoch 267/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 77910.6977 - val_loss: 174082.9137\n",
      "Epoch 268/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 77871.0028 - val_loss: 174019.2605\n",
      "Epoch 269/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 77831.3216 - val_loss: 173955.6318\n",
      "Epoch 270/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 77791.6501 - val_loss: 173892.0069\n",
      "Epoch 271/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 77751.9918 - val_loss: 173828.4029\n",
      "Epoch 272/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 77712.3436 - val_loss: 173764.8044\n",
      "Epoch 273/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 77672.7087 - val_loss: 173701.2317\n",
      "Epoch 274/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 77633.0839 - val_loss: 173637.6625\n",
      "Epoch 275/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 77593.4696 - val_loss: 173574.1053\n",
      "Epoch 276/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 77553.8696 - val_loss: 173510.5522\n",
      "Epoch 277/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 77514.2772 - val_loss: 173447.0354\n",
      "Epoch 278/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 77474.6968 - val_loss: 173383.5132\n",
      "Epoch 279/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 77435.1260 - val_loss: 173320.0110\n",
      "Epoch 280/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 77395.5676 - val_loss: 173256.5217\n",
      "Epoch 281/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 77356.0162 - val_loss: 173193.0386\n",
      "Epoch 282/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 77316.4755 - val_loss: 173129.5671\n",
      "Epoch 283/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 77276.9491 - val_loss: 173066.0956\n",
      "Epoch 284/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 77237.4290 - val_loss: 173002.6572\n",
      "Epoch 285/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 77197.9222 - val_loss: 172939.2282\n",
      "Epoch 286/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 77158.4242 - val_loss: 172875.8066\n",
      "Epoch 287/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 77118.9390 - val_loss: 172812.4001\n",
      "Epoch 288/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 77079.4634 - val_loss: 172749.0030\n",
      "Epoch 289/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 77039.9987 - val_loss: 172685.6168\n",
      "Epoch 290/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 77000.5445 - val_loss: 172622.2500\n",
      "Epoch 291/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 76961.1001 - val_loss: 172558.8867\n",
      "Epoch 292/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 76921.6686 - val_loss: 172495.5537\n",
      "Epoch 293/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 76882.2506 - val_loss: 172432.2257\n",
      "Epoch 294/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 76842.8412 - val_loss: 172368.9031\n",
      "Epoch 295/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 76803.4412 - val_loss: 172305.5921\n",
      "Epoch 296/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 76764.0543 - val_loss: 172242.3112\n",
      "Epoch 297/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 76724.6808 - val_loss: 172179.0256\n",
      "Epoch 298/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 76685.3123 - val_loss: 172115.7709\n",
      "Epoch 299/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 76645.9594 - val_loss: 172052.5081\n",
      "Epoch 300/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 76606.6160 - val_loss: 171989.2630\n",
      "Epoch 301/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 76567.2831 - val_loss: 171926.0325\n",
      "Epoch 302/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 76527.9614 - val_loss: 171862.8335\n",
      "Epoch 303/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 76488.6502 - val_loss: 171799.6162\n",
      "Epoch 304/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 76449.3472 - val_loss: 171736.4329\n",
      "Epoch 305/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 76410.0577 - val_loss: 171673.2397\n",
      "Epoch 306/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 76370.7789 - val_loss: 171610.0826\n",
      "Epoch 307/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 76331.5084 - val_loss: 171546.9333\n",
      "Epoch 308/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 76292.2515 - val_loss: 171483.7746\n",
      "Epoch 309/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 76253.0013 - val_loss: 171420.6500\n",
      "Epoch 310/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 76213.7662 - val_loss: 171357.5154\n",
      "Epoch 311/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 76174.5384 - val_loss: 171294.4208\n",
      "Epoch 312/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 76135.3205 - val_loss: 171231.3311\n",
      "Epoch 313/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 76096.1167 - val_loss: 171168.2619\n",
      "Epoch 314/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 76056.9261 - val_loss: 171105.1973\n",
      "Epoch 315/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 76017.7438 - val_loss: 171042.1420\n",
      "Epoch 316/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 75978.5736 - val_loss: 170979.1022\n",
      "Epoch 317/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 75939.4136 - val_loss: 170916.0740\n",
      "Epoch 318/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 75900.2668 - val_loss: 170853.0573\n",
      "Epoch 319/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 75861.1274 - val_loss: 170790.0536\n",
      "Epoch 320/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 75822.0009 - val_loss: 170727.0643\n",
      "Epoch 321/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 75782.8859 - val_loss: 170664.0851\n",
      "Epoch 322/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 75743.7819 - val_loss: 170601.1184\n",
      "Epoch 323/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 75704.6864 - val_loss: 170538.1555\n",
      "Epoch 324/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 75665.6001 - val_loss: 170475.2336\n",
      "Epoch 325/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 75626.5279 - val_loss: 170412.3068\n",
      "Epoch 326/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 75587.4643 - val_loss: 170349.3879\n",
      "Epoch 327/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 75548.4142 - val_loss: 170286.4731\n",
      "Epoch 328/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 75509.3707 - val_loss: 170223.6007\n",
      "Epoch 329/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 75470.3411 - val_loss: 170160.7143\n",
      "Epoch 330/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 75431.3196 - val_loss: 170097.8384\n",
      "Epoch 331/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 75392.3117 - val_loss: 170034.9954\n",
      "Epoch 332/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 75353.3122 - val_loss: 169972.1550\n",
      "Epoch 333/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 75314.3248 - val_loss: 169909.3156\n",
      "Epoch 334/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 75275.3460 - val_loss: 169846.5090\n",
      "Epoch 335/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 75236.3787 - val_loss: 169783.6973\n",
      "Epoch 336/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 75197.4225 - val_loss: 169720.9123\n",
      "Epoch 337/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 75158.4787 - val_loss: 169658.1232\n",
      "Epoch 338/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 75119.5436 - val_loss: 169595.3697\n",
      "Epoch 339/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 75080.6194 - val_loss: 169532.5966\n",
      "Epoch 340/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 75041.7040 - val_loss: 169469.8734\n",
      "Epoch 341/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 75002.8019 - val_loss: 169407.1304\n",
      "Epoch 342/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 74963.9074 - val_loss: 169344.4188\n",
      "Epoch 343/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 74925.0293 - val_loss: 169281.7005\n",
      "Epoch 344/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 74886.1580 - val_loss: 169219.0168\n",
      "Epoch 345/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 74847.2979 - val_loss: 169156.3474\n",
      "Epoch 346/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 74808.4522 - val_loss: 169093.6677\n",
      "Epoch 347/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 74769.6114 - val_loss: 169031.0123\n",
      "Epoch 348/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 74730.7848 - val_loss: 168968.3764\n",
      "Epoch 349/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 74691.9695 - val_loss: 168905.7460\n",
      "Epoch 350/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 74653.1633 - val_loss: 168843.1344\n",
      "Epoch 351/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 74614.3695 - val_loss: 168780.5298\n",
      "Epoch 352/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 74575.5854 - val_loss: 168717.9186\n",
      "Epoch 353/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 74536.8129 - val_loss: 168655.3390\n",
      "Epoch 354/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 74498.0508 - val_loss: 168592.7722\n",
      "Epoch 355/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 74459.2992 - val_loss: 168530.2156\n",
      "Epoch 356/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 74420.5571 - val_loss: 168467.6742\n",
      "Epoch 357/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 74381.8244 - val_loss: 168405.1466\n",
      "Epoch 358/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 74343.1055 - val_loss: 168342.6249\n",
      "Epoch 359/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 74304.3969 - val_loss: 168280.1217\n",
      "Epoch 360/2000\n",
      "534/534 [==============================] - 0s 134us/step - loss: 74265.6968 - val_loss: 168217.6290\n",
      "Epoch 361/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 74227.0102 - val_loss: 168155.1619\n",
      "Epoch 362/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 74188.3339 - val_loss: 168092.6994\n",
      "Epoch 363/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 74149.6685 - val_loss: 168030.2373\n",
      "Epoch 364/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 74111.0168 - val_loss: 167967.7812\n",
      "Epoch 365/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 74072.3751 - val_loss: 167905.3751\n",
      "Epoch 366/2000\n",
      "534/534 [==============================] - 0s 164us/step - loss: 74033.7408 - val_loss: 167842.9535\n",
      "Epoch 367/2000\n",
      "534/534 [==============================] - 0s 122us/step - loss: 73995.1211 - val_loss: 167780.5619\n",
      "Epoch 368/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 73956.5111 - val_loss: 167718.1619\n",
      "Epoch 369/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 73917.9120 - val_loss: 167655.7755\n",
      "Epoch 370/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 73879.3227 - val_loss: 167593.4205\n",
      "Epoch 371/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 73840.7429 - val_loss: 167531.0563\n",
      "Epoch 372/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 73802.1756 - val_loss: 167468.7291\n",
      "Epoch 373/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 73763.6184 - val_loss: 167406.3853\n",
      "Epoch 374/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 73725.0729 - val_loss: 167344.0793\n",
      "Epoch 375/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 73686.5361 - val_loss: 167281.7688\n",
      "Epoch 376/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 73648.0118 - val_loss: 167219.4765\n",
      "Epoch 377/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 73609.4996 - val_loss: 167157.2069\n",
      "Epoch 378/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 73570.9960 - val_loss: 167094.9400\n",
      "Epoch 379/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 73532.5024 - val_loss: 167032.6853\n",
      "Epoch 380/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 73494.0202 - val_loss: 166970.4432\n",
      "Epoch 381/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 73455.5500 - val_loss: 166908.2081\n",
      "Epoch 382/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 73417.0870 - val_loss: 166845.9908\n",
      "Epoch 383/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 73378.6371 - val_loss: 166783.7909\n",
      "Epoch 384/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 73340.1974 - val_loss: 166721.6035\n",
      "Epoch 385/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 73301.7663 - val_loss: 166659.3982\n",
      "Epoch 386/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 73263.3461 - val_loss: 166597.2395\n",
      "Epoch 387/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 73224.9401 - val_loss: 166535.0846\n",
      "Epoch 388/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 73186.5406 - val_loss: 166472.9468\n",
      "Epoch 389/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 73148.1554 - val_loss: 166410.8039\n",
      "Epoch 390/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 73109.7775 - val_loss: 166348.6775\n",
      "Epoch 391/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 73071.4105 - val_loss: 166286.5694\n",
      "Epoch 392/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 73033.0552 - val_loss: 166224.4729\n",
      "Epoch 393/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 72994.7097 - val_loss: 166162.4002\n",
      "Epoch 394/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 72956.3737 - val_loss: 166100.3253\n",
      "Epoch 395/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 72918.0512 - val_loss: 166038.2697\n",
      "Epoch 396/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 72879.7367 - val_loss: 165976.2022\n",
      "Epoch 397/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 72841.4312 - val_loss: 165914.1678\n",
      "Epoch 398/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 72803.1356 - val_loss: 165852.1451\n",
      "Epoch 399/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 72764.8538 - val_loss: 165790.1366\n",
      "Epoch 400/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 72726.5827 - val_loss: 165728.1377\n",
      "Epoch 401/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 72688.3211 - val_loss: 165666.1497\n",
      "Epoch 402/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 72650.0725 - val_loss: 165604.1734\n",
      "Epoch 403/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 72611.8338 - val_loss: 165542.2119\n",
      "Epoch 404/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 72573.6091 - val_loss: 165480.2770\n",
      "Epoch 405/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 72535.3938 - val_loss: 165418.3433\n",
      "Epoch 406/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 72497.1857 - val_loss: 165356.4165\n",
      "Epoch 407/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 72458.9872 - val_loss: 165294.4959\n",
      "Epoch 408/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 72420.8024 - val_loss: 165232.5930\n",
      "Epoch 409/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 72382.6290 - val_loss: 165170.7104\n",
      "Epoch 410/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 72344.4658 - val_loss: 165108.8404\n",
      "Epoch 411/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 72306.3116 - val_loss: 165046.9736\n",
      "Epoch 412/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 72268.1669 - val_loss: 164985.1191\n",
      "Epoch 413/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 72230.0348 - val_loss: 164923.2977\n",
      "Epoch 414/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 72191.9173 - val_loss: 164861.4640\n",
      "Epoch 415/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 72153.8047 - val_loss: 164799.6401\n",
      "Epoch 416/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 72115.7028 - val_loss: 164737.8570\n",
      "Epoch 417/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 72077.6149 - val_loss: 164676.0556\n",
      "Epoch 418/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 72039.5331 - val_loss: 164614.2714\n",
      "Epoch 419/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 72001.4626 - val_loss: 164552.5153\n",
      "Epoch 420/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 71963.4093 - val_loss: 164490.7571\n",
      "Epoch 421/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 71925.3550 - val_loss: 164429.0063\n",
      "Epoch 422/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 71887.3208 - val_loss: 164367.2934\n",
      "Epoch 423/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 71849.2919 - val_loss: 164305.5653\n",
      "Epoch 424/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 71811.2736 - val_loss: 164243.8698\n",
      "Epoch 425/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 71773.2722 - val_loss: 164182.1631\n",
      "Epoch 426/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 71735.2703 - val_loss: 164120.4786\n",
      "Epoch 427/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 71697.2853 - val_loss: 164058.8206\n",
      "Epoch 428/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 71659.3111 - val_loss: 163997.1555\n",
      "Epoch 429/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 71621.3464 - val_loss: 163935.5129\n",
      "Epoch 430/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 71583.3942 - val_loss: 163873.8768\n",
      "Epoch 431/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 71545.4515 - val_loss: 163812.2680\n",
      "Epoch 432/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 71507.5183 - val_loss: 163750.6490\n",
      "Epoch 433/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 71469.5994 - val_loss: 163689.0592\n",
      "Epoch 434/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 71431.6876 - val_loss: 163627.4627\n",
      "Epoch 435/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 71393.7869 - val_loss: 163565.9019\n",
      "Epoch 436/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 71355.8952 - val_loss: 163504.3425\n",
      "Epoch 437/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 71318.0153 - val_loss: 163442.7873\n",
      "Epoch 438/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 71280.1500 - val_loss: 163381.2636\n",
      "Epoch 439/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 71242.2941 - val_loss: 163319.7508\n",
      "Epoch 440/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 71204.4463 - val_loss: 163258.2477\n",
      "Epoch 441/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 71166.6100 - val_loss: 163196.7470\n",
      "Epoch 442/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 71128.7890 - val_loss: 163135.2510\n",
      "Epoch 443/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 71090.9749 - val_loss: 163073.7869\n",
      "Epoch 444/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 71053.1707 - val_loss: 163012.3283\n",
      "Epoch 445/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 71015.3807 - val_loss: 162950.8842\n",
      "Epoch 446/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 70977.5988 - val_loss: 162889.4574\n",
      "Epoch 447/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 70939.8290 - val_loss: 162828.0352\n",
      "Epoch 448/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 70902.0669 - val_loss: 162766.6266\n",
      "Epoch 449/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 70864.3181 - val_loss: 162705.2327\n",
      "Epoch 450/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 70826.5792 - val_loss: 162643.8440\n",
      "Epoch 451/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 70788.8481 - val_loss: 162582.4731\n",
      "Epoch 452/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 70751.1310 - val_loss: 162521.1085\n",
      "Epoch 453/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 70713.4247 - val_loss: 162459.7617\n",
      "Epoch 454/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 70675.7249 - val_loss: 162398.4200\n",
      "Epoch 455/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 70638.0383 - val_loss: 162337.0954\n",
      "Epoch 456/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 70600.3613 - val_loss: 162275.7856\n",
      "Epoch 457/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 70562.6939 - val_loss: 162214.4788\n",
      "Epoch 458/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 70525.0399 - val_loss: 162153.2028\n",
      "Epoch 459/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 70487.3938 - val_loss: 162091.9227\n",
      "Epoch 460/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 70449.7614 - val_loss: 162030.6680\n",
      "Epoch 461/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 70412.1376 - val_loss: 161969.4126\n",
      "Epoch 462/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 70374.5242 - val_loss: 161908.1664\n",
      "Epoch 463/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 70336.9223 - val_loss: 161846.9410\n",
      "Epoch 464/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 70299.3269 - val_loss: 161785.7324\n",
      "Epoch 465/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 70261.7471 - val_loss: 161724.5354\n",
      "Epoch 466/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 70224.1797 - val_loss: 161663.3387\n",
      "Epoch 467/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 70186.6188 - val_loss: 161602.1517\n",
      "Epoch 468/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 70149.0686 - val_loss: 161541.0039\n",
      "Epoch 469/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 70111.5314 - val_loss: 161479.8407\n",
      "Epoch 470/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 70074.0044 - val_loss: 161418.7089\n",
      "Epoch 471/2000\n",
      "534/534 [==============================] - 0s 135us/step - loss: 70036.4913 - val_loss: 161357.5788\n",
      "Epoch 472/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 69998.9847 - val_loss: 161296.4639\n",
      "Epoch 473/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 69961.4909 - val_loss: 161235.3662\n",
      "Epoch 474/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 69924.0063 - val_loss: 161174.2723\n",
      "Epoch 475/2000\n",
      "534/534 [==============================] - 0s 137us/step - loss: 69886.5334 - val_loss: 161113.2022\n",
      "Epoch 476/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 69849.0690 - val_loss: 161052.1289\n",
      "Epoch 477/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 69811.6158 - val_loss: 160991.0730\n",
      "Epoch 478/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 69774.1731 - val_loss: 160930.0486\n",
      "Epoch 479/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 69736.7425 - val_loss: 160869.0037\n",
      "Epoch 480/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 69699.3222 - val_loss: 160807.9938\n",
      "Epoch 481/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 69661.9100 - val_loss: 160746.9847\n",
      "Epoch 482/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 69624.5125 - val_loss: 160685.9990\n",
      "Epoch 483/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 69587.1214 - val_loss: 160625.0198\n",
      "Epoch 484/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 69549.7419 - val_loss: 160564.0361\n",
      "Epoch 485/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 69512.3720 - val_loss: 160503.0852\n",
      "Epoch 486/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 69475.0150 - val_loss: 160442.1511\n",
      "Epoch 487/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 69437.6688 - val_loss: 160381.2137\n",
      "Epoch 488/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 69400.3306 - val_loss: 160320.2909\n",
      "Epoch 489/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 69363.0071 - val_loss: 160259.3909\n",
      "Epoch 490/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 69325.6900 - val_loss: 160198.4996\n",
      "Epoch 491/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 69288.3849 - val_loss: 160137.6097\n",
      "Epoch 492/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 69251.0919 - val_loss: 160076.7332\n",
      "Epoch 493/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 69213.8067 - val_loss: 160015.8780\n",
      "Epoch 494/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 69176.5329 - val_loss: 159955.0276\n",
      "Epoch 495/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 69139.2701 - val_loss: 159894.2011\n",
      "Epoch 496/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 69102.0207 - val_loss: 159833.3836\n",
      "Epoch 497/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 69064.7791 - val_loss: 159772.5787\n",
      "Epoch 498/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 69027.5493 - val_loss: 159711.7728\n",
      "Epoch 499/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 68990.3265 - val_loss: 159650.9853\n",
      "Epoch 500/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 68953.1167 - val_loss: 159590.2016\n",
      "Epoch 501/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 68915.9167 - val_loss: 159529.4469\n",
      "Epoch 502/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 68878.7276 - val_loss: 159468.6939\n",
      "Epoch 503/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 68841.5501 - val_loss: 159407.9579\n",
      "Epoch 504/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 68804.3803 - val_loss: 159347.2348\n",
      "Epoch 505/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 68767.2197 - val_loss: 159286.5262\n",
      "Epoch 506/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 68730.0740 - val_loss: 159225.8237\n",
      "Epoch 507/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 68692.9338 - val_loss: 159165.1290\n",
      "Epoch 508/2000\n",
      "534/534 [==============================] - 0s 122us/step - loss: 68655.8078 - val_loss: 159104.4513\n",
      "Epoch 509/2000\n",
      "534/534 [==============================] - 0s 160us/step - loss: 68618.6902 - val_loss: 159043.7891\n",
      "Epoch 510/2000\n",
      "534/534 [==============================] - 0s 119us/step - loss: 68581.5856 - val_loss: 158983.1256\n",
      "Epoch 511/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 68544.4880 - val_loss: 158922.4695\n",
      "Epoch 512/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 68507.4019 - val_loss: 158861.8415\n",
      "Epoch 513/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 68470.3272 - val_loss: 158801.2218\n",
      "Epoch 514/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 68433.2620 - val_loss: 158740.6324\n",
      "Epoch 515/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 68396.2108 - val_loss: 158680.0304\n",
      "Epoch 516/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 68359.1680 - val_loss: 158619.4564\n",
      "Epoch 517/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 68322.1364 - val_loss: 158558.8896\n",
      "Epoch 518/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 68285.1143 - val_loss: 158498.3228\n",
      "Epoch 519/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 68248.1043 - val_loss: 158437.7762\n",
      "Epoch 520/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 68211.1016 - val_loss: 158377.2438\n",
      "Epoch 521/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 68174.1106 - val_loss: 158316.7185\n",
      "Epoch 522/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 68137.1316 - val_loss: 158256.2061\n",
      "Epoch 523/2000\n",
      "534/534 [==============================] - 0s 90us/step - loss: 68100.1620 - val_loss: 158195.7143\n",
      "Epoch 524/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 68063.2044 - val_loss: 158135.2393\n",
      "Epoch 525/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 68026.2556 - val_loss: 158074.7639\n",
      "Epoch 526/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 67989.3186 - val_loss: 158014.2967\n",
      "Epoch 527/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 67952.3904 - val_loss: 157953.8558\n",
      "Epoch 528/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 67915.4768 - val_loss: 157893.4233\n",
      "Epoch 529/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 67878.5720 - val_loss: 157832.9917\n",
      "Epoch 530/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 67841.6797 - val_loss: 157772.5965\n",
      "Epoch 531/2000\n",
      "534/534 [==============================] - 0s 89us/step - loss: 67804.7964 - val_loss: 157712.1953\n",
      "Epoch 532/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 67767.9238 - val_loss: 157651.8179\n",
      "Epoch 533/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 67731.0632 - val_loss: 157591.4347\n",
      "Epoch 534/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 67694.2147 - val_loss: 157531.0921\n",
      "Epoch 535/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 67657.3729 - val_loss: 157470.7463\n",
      "Epoch 536/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 67620.5482 - val_loss: 157410.4069\n",
      "Epoch 537/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 67583.7314 - val_loss: 157350.0977\n",
      "Epoch 538/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 67546.9280 - val_loss: 157289.7967\n",
      "Epoch 539/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 67510.1334 - val_loss: 157229.5049\n",
      "Epoch 540/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 67473.3492 - val_loss: 157169.2046\n",
      "Epoch 541/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 67436.5757 - val_loss: 157108.9383\n",
      "Epoch 542/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 67399.8138 - val_loss: 157048.6879\n",
      "Epoch 543/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 67363.0557 - val_loss: 156988.4451\n",
      "Epoch 544/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 67326.3138 - val_loss: 156928.2014\n",
      "Epoch 545/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 67289.5822 - val_loss: 156867.9767\n",
      "Epoch 546/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 67252.8588 - val_loss: 156807.7681\n",
      "Epoch 547/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 67216.1481 - val_loss: 156747.5718\n",
      "Epoch 548/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 67179.4463 - val_loss: 156687.3892\n",
      "Epoch 549/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 67142.7597 - val_loss: 156627.2190\n",
      "Epoch 550/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 67106.0821 - val_loss: 156567.0580\n",
      "Epoch 551/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 67069.4162 - val_loss: 156506.9178\n",
      "Epoch 552/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 67032.7609 - val_loss: 156446.7965\n",
      "Epoch 553/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 66996.1186 - val_loss: 156386.6775\n",
      "Epoch 554/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 66959.4834 - val_loss: 156326.5642\n",
      "Epoch 555/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 66922.8573 - val_loss: 156266.4607\n",
      "Epoch 556/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 66886.2442 - val_loss: 156206.3884\n",
      "Epoch 557/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 66849.6415 - val_loss: 156146.3199\n",
      "Epoch 558/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 66813.0509 - val_loss: 156086.2595\n",
      "Epoch 559/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 66776.4680 - val_loss: 156026.2027\n",
      "Epoch 560/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 66739.8945 - val_loss: 155966.1632\n",
      "Epoch 561/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 66703.3325 - val_loss: 155906.1550\n",
      "Epoch 562/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 66666.7812 - val_loss: 155846.1355\n",
      "Epoch 563/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 66630.2409 - val_loss: 155786.1328\n",
      "Epoch 564/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 66593.7105 - val_loss: 155726.1366\n",
      "Epoch 565/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 66557.1871 - val_loss: 155666.1628\n",
      "Epoch 566/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 66520.6792 - val_loss: 155606.2084\n",
      "Epoch 567/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 66484.1807 - val_loss: 155546.2453\n",
      "Epoch 568/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 66447.6907 - val_loss: 155486.3025\n",
      "Epoch 569/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 66411.2128 - val_loss: 155426.3793\n",
      "Epoch 570/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 66374.7409 - val_loss: 155366.4645\n",
      "Epoch 571/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 66338.2845 - val_loss: 155306.5595\n",
      "Epoch 572/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 66301.8375 - val_loss: 155246.6550\n",
      "Epoch 573/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 66265.3994 - val_loss: 155186.7885\n",
      "Epoch 574/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 66228.9736 - val_loss: 155126.9070\n",
      "Epoch 575/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 66192.5577 - val_loss: 155067.0454\n",
      "Epoch 576/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 66156.1493 - val_loss: 155007.2133\n",
      "Epoch 577/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 66119.7525 - val_loss: 154947.3743\n",
      "Epoch 578/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 66083.3704 - val_loss: 154887.5491\n",
      "Epoch 579/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 66046.9933 - val_loss: 154827.7358\n",
      "Epoch 580/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 66010.6293 - val_loss: 154767.9424\n",
      "Epoch 581/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 65974.2748 - val_loss: 154708.1553\n",
      "Epoch 582/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 65937.9313 - val_loss: 154648.3764\n",
      "Epoch 583/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 65901.5973 - val_loss: 154588.6188\n",
      "Epoch 584/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 65865.2757 - val_loss: 154528.8594\n",
      "Epoch 585/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 65828.9627 - val_loss: 154469.1375\n",
      "Epoch 586/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 65792.6653 - val_loss: 154409.4029\n",
      "Epoch 587/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 65756.3737 - val_loss: 154349.7037\n",
      "Epoch 588/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 65720.0975 - val_loss: 154290.0089\n",
      "Epoch 589/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 65683.8295 - val_loss: 154230.3088\n",
      "Epoch 590/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 65647.5721 - val_loss: 154170.6495\n",
      "Epoch 591/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 65611.3281 - val_loss: 154110.9914\n",
      "Epoch 592/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 65575.0943 - val_loss: 154051.3492\n",
      "Epoch 593/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 65538.8688 - val_loss: 153991.6999\n",
      "Epoch 594/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 65502.6562 - val_loss: 153932.0802\n",
      "Epoch 595/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 65466.4508 - val_loss: 153872.4715\n",
      "Epoch 596/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 65430.2593 - val_loss: 153812.8777\n",
      "Epoch 597/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 65394.0757 - val_loss: 153753.2828\n",
      "Epoch 598/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 65357.9024 - val_loss: 153693.7021\n",
      "Epoch 599/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 65321.7402 - val_loss: 153634.1424\n",
      "Epoch 600/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 65285.5888 - val_loss: 153574.5916\n",
      "Epoch 601/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 65249.4455 - val_loss: 153515.0515\n",
      "Epoch 602/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 65213.3180 - val_loss: 153455.5333\n",
      "Epoch 603/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 65177.1994 - val_loss: 153396.0087\n",
      "Epoch 604/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 65141.0896 - val_loss: 153336.5086\n",
      "Epoch 605/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 65104.9913 - val_loss: 153277.0071\n",
      "Epoch 606/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 65068.9035 - val_loss: 153217.5421\n",
      "Epoch 607/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 65032.8274 - val_loss: 153158.0796\n",
      "Epoch 608/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 64996.7634 - val_loss: 153098.6372\n",
      "Epoch 609/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 64960.7098 - val_loss: 153039.1963\n",
      "Epoch 610/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 64924.6653 - val_loss: 152979.7648\n",
      "Epoch 611/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 64888.6305 - val_loss: 152920.3475\n",
      "Epoch 612/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 64852.6096 - val_loss: 152860.9556\n",
      "Epoch 613/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 64816.5992 - val_loss: 152801.5705\n",
      "Epoch 614/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 64780.5996 - val_loss: 152742.1863\n",
      "Epoch 615/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 64744.6082 - val_loss: 152682.8189\n",
      "Epoch 616/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 64708.6283 - val_loss: 152623.4801\n",
      "Epoch 617/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 64672.6594 - val_loss: 152564.1285\n",
      "Epoch 618/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 64636.6988 - val_loss: 152504.7960\n",
      "Epoch 619/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 64600.7501 - val_loss: 152445.4888\n",
      "Epoch 620/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 64564.8118 - val_loss: 152386.1864\n",
      "Epoch 621/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 64528.8854 - val_loss: 152326.8834\n",
      "Epoch 622/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 64492.9645 - val_loss: 152267.5953\n",
      "Epoch 623/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 64457.0566 - val_loss: 152208.3396\n",
      "Epoch 624/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 64421.1613 - val_loss: 152149.0737\n",
      "Epoch 625/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 64385.2735 - val_loss: 152089.8230\n",
      "Epoch 626/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 64349.3957 - val_loss: 152030.5787\n",
      "Epoch 627/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 64313.5296 - val_loss: 151971.3758\n",
      "Epoch 628/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 64277.6761 - val_loss: 151912.1560\n",
      "Epoch 629/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 64241.8296 - val_loss: 151852.9561\n",
      "Epoch 630/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 64205.9954 - val_loss: 151793.7762\n",
      "Epoch 631/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 64170.1713 - val_loss: 151734.5928\n",
      "Epoch 632/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 64134.3550 - val_loss: 151675.4470\n",
      "Epoch 633/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 64098.5530 - val_loss: 151616.2868\n",
      "Epoch 634/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 64062.7588 - val_loss: 151557.1497\n",
      "Epoch 635/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 64026.9775 - val_loss: 151498.0223\n",
      "Epoch 636/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 63991.2050 - val_loss: 151438.9020\n",
      "Epoch 637/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 63955.4423 - val_loss: 151379.8097\n",
      "Epoch 638/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 63919.6900 - val_loss: 151320.7130\n",
      "Epoch 639/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 63883.9542 - val_loss: 151261.6467\n",
      "Epoch 640/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 63848.2244 - val_loss: 151202.5931\n",
      "Epoch 641/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 63812.5102 - val_loss: 151143.5489\n",
      "Epoch 642/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 63776.8064 - val_loss: 151084.5107\n",
      "Epoch 643/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 63741.1116 - val_loss: 151025.4755\n",
      "Epoch 644/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 63705.4310 - val_loss: 150966.4696\n",
      "Epoch 645/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 63669.7565 - val_loss: 150907.4782\n",
      "Epoch 646/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 63634.0946 - val_loss: 150848.4912\n",
      "Epoch 647/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 63598.4406 - val_loss: 150789.5227\n",
      "Epoch 648/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 63562.7984 - val_loss: 150730.5621\n",
      "Epoch 649/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 63527.1680 - val_loss: 150671.6097\n",
      "Epoch 650/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 63491.5433 - val_loss: 150612.6620\n",
      "Epoch 651/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 63455.9346 - val_loss: 150553.7248\n",
      "Epoch 652/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 63420.3342 - val_loss: 150494.8406\n",
      "Epoch 653/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 63384.7440 - val_loss: 150435.9294\n",
      "Epoch 654/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 63349.1656 - val_loss: 150377.0468\n",
      "Epoch 655/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 63313.5990 - val_loss: 150318.1692\n",
      "Epoch 656/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 63278.0415 - val_loss: 150259.3018\n",
      "Epoch 657/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 63242.4966 - val_loss: 150200.4459\n",
      "Epoch 658/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 63206.9578 - val_loss: 150141.6069\n",
      "Epoch 659/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 63171.4339 - val_loss: 150082.7756\n",
      "Epoch 660/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 63135.9160 - val_loss: 150023.9581\n",
      "Epoch 661/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 63100.4113 - val_loss: 149965.1490\n",
      "Epoch 662/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 63064.9180 - val_loss: 149906.3786\n",
      "Epoch 663/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 63029.4337 - val_loss: 149847.5959\n",
      "Epoch 664/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 62993.9639 - val_loss: 149788.8217\n",
      "Epoch 665/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 62958.5000 - val_loss: 149730.0658\n",
      "Epoch 666/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 62923.0476 - val_loss: 149671.3259\n",
      "Epoch 667/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 62887.6031 - val_loss: 149612.6022\n",
      "Epoch 668/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 62852.1730 - val_loss: 149553.8775\n",
      "Epoch 669/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 62816.7533 - val_loss: 149495.1616\n",
      "Epoch 670/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 62781.3411 - val_loss: 149436.4630\n",
      "Epoch 671/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 62745.9387 - val_loss: 149377.7956\n",
      "Epoch 672/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 62710.5502 - val_loss: 149319.1205\n",
      "Epoch 673/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 62675.1727 - val_loss: 149260.4487\n",
      "Epoch 674/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 62639.8065 - val_loss: 149201.8232\n",
      "Epoch 675/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 62604.4517 - val_loss: 149143.1875\n",
      "Epoch 676/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 62569.1057 - val_loss: 149084.5662\n",
      "Epoch 677/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 62533.7719 - val_loss: 149025.9648\n",
      "Epoch 678/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 62498.4455 - val_loss: 148967.3661\n",
      "Epoch 679/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 62463.1332 - val_loss: 148908.7906\n",
      "Epoch 680/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 62427.8328 - val_loss: 148850.2189\n",
      "Epoch 681/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 62392.5369 - val_loss: 148791.6621\n",
      "Epoch 682/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 62357.2577 - val_loss: 148733.1220\n",
      "Epoch 683/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 62321.9842 - val_loss: 148674.5741\n",
      "Epoch 684/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 62286.7231 - val_loss: 148616.0562\n",
      "Epoch 685/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 62251.4731 - val_loss: 148557.5424\n",
      "Epoch 686/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 62216.2323 - val_loss: 148499.0439\n",
      "Epoch 687/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 62180.9986 - val_loss: 148440.5580\n",
      "Epoch 688/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 62145.7769 - val_loss: 148382.0714\n",
      "Epoch 689/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 62110.5666 - val_loss: 148323.6179\n",
      "Epoch 690/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 62075.3705 - val_loss: 148265.1755\n",
      "Epoch 691/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 62040.1840 - val_loss: 148206.7427\n",
      "Epoch 692/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 62005.0074 - val_loss: 148148.3226\n",
      "Epoch 693/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 61969.8419 - val_loss: 148089.9035\n",
      "Epoch 694/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 61934.6883 - val_loss: 148031.5224\n",
      "Epoch 695/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 61899.5444 - val_loss: 147973.1375\n",
      "Epoch 696/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 61864.4130 - val_loss: 147914.7606\n",
      "Epoch 697/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 61829.2878 - val_loss: 147856.4002\n",
      "Epoch 698/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 61794.1756 - val_loss: 147798.0376\n",
      "Epoch 699/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 61759.0740 - val_loss: 147739.6956\n",
      "Epoch 700/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 61723.9823 - val_loss: 147681.3618\n",
      "Epoch 701/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 61688.8990 - val_loss: 147623.0480\n",
      "Epoch 702/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 61653.8272 - val_loss: 147564.7472\n",
      "Epoch 703/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 61618.7654 - val_loss: 147506.4532\n",
      "Epoch 704/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 61583.7153 - val_loss: 147448.1921\n",
      "Epoch 705/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 61548.6785 - val_loss: 147389.9322\n",
      "Epoch 706/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 61513.6476 - val_loss: 147331.6755\n",
      "Epoch 707/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 61478.6326 - val_loss: 147273.4348\n",
      "Epoch 708/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 61443.6262 - val_loss: 147215.2065\n",
      "Epoch 709/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 61408.6275 - val_loss: 147156.9948\n",
      "Epoch 710/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 61373.6403 - val_loss: 147098.7826\n",
      "Epoch 711/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 61338.6619 - val_loss: 147040.5977\n",
      "Epoch 712/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 61303.6951 - val_loss: 146982.4138\n",
      "Epoch 713/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 61268.7419 - val_loss: 146924.2381\n",
      "Epoch 714/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 61233.7983 - val_loss: 146866.0895\n",
      "Epoch 715/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 61198.8635 - val_loss: 146807.9508\n",
      "Epoch 716/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 61163.9430 - val_loss: 146749.8132\n",
      "Epoch 717/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 61129.0310 - val_loss: 146691.6851\n",
      "Epoch 718/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 61094.1268 - val_loss: 146633.5951\n",
      "Epoch 719/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 61059.2355 - val_loss: 146575.4916\n",
      "Epoch 720/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 61024.3552 - val_loss: 146517.4026\n",
      "Epoch 721/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 60989.4822 - val_loss: 146459.3399\n",
      "Epoch 722/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 60954.6248 - val_loss: 146401.2785\n",
      "Epoch 723/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 60919.7723 - val_loss: 146343.2442\n",
      "Epoch 724/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 60884.9346 - val_loss: 146285.1982\n",
      "Epoch 725/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 60850.1066 - val_loss: 146227.1736\n",
      "Epoch 726/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 60815.2887 - val_loss: 146169.1651\n",
      "Epoch 727/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 60780.4821 - val_loss: 146111.1745\n",
      "Epoch 728/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 60745.6830 - val_loss: 146053.1851\n",
      "Epoch 729/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 60710.8966 - val_loss: 145995.2194\n",
      "Epoch 730/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 60676.1210 - val_loss: 145937.2495\n",
      "Epoch 731/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 60641.3569 - val_loss: 145879.3098\n",
      "Epoch 732/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 60606.6017 - val_loss: 145821.3673\n",
      "Epoch 733/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 60571.8578 - val_loss: 145763.4365\n",
      "Epoch 734/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 60537.1251 - val_loss: 145705.5372\n",
      "Epoch 735/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 60502.4009 - val_loss: 145647.6231\n",
      "Epoch 736/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 60467.6883 - val_loss: 145589.7401\n",
      "Epoch 737/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 60432.9849 - val_loss: 145531.8605\n",
      "Epoch 738/2000\n",
      "534/534 [==============================] - 0s 90us/step - loss: 60398.2956 - val_loss: 145473.9920\n",
      "Epoch 739/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 60363.6150 - val_loss: 145416.1494\n",
      "Epoch 740/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 60328.9455 - val_loss: 145358.3133\n",
      "Epoch 741/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 60294.2868 - val_loss: 145300.4870\n",
      "Epoch 742/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 60259.6378 - val_loss: 145242.6795\n",
      "Epoch 743/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 60225.0008 - val_loss: 145184.8812\n",
      "Epoch 744/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 60190.3765 - val_loss: 145127.0994\n",
      "Epoch 745/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 60155.7618 - val_loss: 145069.3227\n",
      "Epoch 746/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 60121.1567 - val_loss: 145011.5571\n",
      "Epoch 747/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 60086.5624 - val_loss: 144953.8070\n",
      "Epoch 748/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 60051.9779 - val_loss: 144896.0659\n",
      "Epoch 749/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 60017.4039 - val_loss: 144838.3374\n",
      "Epoch 750/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 59982.8442 - val_loss: 144780.6178\n",
      "Epoch 751/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 59948.2914 - val_loss: 144722.9174\n",
      "Epoch 752/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 59913.7485 - val_loss: 144665.2348\n",
      "Epoch 753/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 59879.2161 - val_loss: 144607.5676\n",
      "Epoch 754/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 59844.6967 - val_loss: 144549.8970\n",
      "Epoch 755/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 59810.1867 - val_loss: 144492.2367\n",
      "Epoch 756/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 59775.6867 - val_loss: 144434.5939\n",
      "Epoch 757/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 59741.1965 - val_loss: 144376.9602\n",
      "Epoch 758/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 59706.7170 - val_loss: 144319.3558\n",
      "Epoch 759/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 59672.2485 - val_loss: 144261.7466\n",
      "Epoch 760/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 59637.7908 - val_loss: 144204.1468\n",
      "Epoch 761/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 59603.3424 - val_loss: 144146.5647\n",
      "Epoch 762/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 59568.9015 - val_loss: 144088.9855\n",
      "Epoch 763/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 59534.4743 - val_loss: 144031.4425\n",
      "Epoch 764/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 59500.0577 - val_loss: 143973.8928\n",
      "Epoch 765/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 59465.6529 - val_loss: 143916.3547\n",
      "Epoch 766/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 59431.2554 - val_loss: 143858.8204\n",
      "Epoch 767/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 59396.8648 - val_loss: 143801.3126\n",
      "Epoch 768/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 59362.4868 - val_loss: 143743.8196\n",
      "Epoch 769/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 59328.1207 - val_loss: 143686.3262\n",
      "Epoch 770/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 59293.7681 - val_loss: 143628.8490\n",
      "Epoch 771/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 59259.4221 - val_loss: 143571.3890\n",
      "Epoch 772/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 59225.0877 - val_loss: 143513.9377\n",
      "Epoch 773/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 59190.7630 - val_loss: 143456.4933\n",
      "Epoch 774/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 59156.4501 - val_loss: 143399.0576\n",
      "Epoch 775/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 59122.1468 - val_loss: 143341.6584\n",
      "Epoch 776/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 59087.8518 - val_loss: 143284.2491\n",
      "Epoch 777/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 59053.5724 - val_loss: 143226.8526\n",
      "Epoch 778/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 59019.3016 - val_loss: 143169.4836\n",
      "Epoch 779/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 58985.0418 - val_loss: 143112.1038\n",
      "Epoch 780/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 58950.7918 - val_loss: 143054.7669\n",
      "Epoch 781/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 58916.5542 - val_loss: 142997.4124\n",
      "Epoch 782/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 58882.3267 - val_loss: 142940.0772\n",
      "Epoch 783/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 58848.1085 - val_loss: 142882.7619\n",
      "Epoch 784/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 58813.8987 - val_loss: 142825.4681\n",
      "Epoch 785/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 58779.7044 - val_loss: 142768.1611\n",
      "Epoch 786/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 58745.5189 - val_loss: 142710.8880\n",
      "Epoch 787/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 58711.3431 - val_loss: 142653.6275\n",
      "Epoch 788/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 58677.1806 - val_loss: 142596.3704\n",
      "Epoch 789/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 58643.0298 - val_loss: 142539.1245\n",
      "Epoch 790/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 58608.8857 - val_loss: 142481.8999\n",
      "Epoch 791/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 58574.7567 - val_loss: 142424.6812\n",
      "Epoch 792/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 58540.6328 - val_loss: 142367.4831\n",
      "Epoch 793/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 58506.5228 - val_loss: 142310.2966\n",
      "Epoch 794/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 58472.4233 - val_loss: 142253.1055\n",
      "Epoch 795/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 58438.3344 - val_loss: 142195.9395\n",
      "Epoch 796/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 58404.2571 - val_loss: 142138.7750\n",
      "Epoch 797/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 58370.1866 - val_loss: 142081.6308\n",
      "Epoch 798/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 58336.1295 - val_loss: 142024.4972\n",
      "Epoch 799/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 58302.0808 - val_loss: 141967.3817\n",
      "Epoch 800/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 58268.0451 - val_loss: 141910.2743\n",
      "Epoch 801/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 58234.0199 - val_loss: 141853.1766\n",
      "Epoch 802/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 58200.0037 - val_loss: 141796.0910\n",
      "Epoch 803/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 58165.9985 - val_loss: 141739.0179\n",
      "Epoch 804/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 58132.0032 - val_loss: 141681.9740\n",
      "Epoch 805/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 58098.0182 - val_loss: 141624.9264\n",
      "Epoch 806/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 58064.0444 - val_loss: 141567.8960\n",
      "Epoch 807/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 58030.0814 - val_loss: 141510.8677\n",
      "Epoch 808/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 57996.1291 - val_loss: 141453.8562\n",
      "Epoch 809/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 57962.1882 - val_loss: 141396.8533\n",
      "Epoch 810/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 57928.2575 - val_loss: 141339.8856\n",
      "Epoch 811/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 57894.3348 - val_loss: 141282.9119\n",
      "Epoch 812/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 57860.4306 - val_loss: 141225.9552\n",
      "Epoch 813/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 57826.5350 - val_loss: 141169.0127\n",
      "Epoch 814/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 57792.6507 - val_loss: 141112.0909\n",
      "Epoch 815/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 57758.7734 - val_loss: 141055.1573\n",
      "Epoch 816/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 57724.9086 - val_loss: 140998.2621\n",
      "Epoch 817/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 57691.0544 - val_loss: 140941.3579\n",
      "Epoch 818/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 57657.2089 - val_loss: 140884.4783\n",
      "Epoch 819/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 57623.3750 - val_loss: 140827.5927\n",
      "Epoch 820/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 57589.5506 - val_loss: 140770.7431\n",
      "Epoch 821/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 57555.7395 - val_loss: 140713.8818\n",
      "Epoch 822/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 57521.9310 - val_loss: 140657.0547\n",
      "Epoch 823/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 57488.1402 - val_loss: 140600.2270\n",
      "Epoch 824/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 57454.3554 - val_loss: 140543.4134\n",
      "Epoch 825/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 57420.5854 - val_loss: 140486.6245\n",
      "Epoch 826/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 57386.8209 - val_loss: 140429.8171\n",
      "Epoch 827/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 57353.0717 - val_loss: 140373.0455\n",
      "Epoch 828/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 57319.3313 - val_loss: 140316.2742\n",
      "Epoch 829/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 57285.5993 - val_loss: 140259.5244\n",
      "Epoch 830/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 57251.8798 - val_loss: 140202.7901\n",
      "Epoch 831/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 57218.1716 - val_loss: 140146.0539\n",
      "Epoch 832/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 57184.4702 - val_loss: 140089.3333\n",
      "Epoch 833/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 57150.7832 - val_loss: 140032.6381\n",
      "Epoch 834/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 57117.1066 - val_loss: 139975.9368\n",
      "Epoch 835/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 57083.4379 - val_loss: 139919.2674\n",
      "Epoch 836/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 57049.7806 - val_loss: 139862.5869\n",
      "Epoch 837/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 57016.1353 - val_loss: 139805.9394\n",
      "Epoch 838/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 56982.4991 - val_loss: 139749.2990\n",
      "Epoch 839/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 56948.8706 - val_loss: 139692.6681\n",
      "Epoch 840/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 56915.2586 - val_loss: 139636.0437\n",
      "Epoch 841/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 56881.6541 - val_loss: 139579.4348\n",
      "Epoch 842/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 56848.0631 - val_loss: 139522.8475\n",
      "Epoch 843/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 56814.4809 - val_loss: 139466.2644\n",
      "Epoch 844/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 56780.9080 - val_loss: 139409.6964\n",
      "Epoch 845/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 56747.3457 - val_loss: 139353.1349\n",
      "Epoch 846/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 56713.7960 - val_loss: 139296.5925\n",
      "Epoch 847/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 56680.2549 - val_loss: 139240.0559\n",
      "Epoch 848/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 56646.7256 - val_loss: 139183.5353\n",
      "Epoch 849/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 56613.2073 - val_loss: 139127.0340\n",
      "Epoch 850/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 56579.7000 - val_loss: 139070.5352\n",
      "Epoch 851/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 56546.1997 - val_loss: 139014.0471\n",
      "Epoch 852/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 56512.7098 - val_loss: 138957.5735\n",
      "Epoch 853/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 56479.2355 - val_loss: 138901.1070\n",
      "Epoch 854/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 56445.7688 - val_loss: 138844.6635\n",
      "Epoch 855/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 56412.3113 - val_loss: 138788.2278\n",
      "Epoch 856/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 56378.8632 - val_loss: 138731.8108\n",
      "Epoch 857/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 56345.4278 - val_loss: 138675.3880\n",
      "Epoch 858/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 56312.0007 - val_loss: 138618.9867\n",
      "Epoch 859/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 56278.5855 - val_loss: 138562.5905\n",
      "Epoch 860/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 56245.1833 - val_loss: 138506.2227\n",
      "Epoch 861/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 56211.7892 - val_loss: 138449.8603\n",
      "Epoch 862/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 56178.4048 - val_loss: 138393.4990\n",
      "Epoch 863/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 56145.0344 - val_loss: 138337.1684\n",
      "Epoch 864/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 56111.6718 - val_loss: 138280.8441\n",
      "Epoch 865/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 56078.3189 - val_loss: 138224.5173\n",
      "Epoch 866/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 56044.9816 - val_loss: 138168.2166\n",
      "Epoch 867/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 56011.6471 - val_loss: 138111.9308\n",
      "Epoch 868/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 55978.3285 - val_loss: 138055.6477\n",
      "Epoch 869/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 55945.0183 - val_loss: 137999.3881\n",
      "Epoch 870/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 55911.7157 - val_loss: 137943.1216\n",
      "Epoch 871/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 55878.4262 - val_loss: 137886.8766\n",
      "Epoch 872/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 55845.1471 - val_loss: 137830.6456\n",
      "Epoch 873/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 55811.8818 - val_loss: 137774.4396\n",
      "Epoch 874/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 55778.6262 - val_loss: 137718.2222\n",
      "Epoch 875/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 55745.3811 - val_loss: 137662.0340\n",
      "Epoch 876/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 55712.1483 - val_loss: 137605.8612\n",
      "Epoch 877/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 55678.9271 - val_loss: 137549.7045\n",
      "Epoch 878/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 55645.7135 - val_loss: 137493.5523\n",
      "Epoch 879/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 55612.5148 - val_loss: 137437.4158\n",
      "Epoch 880/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 55579.3232 - val_loss: 137381.2939\n",
      "Epoch 881/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 55546.1444 - val_loss: 137325.1751\n",
      "Epoch 882/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 55512.9744 - val_loss: 137269.0710\n",
      "Epoch 883/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 55479.8175 - val_loss: 137212.9872\n",
      "Epoch 884/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 55446.6680 - val_loss: 137156.8904\n",
      "Epoch 885/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 55413.5317 - val_loss: 137100.8345\n",
      "Epoch 886/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 55380.4031 - val_loss: 137044.7819\n",
      "Epoch 887/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 55347.2880 - val_loss: 136988.7381\n",
      "Epoch 888/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 55314.1824 - val_loss: 136932.7071\n",
      "Epoch 889/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 55281.0875 - val_loss: 136876.6848\n",
      "Epoch 890/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 55248.0028 - val_loss: 136820.6781\n",
      "Epoch 891/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 55214.9281 - val_loss: 136764.6934\n",
      "Epoch 892/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 55181.8608 - val_loss: 136708.7179\n",
      "Epoch 893/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 55148.8053 - val_loss: 136652.7434\n",
      "Epoch 894/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 55115.7628 - val_loss: 136596.7799\n",
      "Epoch 895/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 55082.7272 - val_loss: 136540.8330\n",
      "Epoch 896/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 55049.7039 - val_loss: 136484.8927\n",
      "Epoch 897/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 55016.6910 - val_loss: 136428.9681\n",
      "Epoch 898/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 54983.6884 - val_loss: 136373.0533\n",
      "Epoch 899/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 54950.6950 - val_loss: 136317.1542\n",
      "Epoch 900/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 54917.7133 - val_loss: 136261.2777\n",
      "Epoch 901/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 54884.7408 - val_loss: 136205.3979\n",
      "Epoch 902/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 54851.7790 - val_loss: 136149.5282\n",
      "Epoch 903/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 54818.8289 - val_loss: 136093.6737\n",
      "Epoch 904/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 54785.8889 - val_loss: 136037.8431\n",
      "Epoch 905/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 54752.9583 - val_loss: 135982.0152\n",
      "Epoch 906/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 54720.0376 - val_loss: 135926.1931\n",
      "Epoch 907/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 54687.1293 - val_loss: 135870.3897\n",
      "Epoch 908/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 54654.2308 - val_loss: 135814.6089\n",
      "Epoch 909/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 54621.3414 - val_loss: 135758.8229\n",
      "Epoch 910/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 54588.4643 - val_loss: 135703.0459\n",
      "Epoch 911/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 54555.5951 - val_loss: 135647.3050\n",
      "Epoch 912/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 54522.7360 - val_loss: 135591.5543\n",
      "Epoch 913/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 54489.8898 - val_loss: 135535.8219\n",
      "Epoch 914/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 54457.0552 - val_loss: 135480.1115\n",
      "Epoch 915/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 54424.2310 - val_loss: 135424.3951\n",
      "Epoch 916/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 54391.4189 - val_loss: 135368.7128\n",
      "Epoch 917/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 54358.6178 - val_loss: 135313.0420\n",
      "Epoch 918/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 54325.8276 - val_loss: 135257.3698\n",
      "Epoch 919/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 54293.0491 - val_loss: 135201.7116\n",
      "Epoch 920/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 54260.2791 - val_loss: 135146.0763\n",
      "Epoch 921/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 54227.5205 - val_loss: 135090.4507\n",
      "Epoch 922/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 54194.7712 - val_loss: 135034.8414\n",
      "Epoch 923/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 54162.0335 - val_loss: 134979.2375\n",
      "Epoch 924/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 54129.3067 - val_loss: 134923.6499\n",
      "Epoch 925/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 54096.5901 - val_loss: 134868.0626\n",
      "Epoch 926/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 54063.8815 - val_loss: 134812.4941\n",
      "Epoch 927/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 54031.1852 - val_loss: 134756.9271\n",
      "Epoch 928/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 53998.5001 - val_loss: 134701.3991\n",
      "Epoch 929/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 53965.8278 - val_loss: 134645.8558\n",
      "Epoch 930/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 53933.1649 - val_loss: 134590.3479\n",
      "Epoch 931/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 53900.5141 - val_loss: 134534.8543\n",
      "Epoch 932/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 53867.8710 - val_loss: 134479.3586\n",
      "Epoch 933/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 53835.2419 - val_loss: 134423.8754\n",
      "Epoch 934/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 53802.6221 - val_loss: 134368.4140\n",
      "Epoch 935/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 53770.0152 - val_loss: 134312.9642\n",
      "Epoch 936/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 53737.4147 - val_loss: 134257.5202\n",
      "Epoch 937/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 53704.8306 - val_loss: 134202.0989\n",
      "Epoch 938/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 53672.2537 - val_loss: 134146.6873\n",
      "Epoch 939/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 53639.6887 - val_loss: 134091.2832\n",
      "Epoch 940/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 53607.1333 - val_loss: 134035.8909\n",
      "Epoch 941/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 53574.5893 - val_loss: 133980.5154\n",
      "Epoch 942/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 53542.0544 - val_loss: 133925.1487\n",
      "Epoch 943/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 53509.5314 - val_loss: 133869.7925\n",
      "Epoch 944/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 53477.0168 - val_loss: 133814.4469\n",
      "Epoch 945/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 53444.5172 - val_loss: 133759.1156\n",
      "Epoch 946/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 53412.0280 - val_loss: 133703.8026\n",
      "Epoch 947/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 53379.5453 - val_loss: 133648.5050\n",
      "Epoch 948/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 53347.0744 - val_loss: 133593.2087\n",
      "Epoch 949/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 53314.6164 - val_loss: 133537.9256\n",
      "Epoch 950/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 53282.1660 - val_loss: 133482.6579\n",
      "Epoch 951/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 53249.7271 - val_loss: 133427.4112\n",
      "Epoch 952/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 53217.2983 - val_loss: 133372.1682\n",
      "Epoch 953/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 53184.8828 - val_loss: 133316.9412\n",
      "Epoch 954/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 53152.4733 - val_loss: 133261.7138\n",
      "Epoch 955/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 53120.0765 - val_loss: 133206.4986\n",
      "Epoch 956/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 53087.6888 - val_loss: 133151.3065\n",
      "Epoch 957/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 53055.3118 - val_loss: 133096.1246\n",
      "Epoch 958/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 53022.9445 - val_loss: 133040.9531\n",
      "Epoch 959/2000\n",
      "534/534 [==============================] - 0s 91us/step - loss: 52990.5887 - val_loss: 132985.7876\n",
      "Epoch 960/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 52958.2424 - val_loss: 132930.6415\n",
      "Epoch 961/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 52925.9083 - val_loss: 132875.4922\n",
      "Epoch 962/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 52893.5821 - val_loss: 132820.3726\n",
      "Epoch 963/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 52861.2666 - val_loss: 132765.2606\n",
      "Epoch 964/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 52828.9607 - val_loss: 132710.1615\n",
      "Epoch 965/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 52796.6662 - val_loss: 132655.0732\n",
      "Epoch 966/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 52764.3826 - val_loss: 132599.9984\n",
      "Epoch 967/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 52732.1075 - val_loss: 132544.9305\n",
      "Epoch 968/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 52699.8444 - val_loss: 132489.8781\n",
      "Epoch 969/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 52667.5940 - val_loss: 132434.8405\n",
      "Epoch 970/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 52635.3523 - val_loss: 132379.8116\n",
      "Epoch 971/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 52603.1212 - val_loss: 132324.7925\n",
      "Epoch 972/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 52570.8994 - val_loss: 132269.7870\n",
      "Epoch 973/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 52538.6920 - val_loss: 132214.7893\n",
      "Epoch 974/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 52506.4915 - val_loss: 132159.8094\n",
      "Epoch 975/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 52474.3023 - val_loss: 132104.8384\n",
      "Epoch 976/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 52442.1251 - val_loss: 132049.8766\n",
      "Epoch 977/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 52409.9562 - val_loss: 131994.9399\n",
      "Epoch 978/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 52377.7960 - val_loss: 131940.0144\n",
      "Epoch 979/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 52345.6471 - val_loss: 131885.0939\n",
      "Epoch 980/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 52313.5109 - val_loss: 131830.1783\n",
      "Epoch 981/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 52281.3842 - val_loss: 131775.2803\n",
      "Epoch 982/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 52249.2666 - val_loss: 131720.3882\n",
      "Epoch 983/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 52217.1601 - val_loss: 131665.5192\n",
      "Epoch 984/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 52185.0607 - val_loss: 131610.6545\n",
      "Epoch 985/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 52152.9719 - val_loss: 131555.7940\n",
      "Epoch 986/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 52120.8937 - val_loss: 131500.9592\n",
      "Epoch 987/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 52088.8240 - val_loss: 131446.1168\n",
      "Epoch 988/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 52056.7663 - val_loss: 131391.3066\n",
      "Epoch 989/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 52024.7209 - val_loss: 131336.5005\n",
      "Epoch 990/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 51992.6825 - val_loss: 131281.7022\n",
      "Epoch 991/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 51960.6556 - val_loss: 131226.9223\n",
      "Epoch 992/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 51928.6399 - val_loss: 131172.1473\n",
      "Epoch 993/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 51896.6322 - val_loss: 131117.3998\n",
      "Epoch 994/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 51864.6374 - val_loss: 131062.6475\n",
      "Epoch 995/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 51832.6528 - val_loss: 131007.9095\n",
      "Epoch 996/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 51800.6786 - val_loss: 130953.1844\n",
      "Epoch 997/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 51768.7180 - val_loss: 130898.4838\n",
      "Epoch 998/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 51736.7672 - val_loss: 130843.7946\n",
      "Epoch 999/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 51704.8253 - val_loss: 130789.1016\n",
      "Epoch 1000/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 51672.8929 - val_loss: 130734.4284\n",
      "Epoch 1001/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 51640.9719 - val_loss: 130679.7785\n",
      "Epoch 1002/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 51609.0620 - val_loss: 130625.1235\n",
      "Epoch 1003/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 51577.1619 - val_loss: 130570.4972\n",
      "Epoch 1004/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 51545.2720 - val_loss: 130515.8697\n",
      "Epoch 1005/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 51513.3970 - val_loss: 130461.2667\n",
      "Epoch 1006/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 51481.5309 - val_loss: 130406.6708\n",
      "Epoch 1007/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 51449.6762 - val_loss: 130352.0820\n",
      "Epoch 1008/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 51417.8322 - val_loss: 130297.5193\n",
      "Epoch 1009/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 51386.0006 - val_loss: 130242.9688\n",
      "Epoch 1010/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 51354.1779 - val_loss: 130188.4274\n",
      "Epoch 1011/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 51322.3650 - val_loss: 130133.8880\n",
      "Epoch 1012/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 51290.5638 - val_loss: 130079.3572\n",
      "Epoch 1013/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 51258.7731 - val_loss: 130024.8547\n",
      "Epoch 1014/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 51226.9952 - val_loss: 129970.3667\n",
      "Epoch 1015/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 51195.2268 - val_loss: 129915.8903\n",
      "Epoch 1016/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 51163.4699 - val_loss: 129861.4129\n",
      "Epoch 1017/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 51131.7227 - val_loss: 129806.9578\n",
      "Epoch 1018/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 51099.9844 - val_loss: 129752.5254\n",
      "Epoch 1019/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 51068.2613 - val_loss: 129698.0883\n",
      "Epoch 1020/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 51036.5480 - val_loss: 129643.6829\n",
      "Epoch 1021/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 51004.8468 - val_loss: 129589.2722\n",
      "Epoch 1022/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 50973.1563 - val_loss: 129534.8918\n",
      "Epoch 1023/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50941.4772 - val_loss: 129480.5049\n",
      "Epoch 1024/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 50909.8072 - val_loss: 129426.1508\n",
      "Epoch 1025/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50878.1490 - val_loss: 129371.7974\n",
      "Epoch 1026/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 50846.4992 - val_loss: 129317.4508\n",
      "Epoch 1027/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 50814.8606 - val_loss: 129263.1153\n",
      "Epoch 1028/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50783.2330 - val_loss: 129208.7988\n",
      "Epoch 1029/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 50751.6146 - val_loss: 129154.5024\n",
      "Epoch 1030/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50720.0082 - val_loss: 129100.2101\n",
      "Epoch 1031/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 50688.4088 - val_loss: 129045.9235\n",
      "Epoch 1032/2000\n",
      "534/534 [==============================] - 0s 91us/step - loss: 50656.8215 - val_loss: 128991.6604\n",
      "Epoch 1033/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 50625.2463 - val_loss: 128937.3962\n",
      "Epoch 1034/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50593.6800 - val_loss: 128883.1489\n",
      "Epoch 1035/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 50562.1229 - val_loss: 128828.9211\n",
      "Epoch 1036/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 50530.5762 - val_loss: 128774.6860\n",
      "Epoch 1037/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 50499.0418 - val_loss: 128720.4827\n",
      "Epoch 1038/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50467.5213 - val_loss: 128666.3029\n",
      "Epoch 1039/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 50436.0119 - val_loss: 128612.1178\n",
      "Epoch 1040/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 50404.5123 - val_loss: 128557.9544\n",
      "Epoch 1041/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 50373.0253 - val_loss: 128503.8036\n",
      "Epoch 1042/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50341.5463 - val_loss: 128449.6587\n",
      "Epoch 1043/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50310.0790 - val_loss: 128395.5237\n",
      "Epoch 1044/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50278.6230 - val_loss: 128341.4011\n",
      "Epoch 1045/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 50247.1776 - val_loss: 128287.3110\n",
      "Epoch 1046/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50215.7446 - val_loss: 128233.2121\n",
      "Epoch 1047/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50184.3192 - val_loss: 128179.1386\n",
      "Epoch 1048/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 50152.9067 - val_loss: 128125.0747\n",
      "Epoch 1049/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 50121.5050 - val_loss: 128071.0177\n",
      "Epoch 1050/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50090.1144 - val_loss: 128016.9754\n",
      "Epoch 1051/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 50058.7324 - val_loss: 127962.9488\n",
      "Epoch 1052/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 50027.3611 - val_loss: 127908.9290\n",
      "Epoch 1053/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 49996.0001 - val_loss: 127854.9225\n",
      "Epoch 1054/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 49964.6470 - val_loss: 127800.9292\n",
      "Epoch 1055/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 49933.3062 - val_loss: 127746.9466\n",
      "Epoch 1056/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 49901.9771 - val_loss: 127692.9831\n",
      "Epoch 1057/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 49870.6600 - val_loss: 127639.0281\n",
      "Epoch 1058/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 49839.3511 - val_loss: 127585.0921\n",
      "Epoch 1059/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 49808.0545 - val_loss: 127531.1593\n",
      "Epoch 1060/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 49776.7695 - val_loss: 127477.2264\n",
      "Epoch 1061/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 49745.4921 - val_loss: 127423.3217\n",
      "Epoch 1062/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 49714.2287 - val_loss: 127369.4329\n",
      "Epoch 1063/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 49682.9750 - val_loss: 127315.5575\n",
      "Epoch 1064/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 49651.7327 - val_loss: 127261.6899\n",
      "Epoch 1065/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 49620.5002 - val_loss: 127207.8284\n",
      "Epoch 1066/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 49589.2770 - val_loss: 127153.9833\n",
      "Epoch 1067/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 49558.0652 - val_loss: 127100.1571\n",
      "Epoch 1068/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 49526.8651 - val_loss: 127046.3344\n",
      "Epoch 1069/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 49495.6742 - val_loss: 126992.5304\n",
      "Epoch 1070/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 49464.4968 - val_loss: 126938.7355\n",
      "Epoch 1071/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 49433.3278 - val_loss: 126884.9629\n",
      "Epoch 1072/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 49402.1728 - val_loss: 126831.1882\n",
      "Epoch 1073/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 49371.0243 - val_loss: 126777.4380\n",
      "Epoch 1074/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 49339.8863 - val_loss: 126723.6944\n",
      "Epoch 1075/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 49308.7584 - val_loss: 126669.9529\n",
      "Epoch 1076/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 49277.6450 - val_loss: 126616.2290\n",
      "Epoch 1077/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 49246.5375 - val_loss: 126562.5336\n",
      "Epoch 1078/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 49215.4400 - val_loss: 126508.8272\n",
      "Epoch 1079/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 49184.3555 - val_loss: 126455.1328\n",
      "Epoch 1080/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 49153.2824 - val_loss: 126401.4725\n",
      "Epoch 1081/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 49122.2202 - val_loss: 126347.8060\n",
      "Epoch 1082/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 49091.1668 - val_loss: 126294.1701\n",
      "Epoch 1083/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 49060.1257 - val_loss: 126240.5362\n",
      "Epoch 1084/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 49029.0953 - val_loss: 126186.9078\n",
      "Epoch 1085/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 48998.0740 - val_loss: 126133.2953\n",
      "Epoch 1086/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 48967.0645 - val_loss: 126079.6987\n",
      "Epoch 1087/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 48936.0629 - val_loss: 126026.1202\n",
      "Epoch 1088/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 48905.0724 - val_loss: 125972.5430\n",
      "Epoch 1089/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 48874.0942 - val_loss: 125918.9763\n",
      "Epoch 1090/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 48843.1245 - val_loss: 125865.4331\n",
      "Epoch 1091/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 48812.1673 - val_loss: 125811.8917\n",
      "Epoch 1092/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 48781.2173 - val_loss: 125758.3622\n",
      "Epoch 1093/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 48750.2793 - val_loss: 125704.8562\n",
      "Epoch 1094/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 48719.3531 - val_loss: 125651.3542\n",
      "Epoch 1095/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 48688.4374 - val_loss: 125597.8716\n",
      "Epoch 1096/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 48657.5366 - val_loss: 125544.3979\n",
      "Epoch 1097/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 48626.6434 - val_loss: 125490.9378\n",
      "Epoch 1098/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 48595.7657 - val_loss: 125437.5051\n",
      "Epoch 1099/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 48564.8947 - val_loss: 125384.0545\n",
      "Epoch 1100/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 48534.0331 - val_loss: 125330.6404\n",
      "Epoch 1101/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 48503.1801 - val_loss: 125277.2162\n",
      "Epoch 1102/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 48472.3364 - val_loss: 125223.8117\n",
      "Epoch 1103/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 48441.5041 - val_loss: 125170.4307\n",
      "Epoch 1104/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 48410.6816 - val_loss: 125117.0369\n",
      "Epoch 1105/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 48379.8683 - val_loss: 125063.6675\n",
      "Epoch 1106/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 48349.0670 - val_loss: 125010.3110\n",
      "Epoch 1107/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 48318.2757 - val_loss: 124956.9672\n",
      "Epoch 1108/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 48287.4961 - val_loss: 124903.6320\n",
      "Epoch 1109/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 48256.7250 - val_loss: 124850.3224\n",
      "Epoch 1110/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 48225.9647 - val_loss: 124797.0126\n",
      "Epoch 1111/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 48195.2127 - val_loss: 124743.7165\n",
      "Epoch 1112/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 48164.4737 - val_loss: 124690.4262\n",
      "Epoch 1113/2000\n",
      "534/534 [==============================] - 0s 126us/step - loss: 48133.7437 - val_loss: 124637.1498\n",
      "Epoch 1114/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 48103.0250 - val_loss: 124583.9017\n",
      "Epoch 1115/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 48072.3154 - val_loss: 124530.6486\n",
      "Epoch 1116/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 48041.6184 - val_loss: 124477.4083\n",
      "Epoch 1117/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 48010.9319 - val_loss: 124424.1892\n",
      "Epoch 1118/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 47980.2555 - val_loss: 124370.9732\n",
      "Epoch 1119/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 47949.5891 - val_loss: 124317.7710\n",
      "Epoch 1120/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 47918.9364 - val_loss: 124264.5912\n",
      "Epoch 1121/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 47888.2904 - val_loss: 124211.4232\n",
      "Epoch 1122/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 47857.6579 - val_loss: 124158.2598\n",
      "Epoch 1123/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 47827.0350 - val_loss: 124105.1090\n",
      "Epoch 1124/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 47796.4244 - val_loss: 124051.9802\n",
      "Epoch 1125/2000\n",
      "534/534 [==============================] - 0s 134us/step - loss: 47765.8234 - val_loss: 123998.8609\n",
      "Epoch 1126/2000\n",
      "534/534 [==============================] - 0s 153us/step - loss: 47735.2374 - val_loss: 123945.7456\n",
      "Epoch 1127/2000\n",
      "534/534 [==============================] - 0s 138us/step - loss: 47704.6577 - val_loss: 123892.6578\n",
      "Epoch 1128/2000\n",
      "534/534 [==============================] - 0s 134us/step - loss: 47674.0921 - val_loss: 123839.5753\n",
      "Epoch 1129/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 47643.5359 - val_loss: 123786.4964\n",
      "Epoch 1130/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 47612.9901 - val_loss: 123733.4387\n",
      "Epoch 1131/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 47582.4531 - val_loss: 123680.3996\n",
      "Epoch 1132/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 47551.9259 - val_loss: 123627.3548\n",
      "Epoch 1133/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 47521.4088 - val_loss: 123574.3261\n",
      "Epoch 1134/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 47490.9047 - val_loss: 123521.3222\n",
      "Epoch 1135/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 47460.4083 - val_loss: 123468.3122\n",
      "Epoch 1136/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 47429.9231 - val_loss: 123415.3247\n",
      "Epoch 1137/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 47399.4491 - val_loss: 123362.3492\n",
      "Epoch 1138/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 47368.9856 - val_loss: 123309.3861\n",
      "Epoch 1139/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 47338.5320 - val_loss: 123256.4349\n",
      "Epoch 1140/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 47308.0872 - val_loss: 123203.4955\n",
      "Epoch 1141/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 47277.6530 - val_loss: 123150.5599\n",
      "Epoch 1142/2000\n",
      "534/534 [==============================] - 0s 145us/step - loss: 47247.2313 - val_loss: 123097.6350\n",
      "Epoch 1143/2000\n",
      "534/534 [==============================] - 0s 146us/step - loss: 47216.8184 - val_loss: 123044.7384\n",
      "Epoch 1144/2000\n",
      "534/534 [==============================] - 0s 129us/step - loss: 47186.4174 - val_loss: 122991.8398\n",
      "Epoch 1145/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 47156.0252 - val_loss: 122938.9716\n",
      "Epoch 1146/2000\n",
      "534/534 [==============================] - 0s 120us/step - loss: 47125.6426 - val_loss: 122886.0845\n",
      "Epoch 1147/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 47095.2718 - val_loss: 122833.2380\n",
      "Epoch 1148/2000\n",
      "534/534 [==============================] - 0s 141us/step - loss: 47064.9100 - val_loss: 122780.3941\n",
      "Epoch 1149/2000\n",
      "534/534 [==============================] - 0s 132us/step - loss: 47034.5598 - val_loss: 122727.5592\n",
      "Epoch 1150/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 47004.2214 - val_loss: 122674.7338\n",
      "Epoch 1151/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 46973.8931 - val_loss: 122621.9309\n",
      "Epoch 1152/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 46943.5759 - val_loss: 122569.1313\n",
      "Epoch 1153/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 46913.2686 - val_loss: 122516.3557\n",
      "Epoch 1154/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 46882.9719 - val_loss: 122463.5752\n",
      "Epoch 1155/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 46852.6834 - val_loss: 122410.8098\n",
      "Epoch 1156/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 46822.4063 - val_loss: 122358.0644\n",
      "Epoch 1157/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 46792.1391 - val_loss: 122305.3358\n",
      "Epoch 1158/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 46761.8865 - val_loss: 122252.6192\n",
      "Epoch 1159/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 46731.6416 - val_loss: 122199.9055\n",
      "Epoch 1160/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 46701.4055 - val_loss: 122147.2000\n",
      "Epoch 1161/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 46671.1802 - val_loss: 122094.5176\n",
      "Epoch 1162/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 46640.9636 - val_loss: 122041.8397\n",
      "Epoch 1163/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 46610.7588 - val_loss: 121989.1677\n",
      "Epoch 1164/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 46580.5657 - val_loss: 121936.5222\n",
      "Epoch 1165/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 46550.3811 - val_loss: 121883.8796\n",
      "Epoch 1166/2000\n",
      "534/534 [==============================] - 0s 121us/step - loss: 46520.2092 - val_loss: 121831.2533\n",
      "Epoch 1167/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 46490.0472 - val_loss: 121778.6383\n",
      "Epoch 1168/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 46459.8956 - val_loss: 121726.0357\n",
      "Epoch 1169/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 46429.7567 - val_loss: 121673.4418\n",
      "Epoch 1170/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 46399.6268 - val_loss: 121620.8706\n",
      "Epoch 1171/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 46369.5079 - val_loss: 121568.3129\n",
      "Epoch 1172/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 46339.4034 - val_loss: 121515.7662\n",
      "Epoch 1173/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 46309.3078 - val_loss: 121463.2282\n",
      "Epoch 1174/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 46279.2225 - val_loss: 121410.7057\n",
      "Epoch 1175/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 46249.1466 - val_loss: 121358.1839\n",
      "Epoch 1176/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 46219.0816 - val_loss: 121305.6819\n",
      "Epoch 1177/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 46189.0277 - val_loss: 121253.1956\n",
      "Epoch 1178/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 46158.9825 - val_loss: 121200.7047\n",
      "Epoch 1179/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 46128.9484 - val_loss: 121148.2533\n",
      "Epoch 1180/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 46098.9237 - val_loss: 121095.7867\n",
      "Epoch 1181/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 46068.9131 - val_loss: 121043.3559\n",
      "Epoch 1182/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 46038.9099 - val_loss: 120990.9354\n",
      "Epoch 1183/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 46008.9192 - val_loss: 120938.5164\n",
      "Epoch 1184/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 45978.9396 - val_loss: 120886.1100\n",
      "Epoch 1185/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 45948.9714 - val_loss: 120833.7379\n",
      "Epoch 1186/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 45919.0121 - val_loss: 120781.3474\n",
      "Epoch 1187/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 45889.0643 - val_loss: 120728.9802\n",
      "Epoch 1188/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 45859.1268 - val_loss: 120676.6385\n",
      "Epoch 1189/2000\n",
      "534/534 [==============================] - 0s 93us/step - loss: 45829.1999 - val_loss: 120624.2920\n",
      "Epoch 1190/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 45799.2820 - val_loss: 120571.9651\n",
      "Epoch 1191/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 45769.3752 - val_loss: 120519.6487\n",
      "Epoch 1192/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 45739.4790 - val_loss: 120467.3407\n",
      "Epoch 1193/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 45709.5945 - val_loss: 120415.0519\n",
      "Epoch 1194/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 45679.7217 - val_loss: 120362.7805\n",
      "Epoch 1195/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 45649.8574 - val_loss: 120310.5127\n",
      "Epoch 1196/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 45620.0046 - val_loss: 120258.2525\n",
      "Epoch 1197/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 45590.1617 - val_loss: 120206.0210\n",
      "Epoch 1198/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 45560.3286 - val_loss: 120153.7818\n",
      "Epoch 1199/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 45530.5064 - val_loss: 120101.5623\n",
      "Epoch 1200/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 45500.6943 - val_loss: 120049.3543\n",
      "Epoch 1201/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 45470.8907 - val_loss: 119997.1520\n",
      "Epoch 1202/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 45441.0990 - val_loss: 119944.9726\n",
      "Epoch 1203/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 45411.3156 - val_loss: 119892.8018\n",
      "Epoch 1204/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 45381.5463 - val_loss: 119840.6307\n",
      "Epoch 1205/2000\n",
      "534/534 [==============================] - 0s 121us/step - loss: 45351.7855 - val_loss: 119788.4893\n",
      "Epoch 1206/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 45322.0334 - val_loss: 119736.3498\n",
      "Epoch 1207/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 45292.2924 - val_loss: 119684.2285\n",
      "Epoch 1208/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 45262.5637 - val_loss: 119632.1118\n",
      "Epoch 1209/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 45232.8420 - val_loss: 119580.0179\n",
      "Epoch 1210/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 45203.1335 - val_loss: 119527.9185\n",
      "Epoch 1211/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 45173.4348 - val_loss: 119475.8373\n",
      "Epoch 1212/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 45143.7420 - val_loss: 119423.7781\n",
      "Epoch 1213/2000\n",
      "534/534 [==============================] - 0s 125us/step - loss: 45114.0605 - val_loss: 119371.7065\n",
      "Epoch 1214/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 45084.3880 - val_loss: 119319.6677\n",
      "Epoch 1215/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 45054.7276 - val_loss: 119267.6347\n",
      "Epoch 1216/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 45025.0776 - val_loss: 119215.6054\n",
      "Epoch 1217/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 44995.4379 - val_loss: 119163.6015\n",
      "Epoch 1218/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 44965.8086 - val_loss: 119111.5927\n",
      "Epoch 1219/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 44936.1881 - val_loss: 119059.6135\n",
      "Epoch 1220/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 44906.5778 - val_loss: 119007.6299\n",
      "Epoch 1221/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 44876.9798 - val_loss: 118955.6673\n",
      "Epoch 1222/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 44847.3895 - val_loss: 118903.7182\n",
      "Epoch 1223/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 44817.8146 - val_loss: 118851.7894\n",
      "Epoch 1224/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 44788.2514 - val_loss: 118799.8658\n",
      "Epoch 1225/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 44758.6981 - val_loss: 118747.9557\n",
      "Epoch 1226/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 44729.1559 - val_loss: 118696.0671\n",
      "Epoch 1227/2000\n",
      "534/534 [==============================] - 0s 155us/step - loss: 44699.6233 - val_loss: 118644.1856\n",
      "Epoch 1228/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 44670.1021 - val_loss: 118592.3135\n",
      "Epoch 1229/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 44640.5922 - val_loss: 118540.4522\n",
      "Epoch 1230/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 44611.0954 - val_loss: 118488.6194\n",
      "Epoch 1231/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 44581.6067 - val_loss: 118436.7816\n",
      "Epoch 1232/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 44552.1340 - val_loss: 118384.9732\n",
      "Epoch 1233/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 44522.6696 - val_loss: 118333.1639\n",
      "Epoch 1234/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 44493.2174 - val_loss: 118281.3827\n",
      "Epoch 1235/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 44463.7752 - val_loss: 118229.6045\n",
      "Epoch 1236/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 44434.3452 - val_loss: 118177.8450\n",
      "Epoch 1237/2000\n",
      "534/534 [==============================] - 0s 145us/step - loss: 44404.9275 - val_loss: 118126.1052\n",
      "Epoch 1238/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 44375.5197 - val_loss: 118074.3660\n",
      "Epoch 1239/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 44346.1220 - val_loss: 118022.6397\n",
      "Epoch 1240/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 44316.7362 - val_loss: 117970.9231\n",
      "Epoch 1241/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 44287.3575 - val_loss: 117919.2350\n",
      "Epoch 1242/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 44257.9923 - val_loss: 117867.5411\n",
      "Epoch 1243/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 44228.6356 - val_loss: 117815.8692\n",
      "Epoch 1244/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 44199.2891 - val_loss: 117764.2022\n",
      "Epoch 1245/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 44169.9584 - val_loss: 117712.5630\n",
      "Epoch 1246/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 44140.6367 - val_loss: 117660.9295\n",
      "Epoch 1247/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 44111.3262 - val_loss: 117609.3045\n",
      "Epoch 1248/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 44082.0265 - val_loss: 117557.6917\n",
      "Epoch 1249/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 44052.7352 - val_loss: 117506.1062\n",
      "Epoch 1250/2000\n",
      "534/534 [==============================] - 0s 124us/step - loss: 44023.4561 - val_loss: 117454.5107\n",
      "Epoch 1251/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 43994.1863 - val_loss: 117402.9343\n",
      "Epoch 1252/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 43964.9257 - val_loss: 117351.3841\n",
      "Epoch 1253/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 43935.6777 - val_loss: 117299.8287\n",
      "Epoch 1254/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 43906.4382 - val_loss: 117248.2828\n",
      "Epoch 1255/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 43877.2080 - val_loss: 117196.7539\n",
      "Epoch 1256/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 43847.9893 - val_loss: 117145.2347\n",
      "Epoch 1257/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 43818.7814 - val_loss: 117093.7338\n",
      "Epoch 1258/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 43789.5824 - val_loss: 117042.2382\n",
      "Epoch 1259/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 43760.3933 - val_loss: 116990.7609\n",
      "Epoch 1260/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 43731.2143 - val_loss: 116939.2931\n",
      "Epoch 1261/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 43702.0466 - val_loss: 116887.8328\n",
      "Epoch 1262/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 43672.8893 - val_loss: 116836.3849\n",
      "Epoch 1263/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 43643.7415 - val_loss: 116784.9542\n",
      "Epoch 1264/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 43614.6077 - val_loss: 116733.5396\n",
      "Epoch 1265/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 43585.4847 - val_loss: 116682.1443\n",
      "Epoch 1266/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 43556.3783 - val_loss: 116630.7519\n",
      "Epoch 1267/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 43527.2764 - val_loss: 116579.3844\n",
      "Epoch 1268/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 43498.1898 - val_loss: 116528.0202\n",
      "Epoch 1269/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 43469.1121 - val_loss: 116476.6593\n",
      "Epoch 1270/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 43440.0428 - val_loss: 116425.3267\n",
      "Epoch 1271/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 43410.9865 - val_loss: 116374.0007\n",
      "Epoch 1272/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 43381.9380 - val_loss: 116322.6789\n",
      "Epoch 1273/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 43352.9011 - val_loss: 116271.3793\n",
      "Epoch 1274/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 43323.8740 - val_loss: 116220.0828\n",
      "Epoch 1275/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 43294.8563 - val_loss: 116168.7978\n",
      "Epoch 1276/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 43265.8493 - val_loss: 116117.5299\n",
      "Epoch 1277/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 43236.8551 - val_loss: 116066.2760\n",
      "Epoch 1278/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 43207.8683 - val_loss: 116015.0283\n",
      "Epoch 1279/2000\n",
      "534/534 [==============================] - 0s 119us/step - loss: 43178.8911 - val_loss: 115963.7964\n",
      "Epoch 1280/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 43149.9269 - val_loss: 115912.5699\n",
      "Epoch 1281/2000\n",
      "534/534 [==============================] - 0s 126us/step - loss: 43120.9699 - val_loss: 115861.3693\n",
      "Epoch 1282/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 43092.0274 - val_loss: 115810.1692\n",
      "Epoch 1283/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 43063.0927 - val_loss: 115758.9840\n",
      "Epoch 1284/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 43034.1683 - val_loss: 115707.8048\n",
      "Epoch 1285/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 43005.2549 - val_loss: 115656.6518\n",
      "Epoch 1286/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 42976.3506 - val_loss: 115605.4948\n",
      "Epoch 1287/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 42947.4582 - val_loss: 115554.3614\n",
      "Epoch 1288/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 42918.5733 - val_loss: 115503.2350\n",
      "Epoch 1289/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 42889.7005 - val_loss: 115452.1141\n",
      "Epoch 1290/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 42860.8367 - val_loss: 115401.0089\n",
      "Epoch 1291/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 42831.9854 - val_loss: 115349.9177\n",
      "Epoch 1292/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 42803.1427 - val_loss: 115298.8378\n",
      "Epoch 1293/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 42774.3087 - val_loss: 115247.7641\n",
      "Epoch 1294/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 42745.4882 - val_loss: 115196.7193\n",
      "Epoch 1295/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 42716.6769 - val_loss: 115145.6726\n",
      "Epoch 1296/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 42687.8759 - val_loss: 115094.6390\n",
      "Epoch 1297/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 42659.0846 - val_loss: 115043.6247\n",
      "Epoch 1298/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 42630.3034 - val_loss: 114992.6125\n",
      "Epoch 1299/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 42601.5336 - val_loss: 114941.6088\n",
      "Epoch 1300/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 42572.7718 - val_loss: 114890.6327\n",
      "Epoch 1301/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 42544.0216 - val_loss: 114839.6448\n",
      "Epoch 1302/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 42515.2812 - val_loss: 114788.6919\n",
      "Epoch 1303/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 42486.5552 - val_loss: 114737.7488\n",
      "Epoch 1304/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 42457.8400 - val_loss: 114686.8157\n",
      "Epoch 1305/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 42429.1362 - val_loss: 114635.9031\n",
      "Epoch 1306/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 42400.4439 - val_loss: 114585.0068\n",
      "Epoch 1307/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 42371.7628 - val_loss: 114534.1088\n",
      "Epoch 1308/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 42343.0892 - val_loss: 114483.2355\n",
      "Epoch 1309/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 42314.4323 - val_loss: 114432.3717\n",
      "Epoch 1310/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 42285.7833 - val_loss: 114381.5283\n",
      "Epoch 1311/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 42257.1463 - val_loss: 114330.6791\n",
      "Epoch 1312/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 42228.5198 - val_loss: 114279.8552\n",
      "Epoch 1313/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 42199.9046 - val_loss: 114229.0483\n",
      "Epoch 1314/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 42171.3021 - val_loss: 114178.2537\n",
      "Epoch 1315/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 42142.7106 - val_loss: 114127.4672\n",
      "Epoch 1316/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 42114.1289 - val_loss: 114076.6979\n",
      "Epoch 1317/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 42085.5568 - val_loss: 114025.9326\n",
      "Epoch 1318/2000\n",
      "534/534 [==============================] - 0s 135us/step - loss: 42056.9974 - val_loss: 113975.1947\n",
      "Epoch 1319/2000\n",
      "534/534 [==============================] - 0s 150us/step - loss: 42028.4457 - val_loss: 113924.4601\n",
      "Epoch 1320/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 41999.9019 - val_loss: 113873.7290\n",
      "Epoch 1321/2000\n",
      "534/534 [==============================] - 0s 92us/step - loss: 41971.3687 - val_loss: 113823.0040\n",
      "Epoch 1322/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 41942.8461 - val_loss: 113772.3015\n",
      "Epoch 1323/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 41914.3344 - val_loss: 113721.6124\n",
      "Epoch 1324/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 41885.8291 - val_loss: 113670.9303\n",
      "Epoch 1325/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 41857.3382 - val_loss: 113620.2638\n",
      "Epoch 1326/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 41828.8585 - val_loss: 113569.6042\n",
      "Epoch 1327/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 41800.3887 - val_loss: 113518.9628\n",
      "Epoch 1328/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 41771.9298 - val_loss: 113468.3267\n",
      "Epoch 1329/2000\n",
      "534/534 [==============================] - 0s 127us/step - loss: 41743.4811 - val_loss: 113417.7169\n",
      "Epoch 1330/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 41715.0448 - val_loss: 113367.1110\n",
      "Epoch 1331/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 41686.6174 - val_loss: 113316.5244\n",
      "Epoch 1332/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 41658.2028 - val_loss: 113265.9499\n",
      "Epoch 1333/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 41629.7990 - val_loss: 113215.3842\n",
      "Epoch 1334/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 41601.4027 - val_loss: 113164.8159\n",
      "Epoch 1335/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 41573.0186 - val_loss: 113114.2765\n",
      "Epoch 1336/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 41544.6440 - val_loss: 113063.7539\n",
      "Epoch 1337/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 41516.2805 - val_loss: 113013.2221\n",
      "Epoch 1338/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 41487.9280 - val_loss: 112962.7136\n",
      "Epoch 1339/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 41459.5841 - val_loss: 112912.2288\n",
      "Epoch 1340/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 41431.2526 - val_loss: 112861.7451\n",
      "Epoch 1341/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 41402.9305 - val_loss: 112811.2864\n",
      "Epoch 1342/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 41374.6206 - val_loss: 112760.8301\n",
      "Epoch 1343/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 41346.3203 - val_loss: 112710.3808\n",
      "Epoch 1344/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 41318.0305 - val_loss: 112659.9537\n",
      "Epoch 1345/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 41289.7519 - val_loss: 112609.5241\n",
      "Epoch 1346/2000\n",
      "534/534 [==============================] - 0s 133us/step - loss: 41261.4833 - val_loss: 112559.1214\n",
      "Epoch 1347/2000\n",
      "534/534 [==============================] - 0s 124us/step - loss: 41233.2251 - val_loss: 112508.7265\n",
      "Epoch 1348/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 41204.9768 - val_loss: 112458.3442\n",
      "Epoch 1349/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 41176.7394 - val_loss: 112407.9589\n",
      "Epoch 1350/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 41148.5119 - val_loss: 112357.6188\n",
      "Epoch 1351/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 41120.2959 - val_loss: 112307.2557\n",
      "Epoch 1352/2000\n",
      "534/534 [==============================] - 0s 127us/step - loss: 41092.0844 - val_loss: 112256.9177\n",
      "Epoch 1353/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 41063.8845 - val_loss: 112206.5855\n",
      "Epoch 1354/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 41035.6941 - val_loss: 112156.2751\n",
      "Epoch 1355/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 41007.5157 - val_loss: 112105.9662\n",
      "Epoch 1356/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 40979.3468 - val_loss: 112055.6651\n",
      "Epoch 1357/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 40951.1897 - val_loss: 112005.3813\n",
      "Epoch 1358/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 40923.0394 - val_loss: 111955.1073\n",
      "Epoch 1359/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 40894.9013 - val_loss: 111904.8530\n",
      "Epoch 1360/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 40866.7708 - val_loss: 111854.6007\n",
      "Epoch 1361/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 40838.6529 - val_loss: 111804.3690\n",
      "Epoch 1362/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 40810.5454 - val_loss: 111754.1253\n",
      "Epoch 1363/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 40782.4462 - val_loss: 111703.9196\n",
      "Epoch 1364/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 40754.3600 - val_loss: 111653.7211\n",
      "Epoch 1365/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 40726.2867 - val_loss: 111603.5471\n",
      "Epoch 1366/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 40698.2244 - val_loss: 111553.3863\n",
      "Epoch 1367/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 40670.1757 - val_loss: 111503.2287\n",
      "Epoch 1368/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 40642.1396 - val_loss: 111453.0917\n",
      "Epoch 1369/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 40614.1111 - val_loss: 111402.9730\n",
      "Epoch 1370/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 40586.0940 - val_loss: 111352.8526\n",
      "Epoch 1371/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 40558.0881 - val_loss: 111302.7440\n",
      "Epoch 1372/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 40530.0895 - val_loss: 111252.6617\n",
      "Epoch 1373/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 40502.1038 - val_loss: 111202.5714\n",
      "Epoch 1374/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 40474.1258 - val_loss: 111152.5048\n",
      "Epoch 1375/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 40446.1612 - val_loss: 111102.4498\n",
      "Epoch 1376/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 40418.2042 - val_loss: 111052.4015\n",
      "Epoch 1377/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 40390.2602 - val_loss: 111002.3726\n",
      "Epoch 1378/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 40362.3282 - val_loss: 110952.3579\n",
      "Epoch 1379/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 40334.4054 - val_loss: 110902.3565\n",
      "Epoch 1380/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 40306.4929 - val_loss: 110852.3649\n",
      "Epoch 1381/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 40278.5936 - val_loss: 110802.3934\n",
      "Epoch 1382/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 40250.7040 - val_loss: 110752.4368\n",
      "Epoch 1383/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 40222.8251 - val_loss: 110702.4705\n",
      "Epoch 1384/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 40194.9563 - val_loss: 110652.5279\n",
      "Epoch 1385/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 40167.0983 - val_loss: 110602.6066\n",
      "Epoch 1386/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 40139.2500 - val_loss: 110552.6847\n",
      "Epoch 1387/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 40111.4115 - val_loss: 110502.7749\n",
      "Epoch 1388/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 40083.5830 - val_loss: 110452.8833\n",
      "Epoch 1389/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 40055.7652 - val_loss: 110402.9951\n",
      "Epoch 1390/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 40027.9580 - val_loss: 110353.1293\n",
      "Epoch 1391/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 40000.1598 - val_loss: 110303.2662\n",
      "Epoch 1392/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 39972.3713 - val_loss: 110253.4199\n",
      "Epoch 1393/2000\n",
      "534/534 [==============================] - 0s 119us/step - loss: 39944.5947 - val_loss: 110203.5885\n",
      "Epoch 1394/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 39916.8286 - val_loss: 110153.7616\n",
      "Epoch 1395/2000\n",
      "534/534 [==============================] - 0s 160us/step - loss: 39889.0733 - val_loss: 110103.9514\n",
      "Epoch 1396/2000\n",
      "534/534 [==============================] - 0s 149us/step - loss: 39861.3289 - val_loss: 110054.1491\n",
      "Epoch 1397/2000\n",
      "534/534 [==============================] - 0s 139us/step - loss: 39833.5939 - val_loss: 110004.3688\n",
      "Epoch 1398/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 39805.8724 - val_loss: 109954.6041\n",
      "Epoch 1399/2000\n",
      "534/534 [==============================] - 0s 131us/step - loss: 39778.1610 - val_loss: 109904.8432\n",
      "Epoch 1400/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 39750.4611 - val_loss: 109855.0897\n",
      "Epoch 1401/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 39722.7706 - val_loss: 109805.3591\n",
      "Epoch 1402/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 39695.0889 - val_loss: 109755.6440\n",
      "Epoch 1403/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 39667.4188 - val_loss: 109705.9275\n",
      "Epoch 1404/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 39639.7585 - val_loss: 109656.2234\n",
      "Epoch 1405/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 39612.1094 - val_loss: 109606.5434\n",
      "Epoch 1406/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 39584.4672 - val_loss: 109556.8695\n",
      "Epoch 1407/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 39556.8372 - val_loss: 109507.1916\n",
      "Epoch 1408/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 39529.2180 - val_loss: 109457.5392\n",
      "Epoch 1409/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 39501.6077 - val_loss: 109407.9058\n",
      "Epoch 1410/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 39474.0082 - val_loss: 109358.2746\n",
      "Epoch 1411/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 39446.4192 - val_loss: 109308.6532\n",
      "Epoch 1412/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 39418.8432 - val_loss: 109259.0440\n",
      "Epoch 1413/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 39391.2760 - val_loss: 109209.4508\n",
      "Epoch 1414/2000\n",
      "534/534 [==============================] - 0s 122us/step - loss: 39363.7188 - val_loss: 109159.8724\n",
      "Epoch 1415/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 39336.1728 - val_loss: 109110.3106\n",
      "Epoch 1416/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 39308.6377 - val_loss: 109060.7471\n",
      "Epoch 1417/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 39281.1148 - val_loss: 109011.2124\n",
      "Epoch 1418/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 39253.6026 - val_loss: 108961.6862\n",
      "Epoch 1419/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 39226.1007 - val_loss: 108912.1791\n",
      "Epoch 1420/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 39198.6085 - val_loss: 108862.6713\n",
      "Epoch 1421/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 39171.1274 - val_loss: 108813.1805\n",
      "Epoch 1422/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 39143.6559 - val_loss: 108763.7138\n",
      "Epoch 1423/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 39116.1964 - val_loss: 108714.2379\n",
      "Epoch 1424/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 39088.7498 - val_loss: 108664.7857\n",
      "Epoch 1425/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 39061.3105 - val_loss: 108615.3448\n",
      "Epoch 1426/2000\n",
      "534/534 [==============================] - 0s 151us/step - loss: 39033.8830 - val_loss: 108565.9221\n",
      "Epoch 1427/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 39006.4661 - val_loss: 108516.5019\n",
      "Epoch 1428/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 38979.0619 - val_loss: 108467.0976\n",
      "Epoch 1429/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 38951.6629 - val_loss: 108417.7215\n",
      "Epoch 1430/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 38924.2785 - val_loss: 108368.3360\n",
      "Epoch 1431/2000\n",
      "534/534 [==============================] - 0s 122us/step - loss: 38896.9041 - val_loss: 108318.9686\n",
      "Epoch 1432/2000\n",
      "534/534 [==============================] - 0s 134us/step - loss: 38869.5379 - val_loss: 108269.6137\n",
      "Epoch 1433/2000\n",
      "534/534 [==============================] - 0s 122us/step - loss: 38842.1826 - val_loss: 108220.2794\n",
      "Epoch 1434/2000\n",
      "534/534 [==============================] - 0s 119us/step - loss: 38814.8373 - val_loss: 108170.9418\n",
      "Epoch 1435/2000\n",
      "534/534 [==============================] - 0s 131us/step - loss: 38787.5025 - val_loss: 108121.6173\n",
      "Epoch 1436/2000\n",
      "534/534 [==============================] - 0s 140us/step - loss: 38760.1779 - val_loss: 108072.3082\n",
      "Epoch 1437/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 38732.8629 - val_loss: 108023.0172\n",
      "Epoch 1438/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 38705.5566 - val_loss: 107973.7336\n",
      "Epoch 1439/2000\n",
      "534/534 [==============================] - 0s 123us/step - loss: 38678.2651 - val_loss: 107924.4611\n",
      "Epoch 1440/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 38650.9827 - val_loss: 107875.2013\n",
      "Epoch 1441/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 38623.7114 - val_loss: 107825.9486\n",
      "Epoch 1442/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 38596.4486 - val_loss: 107776.7201\n",
      "Epoch 1443/2000\n",
      "534/534 [==============================] - 0s 125us/step - loss: 38569.1970 - val_loss: 107727.4961\n",
      "Epoch 1444/2000\n",
      "534/534 [==============================] - 0s 126us/step - loss: 38541.9551 - val_loss: 107678.2826\n",
      "Epoch 1445/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 38514.7255 - val_loss: 107629.0727\n",
      "Epoch 1446/2000\n",
      "534/534 [==============================] - 0s 125us/step - loss: 38487.5023 - val_loss: 107579.8912\n",
      "Epoch 1447/2000\n",
      "534/534 [==============================] - 0s 145us/step - loss: 38460.2926 - val_loss: 107530.7119\n",
      "Epoch 1448/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 38433.0915 - val_loss: 107481.5498\n",
      "Epoch 1449/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 38405.9004 - val_loss: 107432.3899\n",
      "Epoch 1450/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 38378.7219 - val_loss: 107383.2505\n",
      "Epoch 1451/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 38351.5554 - val_loss: 107334.1345\n",
      "Epoch 1452/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 38324.3995 - val_loss: 107285.0113\n",
      "Epoch 1453/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 38297.2515 - val_loss: 107235.9224\n",
      "Epoch 1454/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 38270.1166 - val_loss: 107186.8288\n",
      "Epoch 1455/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 38242.9911 - val_loss: 107137.7495\n",
      "Epoch 1456/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 38215.8781 - val_loss: 107088.6865\n",
      "Epoch 1457/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 38188.7748 - val_loss: 107039.6486\n",
      "Epoch 1458/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 38161.6852 - val_loss: 106990.6096\n",
      "Epoch 1459/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 38134.6044 - val_loss: 106941.5893\n",
      "Epoch 1460/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 38107.5332 - val_loss: 106892.5714\n",
      "Epoch 1461/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 38080.4715 - val_loss: 106843.5752\n",
      "Epoch 1462/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 38053.4206 - val_loss: 106794.5918\n",
      "Epoch 1463/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 38026.3819 - val_loss: 106745.6038\n",
      "Epoch 1464/2000\n",
      "534/534 [==============================] - 0s 203us/step - loss: 37999.3508 - val_loss: 106696.6436\n",
      "Epoch 1465/2000\n",
      "534/534 [==============================] - 0s 121us/step - loss: 37972.3313 - val_loss: 106647.6897\n",
      "Epoch 1466/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 37945.3198 - val_loss: 106598.7529\n",
      "Epoch 1467/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 37918.3199 - val_loss: 106549.8100\n",
      "Epoch 1468/2000\n",
      "534/534 [==============================] - 0s 123us/step - loss: 37891.3306 - val_loss: 106500.8862\n",
      "Epoch 1469/2000\n",
      "534/534 [==============================] - 0s 120us/step - loss: 37864.3522 - val_loss: 106451.9820\n",
      "Epoch 1470/2000\n",
      "534/534 [==============================] - 0s 123us/step - loss: 37837.3826 - val_loss: 106403.0980\n",
      "Epoch 1471/2000\n",
      "534/534 [==============================] - 0s 124us/step - loss: 37810.4253 - val_loss: 106354.2165\n",
      "Epoch 1472/2000\n",
      "534/534 [==============================] - 0s 129us/step - loss: 37783.4767 - val_loss: 106305.3383\n",
      "Epoch 1473/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 37756.5379 - val_loss: 106256.4750\n",
      "Epoch 1474/2000\n",
      "534/534 [==============================] - 0s 141us/step - loss: 37729.6090 - val_loss: 106207.6353\n",
      "Epoch 1475/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 37702.6926 - val_loss: 106158.7931\n",
      "Epoch 1476/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 37675.7877 - val_loss: 106109.9780\n",
      "Epoch 1477/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 37648.8922 - val_loss: 106061.1764\n",
      "Epoch 1478/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 37622.0080 - val_loss: 106012.3767\n",
      "Epoch 1479/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 37595.1317 - val_loss: 105963.5866\n",
      "Epoch 1480/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 37568.2690 - val_loss: 105914.8285\n",
      "Epoch 1481/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 37541.4207 - val_loss: 105866.0725\n",
      "Epoch 1482/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 37514.5797 - val_loss: 105817.3258\n",
      "Epoch 1483/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 37487.7511 - val_loss: 105768.6004\n",
      "Epoch 1484/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 37460.9318 - val_loss: 105719.8890\n",
      "Epoch 1485/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 37434.1246 - val_loss: 105671.1841\n",
      "Epoch 1486/2000\n",
      "534/534 [==============================] - 0s 127us/step - loss: 37407.3289 - val_loss: 105622.4875\n",
      "Epoch 1487/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 37380.5441 - val_loss: 105573.8141\n",
      "Epoch 1488/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 37353.7680 - val_loss: 105525.1418\n",
      "Epoch 1489/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 37327.0053 - val_loss: 105476.4967\n",
      "Epoch 1490/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 37300.2519 - val_loss: 105427.8586\n",
      "Epoch 1491/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 37273.5087 - val_loss: 105379.2253\n",
      "Epoch 1492/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 37246.7743 - val_loss: 105330.6161\n",
      "Epoch 1493/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 37220.0538 - val_loss: 105282.0165\n",
      "Epoch 1494/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 37193.3440 - val_loss: 105233.4277\n",
      "Epoch 1495/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 37166.6438 - val_loss: 105184.8521\n",
      "Epoch 1496/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 37139.9561 - val_loss: 105136.2894\n",
      "Epoch 1497/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 37113.2776 - val_loss: 105087.7360\n",
      "Epoch 1498/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 37086.6111 - val_loss: 105039.2036\n",
      "Epoch 1499/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 37059.9581 - val_loss: 104990.6836\n",
      "Epoch 1500/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 37033.3157 - val_loss: 104942.1766\n",
      "Epoch 1501/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 37006.6835 - val_loss: 104893.6761\n",
      "Epoch 1502/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 36980.0619 - val_loss: 104845.2045\n",
      "Epoch 1503/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 36953.4518 - val_loss: 104796.7287\n",
      "Epoch 1504/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 36926.8492 - val_loss: 104748.2672\n",
      "Epoch 1505/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 36900.2580 - val_loss: 104699.8263\n",
      "Epoch 1506/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 36873.6756 - val_loss: 104651.3848\n",
      "Epoch 1507/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 36847.1052 - val_loss: 104602.9580\n",
      "Epoch 1508/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 36820.5447 - val_loss: 104554.5415\n",
      "Epoch 1509/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 36793.9929 - val_loss: 104506.1426\n",
      "Epoch 1510/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 36767.4522 - val_loss: 104457.7478\n",
      "Epoch 1511/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 36740.9219 - val_loss: 104409.3752\n",
      "Epoch 1512/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 36714.4008 - val_loss: 104361.0090\n",
      "Epoch 1513/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 36687.8899 - val_loss: 104312.6485\n",
      "Epoch 1514/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 36661.3920 - val_loss: 104264.3118\n",
      "Epoch 1515/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 36634.9053 - val_loss: 104215.9867\n",
      "Epoch 1516/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 36608.4319 - val_loss: 104167.6690\n",
      "Epoch 1517/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 36581.9655 - val_loss: 104119.3808\n",
      "Epoch 1518/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 36555.5110 - val_loss: 104071.0860\n",
      "Epoch 1519/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 36529.0639 - val_loss: 104022.8035\n",
      "Epoch 1520/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 36502.6286 - val_loss: 103974.5379\n",
      "Epoch 1521/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 36476.1997 - val_loss: 103926.2829\n",
      "Epoch 1522/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 36449.7861 - val_loss: 103878.0364\n",
      "Epoch 1523/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 36423.3806 - val_loss: 103829.7958\n",
      "Epoch 1524/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 36396.9847 - val_loss: 103781.5753\n",
      "Epoch 1525/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 36370.6021 - val_loss: 103733.3784\n",
      "Epoch 1526/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 36344.2241 - val_loss: 103685.1656\n",
      "Epoch 1527/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 36317.8611 - val_loss: 103636.9874\n",
      "Epoch 1528/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 36291.5080 - val_loss: 103588.8191\n",
      "Epoch 1529/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 36265.1680 - val_loss: 103540.6673\n",
      "Epoch 1530/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 36238.8364 - val_loss: 103492.5200\n",
      "Epoch 1531/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 36212.5157 - val_loss: 103444.3866\n",
      "Epoch 1532/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 36186.2040 - val_loss: 103396.2676\n",
      "Epoch 1533/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 36159.9046 - val_loss: 103348.1475\n",
      "Epoch 1534/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 36133.6135 - val_loss: 103300.0629\n",
      "Epoch 1535/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 36107.3321 - val_loss: 103251.9624\n",
      "Epoch 1536/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 36081.0619 - val_loss: 103203.8999\n",
      "Epoch 1537/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 36054.8038 - val_loss: 103155.8243\n",
      "Epoch 1538/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 36028.5535 - val_loss: 103107.7854\n",
      "Epoch 1539/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 36002.3144 - val_loss: 103059.7408\n",
      "Epoch 1540/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 35976.0851 - val_loss: 103011.7216\n",
      "Epoch 1541/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 35949.8685 - val_loss: 102963.7187\n",
      "Epoch 1542/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 35923.6630 - val_loss: 102915.7109\n",
      "Epoch 1543/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 35897.4659 - val_loss: 102867.7148\n",
      "Epoch 1544/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 35871.2798 - val_loss: 102819.7437\n",
      "Epoch 1545/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 35845.1046 - val_loss: 102771.7806\n",
      "Epoch 1546/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 35818.9399 - val_loss: 102723.8405\n",
      "Epoch 1547/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 35792.7868 - val_loss: 102675.8904\n",
      "Epoch 1548/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 35766.6434 - val_loss: 102627.9643\n",
      "Epoch 1549/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 35740.5099 - val_loss: 102580.0603\n",
      "Epoch 1550/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 35714.3880 - val_loss: 102532.1523\n",
      "Epoch 1551/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 35688.2774 - val_loss: 102484.2698\n",
      "Epoch 1552/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 35662.1786 - val_loss: 102436.3885\n",
      "Epoch 1553/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 35636.0862 - val_loss: 102388.5285\n",
      "Epoch 1554/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 35610.0057 - val_loss: 102340.6720\n",
      "Epoch 1555/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 35583.9358 - val_loss: 102292.8336\n",
      "Epoch 1556/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 35557.8775 - val_loss: 102245.0096\n",
      "Epoch 1557/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 35531.8301 - val_loss: 102197.1955\n",
      "Epoch 1558/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 35505.7915 - val_loss: 102149.3900\n",
      "Epoch 1559/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 35479.7627 - val_loss: 102101.5985\n",
      "Epoch 1560/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 35453.7458 - val_loss: 102053.8194\n",
      "Epoch 1561/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 35427.7380 - val_loss: 102006.0503\n",
      "Epoch 1562/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 35401.7399 - val_loss: 101958.2888\n",
      "Epoch 1563/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 35375.7528 - val_loss: 101910.5484\n",
      "Epoch 1564/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 35349.7745 - val_loss: 101862.8091\n",
      "Epoch 1565/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 35323.8089 - val_loss: 101815.0729\n",
      "Epoch 1566/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 35297.8519 - val_loss: 101767.3767\n",
      "Epoch 1567/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 35271.9039 - val_loss: 101719.6784\n",
      "Epoch 1568/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 35245.9692 - val_loss: 101671.9905\n",
      "Epoch 1569/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 35220.0433 - val_loss: 101624.3204\n",
      "Epoch 1570/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 35194.1282 - val_loss: 101576.6550\n",
      "Epoch 1571/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 35168.2242 - val_loss: 101529.0116\n",
      "Epoch 1572/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 35142.3303 - val_loss: 101481.3682\n",
      "Epoch 1573/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 35116.4470 - val_loss: 101433.7498\n",
      "Epoch 1574/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 35090.5737 - val_loss: 101386.1307\n",
      "Epoch 1575/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 35064.7098 - val_loss: 101338.5240\n",
      "Epoch 1576/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 35038.8554 - val_loss: 101290.9379\n",
      "Epoch 1577/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 35013.0160 - val_loss: 101243.3615\n",
      "Epoch 1578/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 34987.1911 - val_loss: 101195.8202\n",
      "Epoch 1579/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 34961.3749 - val_loss: 101148.2749\n",
      "Epoch 1580/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 34935.5702 - val_loss: 101100.7544\n",
      "Epoch 1581/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 34909.7771 - val_loss: 101053.2333\n",
      "Epoch 1582/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 34883.9949 - val_loss: 101005.7268\n",
      "Epoch 1583/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 34858.2217 - val_loss: 100958.2448\n",
      "Epoch 1584/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 34832.4595 - val_loss: 100910.7553\n",
      "Epoch 1585/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 34806.7050 - val_loss: 100863.2942\n",
      "Epoch 1586/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 34780.9637 - val_loss: 100815.8407\n",
      "Epoch 1587/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 34755.2333 - val_loss: 100768.3877\n",
      "Epoch 1588/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 34729.5127 - val_loss: 100720.9684\n",
      "Epoch 1589/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 34703.8021 - val_loss: 100673.5434\n",
      "Epoch 1590/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 34678.1021 - val_loss: 100626.1377\n",
      "Epoch 1591/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 34652.4123 - val_loss: 100578.7507\n",
      "Epoch 1592/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 34626.7326 - val_loss: 100531.3576\n",
      "Epoch 1593/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 34601.0639 - val_loss: 100483.9947\n",
      "Epoch 1594/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 34575.4046 - val_loss: 100436.6231\n",
      "Epoch 1595/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 34549.7567 - val_loss: 100389.2872\n",
      "Epoch 1596/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 34524.1184 - val_loss: 100341.9467\n",
      "Epoch 1597/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 34498.4920 - val_loss: 100294.6284\n",
      "Epoch 1598/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 34472.8749 - val_loss: 100247.3146\n",
      "Epoch 1599/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 34447.2676 - val_loss: 100200.0252\n",
      "Epoch 1600/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 34421.6704 - val_loss: 100152.7336\n",
      "Epoch 1601/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 34396.0845 - val_loss: 100105.4723\n",
      "Epoch 1602/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 34370.5064 - val_loss: 100058.2027\n",
      "Epoch 1603/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 34344.9417 - val_loss: 100010.9473\n",
      "Epoch 1604/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 34319.3854 - val_loss: 99963.7220\n",
      "Epoch 1605/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 34293.8438 - val_loss: 99916.5049\n",
      "Epoch 1606/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 34268.3128 - val_loss: 99869.2919\n",
      "Epoch 1607/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 34242.7915 - val_loss: 99822.0965\n",
      "Epoch 1608/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 34217.2819 - val_loss: 99774.9164\n",
      "Epoch 1609/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 34191.7841 - val_loss: 99727.7488\n",
      "Epoch 1610/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 34166.2952 - val_loss: 99680.5919\n",
      "Epoch 1611/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 34140.8148 - val_loss: 99633.4424\n",
      "Epoch 1612/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 34115.3460 - val_loss: 99586.3103\n",
      "Epoch 1613/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 34089.8839 - val_loss: 99539.1742\n",
      "Epoch 1614/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 34064.4340 - val_loss: 99492.0673\n",
      "Epoch 1615/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 34038.9944 - val_loss: 99444.9643\n",
      "Epoch 1616/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 34013.5651 - val_loss: 99397.8653\n",
      "Epoch 1617/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 33988.1459 - val_loss: 99350.7857\n",
      "Epoch 1618/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 33962.7378 - val_loss: 99303.7320\n",
      "Epoch 1619/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 33937.3414 - val_loss: 99256.6841\n",
      "Epoch 1620/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 33911.9570 - val_loss: 99209.6419\n",
      "Epoch 1621/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 33886.5838 - val_loss: 99162.6192\n",
      "Epoch 1622/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 33861.2204 - val_loss: 99115.6071\n",
      "Epoch 1623/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 33835.8689 - val_loss: 99068.6221\n",
      "Epoch 1624/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 33810.5273 - val_loss: 99021.6426\n",
      "Epoch 1625/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 33785.1961 - val_loss: 98974.6629\n",
      "Epoch 1626/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 33759.8737 - val_loss: 98927.7005\n",
      "Epoch 1627/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 33734.5631 - val_loss: 98880.7488\n",
      "Epoch 1628/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 33709.2620 - val_loss: 98833.8071\n",
      "Epoch 1629/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 33683.9718 - val_loss: 98786.8764\n",
      "Epoch 1630/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 33658.6913 - val_loss: 98739.9782\n",
      "Epoch 1631/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 33633.4206 - val_loss: 98693.0673\n",
      "Epoch 1632/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 33608.1595 - val_loss: 98646.1730\n",
      "Epoch 1633/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 33582.9106 - val_loss: 98599.2858\n",
      "Epoch 1634/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 33557.6692 - val_loss: 98552.4261\n",
      "Epoch 1635/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 33532.4437 - val_loss: 98505.5832\n",
      "Epoch 1636/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 33507.2293 - val_loss: 98458.7401\n",
      "Epoch 1637/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 33482.0261 - val_loss: 98411.9315\n",
      "Epoch 1638/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 33456.8342 - val_loss: 98365.1114\n",
      "Epoch 1639/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 33431.6533 - val_loss: 98318.3262\n",
      "Epoch 1640/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 33406.4837 - val_loss: 98271.5419\n",
      "Epoch 1641/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 33381.3236 - val_loss: 98224.7700\n",
      "Epoch 1642/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 33356.1742 - val_loss: 98178.0109\n",
      "Epoch 1643/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 33331.0345 - val_loss: 98131.2572\n",
      "Epoch 1644/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 33305.9079 - val_loss: 98084.5280\n",
      "Epoch 1645/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 33280.7889 - val_loss: 98037.8133\n",
      "Epoch 1646/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 33255.6826 - val_loss: 97991.1081\n",
      "Epoch 1647/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 33230.5862 - val_loss: 97944.4102\n",
      "Epoch 1648/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 33205.5007 - val_loss: 97897.7351\n",
      "Epoch 1649/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 33180.4248 - val_loss: 97851.0623\n",
      "Epoch 1650/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 33155.3621 - val_loss: 97804.3977\n",
      "Epoch 1651/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 33130.3120 - val_loss: 97757.7565\n",
      "Epoch 1652/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 33105.2684 - val_loss: 97711.1299\n",
      "Epoch 1653/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 33080.2360 - val_loss: 97664.5101\n",
      "Epoch 1654/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 33055.2141 - val_loss: 97617.9040\n",
      "Epoch 1655/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 33030.2013 - val_loss: 97571.3094\n",
      "Epoch 1656/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 33005.2005 - val_loss: 97524.7191\n",
      "Epoch 1657/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 32980.2074 - val_loss: 97478.1405\n",
      "Epoch 1658/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 32955.2252 - val_loss: 97431.5855\n",
      "Epoch 1659/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 32930.2537 - val_loss: 97385.0455\n",
      "Epoch 1660/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 32905.2939 - val_loss: 97338.4995\n",
      "Epoch 1661/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 32880.3451 - val_loss: 97291.9797\n",
      "Epoch 1662/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 32855.4054 - val_loss: 97245.4667\n",
      "Epoch 1663/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 32830.4785 - val_loss: 97198.9824\n",
      "Epoch 1664/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 32805.5609 - val_loss: 97152.4911\n",
      "Epoch 1665/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 32780.6551 - val_loss: 97106.0271\n",
      "Epoch 1666/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 32755.7572 - val_loss: 97059.5606\n",
      "Epoch 1667/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 32730.8723 - val_loss: 97013.1000\n",
      "Epoch 1668/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 32705.9949 - val_loss: 96966.6720\n",
      "Epoch 1669/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 32681.1303 - val_loss: 96920.2399\n",
      "Epoch 1670/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 32656.2738 - val_loss: 96873.8349\n",
      "Epoch 1671/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 32631.4297 - val_loss: 96827.4341\n",
      "Epoch 1672/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 32606.5937 - val_loss: 96781.0405\n",
      "Epoch 1673/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 32581.7700 - val_loss: 96734.6735\n",
      "Epoch 1674/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 32556.9588 - val_loss: 96688.3101\n",
      "Epoch 1675/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 32532.1548 - val_loss: 96641.9553\n",
      "Epoch 1676/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 32507.3617 - val_loss: 96595.6191\n",
      "Epoch 1677/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 32482.5787 - val_loss: 96549.2863\n",
      "Epoch 1678/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 32457.8054 - val_loss: 96502.9722\n",
      "Epoch 1679/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 32433.0438 - val_loss: 96456.6699\n",
      "Epoch 1680/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 32408.2913 - val_loss: 96410.3736\n",
      "Epoch 1681/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 32383.5479 - val_loss: 96364.0834\n",
      "Epoch 1682/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 32358.8144 - val_loss: 96317.8169\n",
      "Epoch 1683/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 32334.0945 - val_loss: 96271.5615\n",
      "Epoch 1684/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 32309.3871 - val_loss: 96225.3272\n",
      "Epoch 1685/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 32284.6894 - val_loss: 96179.0938\n",
      "Epoch 1686/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 32260.0012 - val_loss: 96132.8793\n",
      "Epoch 1687/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 32235.3242 - val_loss: 96086.6691\n",
      "Epoch 1688/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 32210.6562 - val_loss: 96040.4797\n",
      "Epoch 1689/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 32186.0003 - val_loss: 95994.3034\n",
      "Epoch 1690/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 32161.3528 - val_loss: 95948.1240\n",
      "Epoch 1691/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 32136.7172 - val_loss: 95901.9723\n",
      "Epoch 1692/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 32112.0934 - val_loss: 95855.8369\n",
      "Epoch 1693/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 32087.4807 - val_loss: 95809.7189\n",
      "Epoch 1694/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 32062.8781 - val_loss: 95763.5954\n",
      "Epoch 1695/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 32038.2865 - val_loss: 95717.4952\n",
      "Epoch 1696/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 32013.7035 - val_loss: 95671.4054\n",
      "Epoch 1697/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31989.1334 - val_loss: 95625.3152\n",
      "Epoch 1698/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 31964.5704 - val_loss: 95579.2449\n",
      "Epoch 1699/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 31940.0180 - val_loss: 95533.1894\n",
      "Epoch 1700/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 31915.4737 - val_loss: 95487.1374\n",
      "Epoch 1701/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31890.9397 - val_loss: 95441.0975\n",
      "Epoch 1702/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31866.4150 - val_loss: 95395.0711\n",
      "Epoch 1703/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 31841.8999 - val_loss: 95349.0562\n",
      "Epoch 1704/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 31817.3940 - val_loss: 95303.0411\n",
      "Epoch 1705/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 31792.9007 - val_loss: 95257.0613\n",
      "Epoch 1706/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31768.4193 - val_loss: 95211.0836\n",
      "Epoch 1707/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 31743.9469 - val_loss: 95165.1120\n",
      "Epoch 1708/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31719.4852 - val_loss: 95119.1684\n",
      "Epoch 1709/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31695.0332 - val_loss: 95073.2213\n",
      "Epoch 1710/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31670.5941 - val_loss: 95027.3022\n",
      "Epoch 1711/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 31646.1618 - val_loss: 94981.3777\n",
      "Epoch 1712/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 31621.7436 - val_loss: 94935.4674\n",
      "Epoch 1713/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 31597.3335 - val_loss: 94889.5776\n",
      "Epoch 1714/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 31572.9330 - val_loss: 94843.6955\n",
      "Epoch 1715/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 31548.5442 - val_loss: 94797.8220\n",
      "Epoch 1716/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 31524.1638 - val_loss: 94751.9733\n",
      "Epoch 1717/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 31499.7959 - val_loss: 94706.1225\n",
      "Epoch 1718/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31475.4399 - val_loss: 94660.3051\n",
      "Epoch 1719/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 31451.0957 - val_loss: 94614.4744\n",
      "Epoch 1720/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 31426.7613 - val_loss: 94568.6815\n",
      "Epoch 1721/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31402.4394 - val_loss: 94522.8953\n",
      "Epoch 1722/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 31378.1270 - val_loss: 94477.1154\n",
      "Epoch 1723/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 31353.8248 - val_loss: 94431.3469\n",
      "Epoch 1724/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 31329.5329 - val_loss: 94385.5975\n",
      "Epoch 1725/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 31305.2520 - val_loss: 94339.8495\n",
      "Epoch 1726/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 31280.9793 - val_loss: 94294.1207\n",
      "Epoch 1727/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 31256.7172 - val_loss: 94248.4042\n",
      "Epoch 1728/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31232.4673 - val_loss: 94202.6999\n",
      "Epoch 1729/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31208.2264 - val_loss: 94157.0089\n",
      "Epoch 1730/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31183.9984 - val_loss: 94111.3277\n",
      "Epoch 1731/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31159.7797 - val_loss: 94065.6537\n",
      "Epoch 1732/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31135.5716 - val_loss: 94020.0070\n",
      "Epoch 1733/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31111.3735 - val_loss: 93974.3687\n",
      "Epoch 1734/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 31087.1872 - val_loss: 93928.7384\n",
      "Epoch 1735/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 31063.0102 - val_loss: 93883.1077\n",
      "Epoch 1736/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 31038.8434 - val_loss: 93837.5122\n",
      "Epoch 1737/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 31014.6885 - val_loss: 93791.9111\n",
      "Epoch 1738/2000\n",
      "534/534 [==============================] - 0s 123us/step - loss: 30990.5402 - val_loss: 93746.3358\n",
      "Epoch 1739/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 30966.4051 - val_loss: 93700.7638\n",
      "Epoch 1740/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 30942.2785 - val_loss: 93655.1975\n",
      "Epoch 1741/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 30918.1627 - val_loss: 93609.6689\n",
      "Epoch 1742/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 30894.0572 - val_loss: 93564.1283\n",
      "Epoch 1743/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 30869.9619 - val_loss: 93518.6021\n",
      "Epoch 1744/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 30845.8806 - val_loss: 93473.1035\n",
      "Epoch 1745/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 30821.8094 - val_loss: 93427.6007\n",
      "Epoch 1746/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 30797.7482 - val_loss: 93382.1312\n",
      "Epoch 1747/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 30773.6982 - val_loss: 93336.6612\n",
      "Epoch 1748/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 30749.6596 - val_loss: 93291.2042\n",
      "Epoch 1749/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 30725.6304 - val_loss: 93245.7542\n",
      "Epoch 1750/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 30701.6124 - val_loss: 93200.3234\n",
      "Epoch 1751/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 30677.6033 - val_loss: 93154.9195\n",
      "Epoch 1752/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 30653.6034 - val_loss: 93109.4954\n",
      "Epoch 1753/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 30629.6148 - val_loss: 93064.0963\n",
      "Epoch 1754/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 30605.6377 - val_loss: 93018.7122\n",
      "Epoch 1755/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 30581.6680 - val_loss: 92973.3429\n",
      "Epoch 1756/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 30557.7120 - val_loss: 92927.9934\n",
      "Epoch 1757/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 30533.7673 - val_loss: 92882.6412\n",
      "Epoch 1758/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 30509.8312 - val_loss: 92837.3091\n",
      "Epoch 1759/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 30485.9060 - val_loss: 92791.9850\n",
      "Epoch 1760/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 30461.9927 - val_loss: 92746.6838\n",
      "Epoch 1761/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 30438.0891 - val_loss: 92701.3927\n",
      "Epoch 1762/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 30414.1977 - val_loss: 92656.1049\n",
      "Epoch 1763/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 30390.3148 - val_loss: 92610.8381\n",
      "Epoch 1764/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 30366.4412 - val_loss: 92565.5801\n",
      "Epoch 1765/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 30342.5795 - val_loss: 92520.3225\n",
      "Epoch 1766/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 30318.7281 - val_loss: 92475.0991\n",
      "Epoch 1767/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 30294.8911 - val_loss: 92429.8856\n",
      "Epoch 1768/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 30271.0638 - val_loss: 92384.6740\n",
      "Epoch 1769/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 30247.2455 - val_loss: 92339.4744\n",
      "Epoch 1770/2000\n",
      "534/534 [==============================] - 0s 119us/step - loss: 30223.4390 - val_loss: 92294.3050\n",
      "Epoch 1771/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 30199.6431 - val_loss: 92249.1366\n",
      "Epoch 1772/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 30175.8594 - val_loss: 92203.9754\n",
      "Epoch 1773/2000\n",
      "534/534 [==============================] - 0s 123us/step - loss: 30152.0855 - val_loss: 92158.8446\n",
      "Epoch 1774/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 30128.3237 - val_loss: 92113.7181\n",
      "Epoch 1775/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 30104.5707 - val_loss: 92068.6035\n",
      "Epoch 1776/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 30080.8274 - val_loss: 92023.4937\n",
      "Epoch 1777/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 30057.0964 - val_loss: 91978.4058\n",
      "Epoch 1778/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 30033.3754 - val_loss: 91933.3252\n",
      "Epoch 1779/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 30009.6631 - val_loss: 91888.2552\n",
      "Epoch 1780/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 29985.9614 - val_loss: 91843.2046\n",
      "Epoch 1781/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 29962.2714 - val_loss: 91798.1477\n",
      "Epoch 1782/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 29938.5913 - val_loss: 91753.1240\n",
      "Epoch 1783/2000\n",
      "534/534 [==============================] - 0s 120us/step - loss: 29914.9217 - val_loss: 91708.1115\n",
      "Epoch 1784/2000\n",
      "534/534 [==============================] - 0s 129us/step - loss: 29891.2632 - val_loss: 91663.1050\n",
      "Epoch 1785/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 29867.6153 - val_loss: 91618.0996\n",
      "Epoch 1786/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 29843.9751 - val_loss: 91573.1313\n",
      "Epoch 1787/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 29820.3479 - val_loss: 91528.1528\n",
      "Epoch 1788/2000\n",
      "534/534 [==============================] - 0s 126us/step - loss: 29796.7266 - val_loss: 91483.1982\n",
      "Epoch 1789/2000\n",
      "534/534 [==============================] - 0s 127us/step - loss: 29773.1157 - val_loss: 91438.2420\n",
      "Epoch 1790/2000\n",
      "534/534 [==============================] - 0s 120us/step - loss: 29749.5162 - val_loss: 91393.3048\n",
      "Epoch 1791/2000\n",
      "534/534 [==============================] - 0s 134us/step - loss: 29725.9258 - val_loss: 91348.3672\n",
      "Epoch 1792/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 29702.3444 - val_loss: 91303.4600\n",
      "Epoch 1793/2000\n",
      "534/534 [==============================] - 0s 120us/step - loss: 29678.7743 - val_loss: 91258.5535\n",
      "Epoch 1794/2000\n",
      "534/534 [==============================] - 0s 136us/step - loss: 29655.2154 - val_loss: 91213.6646\n",
      "Epoch 1795/2000\n",
      "534/534 [==============================] - 0s 120us/step - loss: 29631.6674 - val_loss: 91168.7881\n",
      "Epoch 1796/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 29608.1319 - val_loss: 91123.9250\n",
      "Epoch 1797/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 29584.6069 - val_loss: 91079.0821\n",
      "Epoch 1798/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 29561.0901 - val_loss: 91034.2338\n",
      "Epoch 1799/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 29537.5843 - val_loss: 90989.4035\n",
      "Epoch 1800/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 29514.0898 - val_loss: 90944.5943\n",
      "Epoch 1801/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 29490.6035 - val_loss: 90899.7925\n",
      "Epoch 1802/2000\n",
      "534/534 [==============================] - 0s 94us/step - loss: 29467.1322 - val_loss: 90855.0183\n",
      "Epoch 1803/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 29443.6713 - val_loss: 90810.2283\n",
      "Epoch 1804/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 29420.2196 - val_loss: 90765.4660\n",
      "Epoch 1805/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 29396.7798 - val_loss: 90720.7229\n",
      "Epoch 1806/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 29373.3492 - val_loss: 90675.9925\n",
      "Epoch 1807/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 29349.9308 - val_loss: 90631.2655\n",
      "Epoch 1808/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 29326.5223 - val_loss: 90586.5483\n",
      "Epoch 1809/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 29303.1240 - val_loss: 90541.8587\n",
      "Epoch 1810/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 29279.7347 - val_loss: 90497.1595\n",
      "Epoch 1811/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 29256.3552 - val_loss: 90452.4849\n",
      "Epoch 1812/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 29232.9891 - val_loss: 90407.8216\n",
      "Epoch 1813/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 29209.6321 - val_loss: 90363.1751\n",
      "Epoch 1814/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 29186.2870 - val_loss: 90318.5445\n",
      "Epoch 1815/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 29162.9515 - val_loss: 90273.9204\n",
      "Epoch 1816/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 29139.6265 - val_loss: 90229.3060\n",
      "Epoch 1817/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 29116.3138 - val_loss: 90184.7012\n",
      "Epoch 1818/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 29093.0101 - val_loss: 90140.1255\n",
      "Epoch 1819/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 29069.7184 - val_loss: 90095.5586\n",
      "Epoch 1820/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 29046.4405 - val_loss: 90050.9896\n",
      "Epoch 1821/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 29023.1705 - val_loss: 90006.4531\n",
      "Epoch 1822/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 28999.9114 - val_loss: 89961.9190\n",
      "Epoch 1823/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 28976.6619 - val_loss: 89917.3967\n",
      "Epoch 1824/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 28953.4223 - val_loss: 89872.8833\n",
      "Epoch 1825/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28930.1949 - val_loss: 89828.3926\n",
      "Epoch 1826/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28906.9779 - val_loss: 89783.9078\n",
      "Epoch 1827/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28883.7721 - val_loss: 89739.4399\n",
      "Epoch 1828/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 28860.5773 - val_loss: 89694.9779\n",
      "Epoch 1829/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 28837.3913 - val_loss: 89650.5393\n",
      "Epoch 1830/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 28814.2166 - val_loss: 89606.1079\n",
      "Epoch 1831/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28791.0538 - val_loss: 89561.6778\n",
      "Epoch 1832/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 28767.8991 - val_loss: 89517.2770\n",
      "Epoch 1833/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 28744.7563 - val_loss: 89472.8760\n",
      "Epoch 1834/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 28721.6221 - val_loss: 89428.4913\n",
      "Epoch 1835/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 28698.4982 - val_loss: 89384.1152\n",
      "Epoch 1836/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28675.3843 - val_loss: 89339.7552\n",
      "Epoch 1837/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 28652.2809 - val_loss: 89295.4008\n",
      "Epoch 1838/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 28629.1883 - val_loss: 89251.0679\n",
      "Epoch 1839/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 28606.1050 - val_loss: 89206.7403\n",
      "Epoch 1840/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28583.0318 - val_loss: 89162.4186\n",
      "Epoch 1841/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28559.9705 - val_loss: 89118.1302\n",
      "Epoch 1842/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 28536.9229 - val_loss: 89073.8409\n",
      "Epoch 1843/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 28513.8857 - val_loss: 89029.5753\n",
      "Epoch 1844/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28490.8602 - val_loss: 88985.3175\n",
      "Epoch 1845/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28467.8445 - val_loss: 88941.0772\n",
      "Epoch 1846/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28444.8388 - val_loss: 88896.8523\n",
      "Epoch 1847/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28421.8434 - val_loss: 88852.6269\n",
      "Epoch 1848/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 28398.8593 - val_loss: 88808.4039\n",
      "Epoch 1849/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 28375.8837 - val_loss: 88764.2167\n",
      "Epoch 1850/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28352.9187 - val_loss: 88720.0290\n",
      "Epoch 1851/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 28329.9644 - val_loss: 88675.8536\n",
      "Epoch 1852/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 28307.0199 - val_loss: 88631.6902\n",
      "Epoch 1853/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 28284.0854 - val_loss: 88587.5401\n",
      "Epoch 1854/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 28261.1621 - val_loss: 88543.4155\n",
      "Epoch 1855/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 28238.2528 - val_loss: 88499.2976\n",
      "Epoch 1856/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 28215.3548 - val_loss: 88455.1950\n",
      "Epoch 1857/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 28192.4684 - val_loss: 88411.1043\n",
      "Epoch 1858/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 28169.5917 - val_loss: 88367.0338\n",
      "Epoch 1859/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 28146.7248 - val_loss: 88322.9646\n",
      "Epoch 1860/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 28123.8682 - val_loss: 88278.9045\n",
      "Epoch 1861/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 28101.0234 - val_loss: 88234.8637\n",
      "Epoch 1862/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 28078.1874 - val_loss: 88190.8289\n",
      "Epoch 1863/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 28055.3600 - val_loss: 88146.8033\n",
      "Epoch 1864/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 28032.5444 - val_loss: 88102.7954\n",
      "Epoch 1865/2000\n",
      "534/534 [==============================] - 0s 97us/step - loss: 28009.7378 - val_loss: 88058.7949\n",
      "Epoch 1866/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 27986.9395 - val_loss: 88014.8063\n",
      "Epoch 1867/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 27964.1530 - val_loss: 87970.8424\n",
      "Epoch 1868/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 27941.3776 - val_loss: 87926.8741\n",
      "Epoch 1869/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 27918.6128 - val_loss: 87882.9303\n",
      "Epoch 1870/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 27895.8579 - val_loss: 87838.9939\n",
      "Epoch 1871/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 27873.1137 - val_loss: 87795.0694\n",
      "Epoch 1872/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 27850.3776 - val_loss: 87751.1588\n",
      "Epoch 1873/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 27827.6520 - val_loss: 87707.2510\n",
      "Epoch 1874/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 27804.9354 - val_loss: 87663.3541\n",
      "Epoch 1875/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 27782.2303 - val_loss: 87619.4647\n",
      "Epoch 1876/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 27759.5328 - val_loss: 87575.6056\n",
      "Epoch 1877/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 27736.8470 - val_loss: 87531.7470\n",
      "Epoch 1878/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 27714.1750 - val_loss: 87487.8965\n",
      "Epoch 1879/2000\n",
      "534/534 [==============================] - 0s 122us/step - loss: 27691.5127 - val_loss: 87444.0792\n",
      "Epoch 1880/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 27668.8609 - val_loss: 87400.2581\n",
      "Epoch 1881/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 27646.2175 - val_loss: 87356.4567\n",
      "Epoch 1882/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 27623.5858 - val_loss: 87312.6625\n",
      "Epoch 1883/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 27600.9635 - val_loss: 87268.8702\n",
      "Epoch 1884/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 27578.3497 - val_loss: 87225.1059\n",
      "Epoch 1885/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 27555.7495 - val_loss: 87181.3438\n",
      "Epoch 1886/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 27533.1572 - val_loss: 87137.5960\n",
      "Epoch 1887/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 27510.5778 - val_loss: 87093.8664\n",
      "Epoch 1888/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 27488.0089 - val_loss: 87050.1444\n",
      "Epoch 1889/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 27465.4499 - val_loss: 87006.4348\n",
      "Epoch 1890/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 27442.9002 - val_loss: 86962.7360\n",
      "Epoch 1891/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 27420.3609 - val_loss: 86919.0579\n",
      "Epoch 1892/2000\n",
      "534/534 [==============================] - 0s 96us/step - loss: 27397.8325 - val_loss: 86875.3839\n",
      "Epoch 1893/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 27375.3139 - val_loss: 86831.7176\n",
      "Epoch 1894/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 27352.8047 - val_loss: 86788.0646\n",
      "Epoch 1895/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 27330.3101 - val_loss: 86744.4411\n",
      "Epoch 1896/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 27307.8260 - val_loss: 86700.8183\n",
      "Epoch 1897/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 27285.3535 - val_loss: 86657.2136\n",
      "Epoch 1898/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 27262.8925 - val_loss: 86613.6187\n",
      "Epoch 1899/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 27240.4418 - val_loss: 86570.0451\n",
      "Epoch 1900/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 27218.0024 - val_loss: 86526.4891\n",
      "Epoch 1901/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 27195.5725 - val_loss: 86482.9319\n",
      "Epoch 1902/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 27173.1519 - val_loss: 86439.3981\n",
      "Epoch 1903/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 27150.7435 - val_loss: 86395.8659\n",
      "Epoch 1904/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 27128.3436 - val_loss: 86352.3510\n",
      "Epoch 1905/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 27105.9540 - val_loss: 86308.8384\n",
      "Epoch 1906/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 27083.5749 - val_loss: 86265.3371\n",
      "Epoch 1907/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 27061.2046 - val_loss: 86221.8675\n",
      "Epoch 1908/2000\n",
      "534/534 [==============================] - 0s 119us/step - loss: 27038.8472 - val_loss: 86178.4011\n",
      "Epoch 1909/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 27016.5004 - val_loss: 86134.9455\n",
      "Epoch 1910/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 26994.1639 - val_loss: 86091.5075\n",
      "Epoch 1911/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 26971.8401 - val_loss: 86048.0736\n",
      "Epoch 1912/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 26949.5243 - val_loss: 86004.6556\n",
      "Epoch 1913/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 26927.2216 - val_loss: 85961.2647\n",
      "Epoch 1914/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 26904.9291 - val_loss: 85917.8639\n",
      "Epoch 1915/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 26882.6456 - val_loss: 85874.4949\n",
      "Epoch 1916/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 26860.3746 - val_loss: 85831.1262\n",
      "Epoch 1917/2000\n",
      "534/534 [==============================] - 0s 95us/step - loss: 26838.1118 - val_loss: 85787.7649\n",
      "Epoch 1918/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 26815.8599 - val_loss: 85744.4197\n",
      "Epoch 1919/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 26793.6163 - val_loss: 85701.0961\n",
      "Epoch 1920/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 26771.3846 - val_loss: 85657.7733\n",
      "Epoch 1921/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 26749.1631 - val_loss: 85614.4671\n",
      "Epoch 1922/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 26726.9502 - val_loss: 85571.1680\n",
      "Epoch 1923/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 26704.7477 - val_loss: 85527.8800\n",
      "Epoch 1924/2000\n",
      "534/534 [==============================] - 0s 118us/step - loss: 26682.5576 - val_loss: 85484.6184\n",
      "Epoch 1925/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 26660.3770 - val_loss: 85441.3486\n",
      "Epoch 1926/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 26638.2087 - val_loss: 85398.1140\n",
      "Epoch 1927/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 26616.0512 - val_loss: 85354.8788\n",
      "Epoch 1928/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 26593.9025 - val_loss: 85311.6635\n",
      "Epoch 1929/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 26571.7688 - val_loss: 85268.4681\n",
      "Epoch 1930/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 26549.6447 - val_loss: 85225.2752\n",
      "Epoch 1931/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 26527.5302 - val_loss: 85182.0859\n",
      "Epoch 1932/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 26505.4267 - val_loss: 85138.9370\n",
      "Epoch 1933/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 26483.3406 - val_loss: 85095.7902\n",
      "Epoch 1934/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 26461.2636 - val_loss: 85052.6575\n",
      "Epoch 1935/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 26439.1963 - val_loss: 85009.5414\n",
      "Epoch 1936/2000\n",
      "534/534 [==============================] - 0s 119us/step - loss: 26417.1398 - val_loss: 84966.4397\n",
      "Epoch 1937/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 26395.0932 - val_loss: 84923.3451\n",
      "Epoch 1938/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 26373.0569 - val_loss: 84880.2614\n",
      "Epoch 1939/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 26351.0306 - val_loss: 84837.1867\n",
      "Epoch 1940/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 26329.0154 - val_loss: 84794.1359\n",
      "Epoch 1941/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 26307.0084 - val_loss: 84751.0803\n",
      "Epoch 1942/2000\n",
      "534/534 [==============================] - 0s 98us/step - loss: 26285.0137 - val_loss: 84708.0436\n",
      "Epoch 1943/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 26263.0268 - val_loss: 84665.0211\n",
      "Epoch 1944/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 26241.0522 - val_loss: 84622.0073\n",
      "Epoch 1945/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 26219.0860 - val_loss: 84579.0106\n",
      "Epoch 1946/2000\n",
      "534/534 [==============================] - 0s 99us/step - loss: 26197.1299 - val_loss: 84536.0167\n",
      "Epoch 1947/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 26175.1853 - val_loss: 84493.0411\n",
      "Epoch 1948/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 26153.2493 - val_loss: 84450.0801\n",
      "Epoch 1949/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 26131.3252 - val_loss: 84407.1248\n",
      "Epoch 1950/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 26109.4100 - val_loss: 84364.1845\n",
      "Epoch 1951/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 26087.5066 - val_loss: 84321.2558\n",
      "Epoch 1952/2000\n",
      "534/534 [==============================] - 0s 112us/step - loss: 26065.6102 - val_loss: 84278.3383\n",
      "Epoch 1953/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 26043.7273 - val_loss: 84235.4332\n",
      "Epoch 1954/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 26021.8527 - val_loss: 84192.5323\n",
      "Epoch 1955/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 25999.9881 - val_loss: 84149.6522\n",
      "Epoch 1956/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 25978.1339 - val_loss: 84106.7866\n",
      "Epoch 1957/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 25956.2896 - val_loss: 84063.9310\n",
      "Epoch 1958/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 25934.4565 - val_loss: 84021.0839\n",
      "Epoch 1959/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 25912.6327 - val_loss: 83978.2449\n",
      "Epoch 1960/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 25890.8184 - val_loss: 83935.4263\n",
      "Epoch 1961/2000\n",
      "534/534 [==============================] - 0s 101us/step - loss: 25869.0146 - val_loss: 83892.6170\n",
      "Epoch 1962/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 25847.2221 - val_loss: 83849.8210\n",
      "Epoch 1963/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 25825.4417 - val_loss: 83807.0384\n",
      "Epoch 1964/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 25803.6722 - val_loss: 83764.2630\n",
      "Epoch 1965/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 25781.9122 - val_loss: 83721.5116\n",
      "Epoch 1966/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 25760.1630 - val_loss: 83678.7590\n",
      "Epoch 1967/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 25738.4239 - val_loss: 83636.0255\n",
      "Epoch 1968/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 25716.6932 - val_loss: 83593.2960\n",
      "Epoch 1969/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 25694.9745 - val_loss: 83550.5897\n",
      "Epoch 1970/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 25673.2633 - val_loss: 83507.8823\n",
      "Epoch 1971/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 25651.5647 - val_loss: 83465.1990\n",
      "Epoch 1972/2000\n",
      "534/534 [==============================] - 0s 108us/step - loss: 25629.8727 - val_loss: 83422.5135\n",
      "Epoch 1973/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 25608.1898 - val_loss: 83379.8415\n",
      "Epoch 1974/2000\n",
      "534/534 [==============================] - 0s 107us/step - loss: 25586.5158 - val_loss: 83337.1808\n",
      "Epoch 1975/2000\n",
      "534/534 [==============================] - 0s 113us/step - loss: 25564.8522 - val_loss: 83294.5323\n",
      "Epoch 1976/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 25543.1992 - val_loss: 83251.8955\n",
      "Epoch 1977/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 25521.5560 - val_loss: 83209.2842\n",
      "Epoch 1978/2000\n",
      "534/534 [==============================] - 0s 117us/step - loss: 25499.9253 - val_loss: 83166.6680\n",
      "Epoch 1979/2000\n",
      "534/534 [==============================] - 0s 114us/step - loss: 25478.3059 - val_loss: 83124.0717\n",
      "Epoch 1980/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 25456.6973 - val_loss: 83081.4881\n",
      "Epoch 1981/2000\n",
      "534/534 [==============================] - 0s 136us/step - loss: 25435.0974 - val_loss: 83038.9228\n",
      "Epoch 1982/2000\n",
      "534/534 [==============================] - 0s 123us/step - loss: 25413.5087 - val_loss: 82996.3531\n",
      "Epoch 1983/2000\n",
      "534/534 [==============================] - 0s 116us/step - loss: 25391.9312 - val_loss: 82953.8097\n",
      "Epoch 1984/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 25370.3654 - val_loss: 82911.2773\n",
      "Epoch 1985/2000\n",
      "534/534 [==============================] - 0s 105us/step - loss: 25348.8101 - val_loss: 82868.7592\n",
      "Epoch 1986/2000\n",
      "534/534 [==============================] - 0s 110us/step - loss: 25327.2652 - val_loss: 82826.2678\n",
      "Epoch 1987/2000\n",
      "534/534 [==============================] - 0s 115us/step - loss: 25305.7339 - val_loss: 82783.7727\n",
      "Epoch 1988/2000\n",
      "534/534 [==============================] - 0s 120us/step - loss: 25284.2127 - val_loss: 82741.3053\n",
      "Epoch 1989/2000\n",
      "534/534 [==============================] - 0s 100us/step - loss: 25262.7049 - val_loss: 82698.8495\n",
      "Epoch 1990/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 25241.2085 - val_loss: 82656.4003\n",
      "Epoch 1991/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 25219.7222 - val_loss: 82613.9749\n",
      "Epoch 1992/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 25198.2492 - val_loss: 82571.5604\n",
      "Epoch 1993/2000\n",
      "534/534 [==============================] - 0s 104us/step - loss: 25176.7875 - val_loss: 82529.1578\n",
      "Epoch 1994/2000\n",
      "534/534 [==============================] - 0s 111us/step - loss: 25155.3329 - val_loss: 82486.7657\n",
      "Epoch 1995/2000\n",
      "534/534 [==============================] - 0s 109us/step - loss: 25133.8916 - val_loss: 82444.3929\n",
      "Epoch 1996/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 25112.4623 - val_loss: 82402.0130\n",
      "Epoch 1997/2000\n",
      "534/534 [==============================] - 0s 106us/step - loss: 25091.0423 - val_loss: 82359.6666\n",
      "Epoch 1998/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 25069.6325 - val_loss: 82317.3442\n",
      "Epoch 1999/2000\n",
      "534/534 [==============================] - 0s 103us/step - loss: 25048.2329 - val_loss: 82274.9990\n",
      "Epoch 2000/2000\n",
      "534/534 [==============================] - 0s 102us/step - loss: 25026.8435 - val_loss: 82232.6848\n"
     ]
    }
   ],
   "source": [
    "res = model.fit(train_x, train_y, validation_data=(test_x,test_y), epochs=2000, batch_size=32, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"1754392e-78aa-4b31-97c7-3ff8a63ddc3d\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"a2a382e3-7430-4f8c-b29b-2a73e49e69f7\":{\"roots\":{\"references\":[{\"attributes\":{\"data_source\":{\"id\":\"e2cc42ab-a992-4694-b501-f49c2d34d4aa\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"f54e27d8-5aec-46ac-a150-5ba3713b7dbf\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"bf9b13c3-7005-4bd1-8fa6-a6372393c1eb\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"80e6c837-0fcf-4347-b82c-f05a825c23f8\",\"type\":\"CDSView\"}},\"id\":\"e91ffce4-df01-4cf0-9cf1-486d3bcc0634\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1fabf660-d6e0-4b43-8981-eb79113c59b3\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"f2f5227e-f4ba-4eb0-bae6-b6618cde81c5\",\"type\":\"BasicTicker\"}},\"id\":\"64266378-625e-4332-99b1-7d61177d7841\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"e2cc42ab-a992-4694-b501-f49c2d34d4aa\",\"type\":\"ColumnDataSource\"}},\"id\":\"80e6c837-0fcf-4347-b82c-f05a825c23f8\",\"type\":\"CDSView\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"bf9b13c3-7005-4bd1-8fa6-a6372393c1eb\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"688a17e9-a9ef-4694-b482-03ba4ef3e8ac\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"c008c8af-3aa0-4d2a-ab4f-5fc5a46c782b\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"83fc9330-4363-4ebe-9ac1-9c57b10cabad\",\"type\":\"PanTool\"},{\"attributes\":{\"line_color\":\"red\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"6e271177-52f7-41d2-ad80-1ab59cb2fdb3\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"ebdff63a-b289-43af-bb08-3c2216e11507\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"overlay\":{\"id\":\"c008c8af-3aa0-4d2a-ab4f-5fc5a46c782b\",\"type\":\"BoxAnnotation\"}},\"id\":\"899ed59b-29b4-438c-a11b-0983ac43c2fe\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"a0915a30-1a97-4038-9764-5f5dacfd8f93\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"dbd704ed-1a63-4643-9023-a72a7433c4b4\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"d8c677ad-b725-401e-b04b-066938ad61da\",\"type\":\"HelpTool\"},{\"attributes\":{\"data_source\":{\"id\":\"2438f108-1f03-4af3-9d67-b21fca67fb46\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"6e271177-52f7-41d2-ad80-1ab59cb2fdb3\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"ee4d4d36-5a7c-4aa7-b9ba-fd7717d22588\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"baed6ac4-dcc4-4f45-b191-ca2d674ac3d6\",\"type\":\"CDSView\"}},\"id\":\"f35afb79-352d-43db-8268-84030079580e\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"3dae3c17-c83c-4037-b4c2-573e4f35417f\",\"type\":\"Title\"},{\"attributes\":{\"source\":{\"id\":\"2438f108-1f03-4af3-9d67-b21fca67fb46\",\"type\":\"ColumnDataSource\"}},\"id\":\"baed6ac4-dcc4-4f45-b191-ca2d674ac3d6\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"db6e52e2-3aad-4243-8fc9-0adac1477824\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"ee4d4d36-5a7c-4aa7-b9ba-fd7717d22588\",\"type\":\"Line\"},{\"attributes\":{\"line_color\":\"blue\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"f54e27d8-5aec-46ac-a150-5ba3713b7dbf\",\"type\":\"Line\"},{\"attributes\":{\"below\":[{\"id\":\"0ccc61d9-1bbb-4c2f-9af1-521055da86c2\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"bfb4a1b1-c8a6-46d6-9987-4b5763109c9a\",\"type\":\"LinearAxis\"}],\"plot_height\":250,\"plot_width\":500,\"renderers\":[{\"id\":\"0ccc61d9-1bbb-4c2f-9af1-521055da86c2\",\"type\":\"LinearAxis\"},{\"id\":\"a01a5196-c5a0-4925-b2d8-2d350bb4fcbb\",\"type\":\"Grid\"},{\"id\":\"bfb4a1b1-c8a6-46d6-9987-4b5763109c9a\",\"type\":\"LinearAxis\"},{\"id\":\"64266378-625e-4332-99b1-7d61177d7841\",\"type\":\"Grid\"},{\"id\":\"c008c8af-3aa0-4d2a-ab4f-5fc5a46c782b\",\"type\":\"BoxAnnotation\"},{\"id\":\"e91ffce4-df01-4cf0-9cf1-486d3bcc0634\",\"type\":\"GlyphRenderer\"},{\"id\":\"f35afb79-352d-43db-8268-84030079580e\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"3dae3c17-c83c-4037-b4c2-573e4f35417f\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"5a0c46ac-3440-443c-8c16-603296cbdea2\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"efcf03d2-841a-44cb-b788-6209d3fc85c9\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"3eccc43c-2a7c-4900-a806-f297579d6ea1\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"c53f7c7b-b558-40ed-bad1-e5453a2e3156\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"11410c9b-2888-4423-93cb-0b93e7ec3da1\",\"type\":\"LinearScale\"}},\"id\":\"1fabf660-d6e0-4b43-8981-eb79113c59b3\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[2000]},\"y\":[88454.89668188202,88200.02557350187,88104.84354517791,87907.61587078651,87803.26934105805,87735.25140449438,87670.61470037453,87604.72764513109,87541.32897354869,87476.19408356742,87412.16886118914,87348.11089653558,87284.44303019663,87220.37157654495,87156.99051966293,87093.23785697565,87029.50277972847,86966.32850538389,86902.76559573971,86839.38550444756,86776.08681530898,86713.21339536516,86649.81870318353,86586.60823384831,86523.55559456929,86460.5473431648,86397.60106507491,86334.68024344569,86271.80325374533,86208.97761587078,86146.19402504682,86083.45997191011,86020.76413272473,85958.10053838951,85895.483789794,85832.91224836142,85770.37763342696,85707.88682116105,85645.43319873596,85583.01155781835,85520.63608965356,85458.29137406367,85395.98001521536,85333.7105863764,85271.47214419476,85209.27206226591,85147.10709269663,85084.98191713484,85022.89360955056,84960.83827832396,84898.82162921349,84836.8354693352,84774.8828125,84712.9693937266,84651.08886352996,84589.23513576778,84527.41889044944,84465.63825491573,84403.89150280898,84342.18100421349,84280.49897588951,84218.85027504682,84157.23393609551,84095.648144897,84034.09770014045,83972.57405781835,83911.09000468165,83849.63699672285,83788.21594101124,83726.82642790262,83665.46936446629,83604.13965941011,83542.84307701311,83481.58227996255,83420.34851942884,83359.14609667604,83297.97741104869,83236.84032654495,83175.73457982209,83114.65929307116,83053.6178897472,82992.60308403558,82931.62298103933,82870.66684222847,82809.74926849251,82748.85861423222,82687.99681062734,82627.1636528558,82566.36458333333,82505.59375,82444.85244030898,82384.14469218165,82323.46263459738,82262.81170997191,82202.19376170413,82141.60223548689,82081.04002808989,82020.50836844569,81960.00380383895,81899.53613647004,81839.09050210674,81778.67687851124,81718.29266151685,81657.93387172285,81597.60674157304,81537.31147588951,81477.03944288389,81416.80135182584,81356.59114583333,81296.405957397,81236.25239934456,81176.12845271536,81116.0319522472,81055.96538506554,80995.92494733146,80935.91324321162,80875.93126755618,80815.97580173222,80756.04924508427,80696.14995903558,80636.28192298689,80576.43717813671,80516.61964536516,80456.83842462547,80397.0787687266,80337.34693937266,80277.64644779962,80217.96766736891,80158.32107326778,80098.70233497191,80039.10855571162,79979.54684573971,79920.00643726591,79860.49458684456,79801.01401568353,79741.55951544944,79682.1329880618,79622.73276568353,79563.35606858614,79504.01027036516,79444.69294241573,79385.40127574907,79326.13398291198,79266.89700374533,79207.68340355805,79148.4999414794,79089.34266736891,79030.21125936329,78971.10712195693,78912.03151334269,78852.97963483146,78793.95540730337,78734.95997191011,78675.98891034644,78617.04424157304,78558.1245903558,78499.23329236891,78440.36911867978,78381.5311329588,78322.71678955993,78263.93349133895,78205.17143609551,78146.4376755618,78087.73165379213,78029.05164442884,77970.39360955056,77911.7660346442,77853.16324321162,77794.5859960206,77736.03364934456,77677.51234784644,77619.01299157304,77560.53795060862,77502.09114583333,77443.66897823034,77385.2733789794,77326.90133426966,77268.55942766854,77210.24286048689,77151.94636587078,77093.68117977527,77035.44001638576,76977.22182233146,76919.0311914794,76860.86534410113,76802.73065894195,76744.61373478464,76686.52446161049,76628.4611130618,76570.42099719102,76512.41218984082,76454.42708333333,76396.46368796816,76338.52513459738,76280.61464185393,76222.72594803371,76164.86850421349,76107.03192298689,76049.22003745318,75991.43559808053,75933.67292837078,75875.93770482209,75818.22577247191,75760.54201779026,75702.88117392322,75645.24423572098,75587.63377808989,75530.04544124533,75472.48832514045,75414.94967228464,75357.44057233146,75299.95332982209,75242.49113412922,75185.05547752809,75127.64352176966,75070.25482794944,75012.89232209738,74955.55536048689,74898.2423630618,74840.95385650749,74783.68963600187,74726.45075491573,74669.23545763109,74612.04514864233,74554.87971090824,74497.73838366105,74440.62412219102,74383.53470271536,74326.46763810862,74269.42196278089,74212.40484550562,74155.40973197565,74098.44165496255,74041.492480103,73984.57244850187,73927.67488881086,73870.80064957865,73813.9533005618,73757.12868679775,73700.33151919476,73643.55814021536,73586.80603347378,73530.08061212547,73473.37842345505,73416.69908707865,73360.04482677902,73303.4140625,73246.80854985955,73190.22741104869,73133.66722261236,73077.13585557116,73020.62567298689,72964.14024461611,72907.67875117042,72851.23914442884,72794.82528675093,72738.4371488764,72682.07464302435,72625.73536985018,72569.41631554307,72513.12309808053,72456.85334737827,72400.60601006554,72344.38565074907,72288.18972378277,72232.01647354869,72175.8671289794,72119.74092930711,72063.64431179775,72007.56732794944,71951.51705875467,71895.48891034644,71839.4841994382,71783.50152153558,71727.54596793071,71671.61493445693,71615.703125,71559.81609901685,71503.95303721911,71448.11414442884,71392.29944990636,71336.51158707865,71280.7418363764,71224.99795177902,71169.2806062734,71113.58383075842,71057.91230688202,71002.26155781835,70946.63559222847,70891.03391268727,70835.45558286516,70779.89829119851,70724.36920646067,70668.859667603,70613.3751170412,70557.91479400749,70502.47960557116,70447.06726942884,70391.67570809925,70336.30875468165,70280.96594101124,70225.65352879213,70170.35533707865,70115.08886352996,70059.83895131086,70004.61610486891,69949.41815894195,69894.24139747191,69839.08915613296,69783.95771886704,69728.85314255618,69673.77217930711,69618.71292720038,69563.67664442884,69508.66625702247,69453.67474250936,69398.711230103,69343.76966292135,69288.84939723783,69233.95558286516,69179.08666900749,69124.23814957865,69069.4144136236,69014.61350070225,68959.83813202247,68905.07947097378,68850.34761235955,68795.63638225655,68740.952832397,68686.29075959738,68631.65150983146,68577.03733614233,68522.44645365169,68467.87617041198,68413.33309925093,68358.81206109551,68304.31688904495,68249.84281367042,68195.39264396067,68140.96983263109,68086.56606975655,68032.18960674158,67977.83116807116,67923.49961961611,67869.18978230337,67814.89978347378,67760.63512406367,67706.39451661985,67652.17790262173,67597.98387757491,67543.81399227527,67489.66862710674,67435.54470973783,67381.44209386704,67327.36174508427,67273.30702832396,67219.27466643258,67165.26682467229,67111.27987476591,67057.31791315544,67003.37704822098,66949.45695809925,66895.56516268727,66841.6953125,66787.85024578651,66734.02876287453,66680.23144897004,66626.45874297753,66572.70640215356,66518.97972261236,66465.2739641854,66411.59041432584,66357.93270131086,66304.29743094569,66250.68413506554,66197.0941596442,66143.52554424158,66089.98326310862,66036.45941596442,65982.95918188202,65929.48399461611,65876.03414676966,65822.60618562734,65769.2033590824,65715.82218515918,65662.46556062734,65609.13079353933,65555.81879096442,65502.52975772472,65449.26670763108,65396.02267673221,65342.80521418539,65289.60782420412,65236.434105805245,65183.285639044945,65130.159731975655,65077.05673572097,65023.97741104869,64970.922167603,64917.88939606742,64864.878686797754,64811.89123946629,64758.93156015917,64705.98999297753,64653.075286750936,64600.1797460206,64547.308432818354,64494.457660346445,64441.63407069288,64388.832367743446,64336.04980102996,64283.291783707864,64230.56018843633,64177.848870552436,64125.16186797753,64072.496371722846,64019.85820458802,63967.24130969101,63914.65001755618,63862.07967579588,63809.53692649813,63757.010504447564,63704.50667134832,63652.02931882023,63599.57265332397,63547.13913272472,63494.729927434455,63442.34234550562,63389.97790847378,63337.63775749064,63285.32104400749,63233.02402270599,63180.74953183521,63128.50040964419,63076.27560276217,63024.072887406364,62971.8908298221,62919.7346090824,62867.597934222846,62815.489466292136,62763.40311914794,62711.34231624532,62659.301029962546,62607.28695575843,62555.293041900746,62503.32224367977,62451.37333216292,62399.44434691011,62347.54459269663,62295.66482326779,62243.809837312736,62191.97726474719,62140.168451544945,62088.38480220037,62036.622337312736,61984.88158356742,61933.1641795412,61881.47024227528,61829.79839653558,61778.152036516854,61726.527007256554,61674.926117743446,61623.34913389513,61571.79459269663,61520.25994850187,61468.75158005618,61417.26398642322,61365.800620318354,61314.35639044944,61262.93905079588,61211.54391970974,61160.17023642322,61108.82227294007,61057.496108380146,61006.192532771536,60954.91099016854,60903.653675093636,60852.417456694755,60801.20929892322,60750.0232326779,60698.856566011236,60647.71643843633,60596.598051264045,60545.5002048221,60494.42784410113,60443.3748536985,60392.35194288389,60341.348724250936,60290.370435393255,60239.4144136236,60188.48130266854,60137.5705173221,60086.68255500936,60035.81864466292,59984.97717696629,59934.1561036985,59883.363471441946,59832.5934866573,59781.84219920412,59731.11478815543,59680.41303838951,59629.72972261236,59579.07241924157,59528.43644662921,59477.825316011236,59427.238354400746,59376.67254798689,59326.13392439138,59275.613676264045,59225.11897237827,59174.644750702246,59124.19607326779,59073.76881437266,59023.36598782772,58972.98349719101,58922.627574906364,58872.29494382023,58821.979254447564,58771.68840706929,58721.4217872191,58671.17728815543,58620.955758426964,58570.757519897,58520.582397003745,58470.42752223783,58420.29552902622,58370.18448618914,58320.09930945693,58270.035697565545,58219.996371722846,58169.979956694755,58119.98393609551,58070.01243562734,58020.065952715355,57970.14001053371,57920.237827715355,57870.36080875468,57820.50550093633,57770.67090941011,57720.86013576779,57671.07218515917,57621.30673572097,57571.56928838951,57521.85009948502,57472.1562207397,57422.48484316479,57372.833099250936,57323.207601825845,57273.60475187266,57224.02261821161,57174.46556062734,57124.9295411985,57075.42085088951,57025.932408707864,56976.46778441011,56927.027007256554,56877.60849719101,56828.21169826779,56778.83514747191,56729.48273642322,56680.151100187264,56630.84597378277,56581.564987125465,56532.30524344569,56483.06800093633,56433.85475187266,56384.66362359551,56335.494674625465,56286.347378277154,56237.22366573034,56188.12426849251,56139.04830875468,56089.99344569288,56040.96248829588,55991.95426615168,55942.96989115168,55894.00974367977,55845.07598899813,55796.164355103,55747.27662687266,55698.41336025281,55649.574467462546,55600.76503979401,55551.97076896067,55503.20093047753,55454.456606975655,55405.73124414794,55357.02533941947,55308.3439840824,55259.684252106745,55211.0465531367,55162.42816596442,55113.8361130618,55065.26623946629,55016.71913038389,54968.19645365168,54919.69598548689,54871.2187792603,54822.76486423221,54774.332045880146,54725.92307467228,54677.5387113764,54629.17427434457,54580.832718867045,54532.51477645131,54484.21556062734,54435.94308871723,54387.69326427903,54339.46737476592,54291.26460088951,54243.0858204588,54194.93156015917,54146.79974250936,54098.69346910113,54050.60993094569,54002.543188202246,53954.50301381086,53906.4846383427,53858.488851825845,53810.51720505618,53762.57259480337,53714.644311797754,53666.73978815543,53618.85987242509,53571.004125702246,53523.1721090824,53475.361891385764,53427.57636938202,53379.81460674157,53332.07259480337,53284.35639044944,53236.660404962546,53188.988471441946,53141.33675678839,53093.7107326779,53046.105834503745,52998.52191596442,52950.96172752809,52903.42769779963,52855.91640332397,52808.427024812736,52760.96307350187,52713.52033590824,52666.10030430712,52618.70183754682,52571.32748127341,52523.97410463483,52476.64621371723,52429.34061914794,52382.05705758427,52334.793627106745,52287.55562382959,52240.34129213483,52193.145862593636,52145.97035931648,52098.81984433521,52051.691859784645,52004.58886352996,51957.50860252809,51910.45160346442,51863.41561329588,51816.40551849251,51769.41295060862,51722.44630735019,51675.50204822097,51628.580641385764,51581.68021418539,51534.80550678839,51487.956841058054,51441.13093984083,51394.3280079588,51347.54892322097,51300.79034995318,51254.05562382959,51207.347114934455,51160.65926381086,51113.99438202247,51067.351269897,51020.73577949438,50974.14170763108,50927.56893726592,50881.019370318354,50834.4921289794,50787.98621839887,50741.504535346445,50695.04380266854,50648.60723899813,50602.19384948502,50555.80354634832,50509.43536399813,50463.089916900746,50416.76711727528,50370.464712078654,50324.18670997191,50277.932291666664,50231.70470505618,50185.49420646067,50139.31080290262,50093.14925678839,50047.0081343633,50000.88845973783,49954.79491455993,49908.722173455055,49862.676381086145,49816.652972846445,49770.653441011236,49724.675356975655,49678.71793071161,49632.78288857678,49586.87444405431,49540.987125468164,49495.120786516854,49449.277007256554,49403.458216292136,49357.66511587079,49311.89741338951,49266.151831694755,49220.424362125465,49174.722466058054,49129.04008661049,49083.38161282772,49037.74771769663,48992.13743562734,48946.54906952247,48900.9841994382,48855.43992860487,48809.92058754682,48764.42225538389,48718.948794475655,48673.49847846442,48628.07086844569,48582.66701779026,48537.28262523408,48491.9216116573,48446.58438670412,48401.26776100187,48355.97708918539,48310.70967930712,48265.46643843633,48220.246635065545,48175.04608497191,48129.87210323034,48084.71965706929,48039.59152621723,47994.486979166664,47949.40695224719,47904.347349016854,47859.31124180712,47814.300532537454,47769.308579119854,47724.33912687266,47679.39533590824,47634.472466058054,47589.57165847378,47544.69484433521,47499.838570926964,47455.00845622659,47410.197799625465,47365.409761235955,47320.643316947564,47275.902475421346,47231.18436914794,47186.489612593636,47141.816508661046,47097.167924859554,47052.54207631086,47007.93796816479,46963.35718047753,46918.79772354869,46874.2655957397,46829.75553019663,46785.270921114236,46740.80764279026,46696.36765566479,46651.95259831461,46607.5621488764,46563.192474250936,46518.84465706929,46474.519487359554,46430.21646769663,46385.934076544945,46341.674508426964,46297.43799742509,46253.22038857678,46209.02993328652,46164.86025280899,46120.71158122659,46076.58684456929,46032.48507724719,45988.40466994382,45944.347641619854,45900.31206109551,45856.29754798689,45812.308754681646,45768.34158473783,45724.39957865168,45680.480015215355,45636.58742977528,45592.71994967228,45548.8750585206,45505.052112593636,45461.252574906364,45417.47802551498,45373.723724250936,45329.99051966292,45286.27958216292,45242.589799859554,45198.92477176966,45155.28186446629,45111.66119499064,45068.06320224719,45024.487798455055,44980.933579119854,44937.403002106745,44893.894955524345,44850.40777153558,44806.94598548689,44763.50819288389,44720.09129213483,44676.70081343633,44633.33055360487,44589.9842286985,44546.66450140449,44503.3674215824,44460.090970271536,44416.838600187264,44373.6095798221,44330.40338249064,44287.21699438202,44244.05612125468,44200.91587663857,44157.80167368914,44114.7109667603,44071.64185393258,44028.59568117977,43985.57127808989,43942.57195107678,43899.59214068352,43856.636499297754,43813.70131086143,43770.79017439138,43727.901129447564,43685.035404962546,43642.19431764981,43599.37371254682,43556.57713014981,43513.80588717228,43471.05568235019,43428.32607677903,43385.621605805245,43342.94036750936,43300.28060627341,43257.64539442884,43215.03202539794,43172.44029435862,43129.87271769663,43087.32502340824,43044.79990344101,43002.29781132959,42959.816245318354,42917.35791198502,42874.924420646064,42832.51250877809,42790.125512055245,42747.76351825843,42705.424479166664,42663.109916315545,42620.81842521067,42578.549654728464,42536.3046582397,42494.082689606745,42451.88200784176,42409.70618270131,42367.55165905899,42325.419241573036,42283.31169534176,42241.22466058053,42199.160522003745,42157.1173923221,42115.0976855103,42073.09967521067,42031.12801381086,41989.174479166664,41947.2461522706,41905.340121722846,41863.45565601592,41821.5936914794,41779.75632022472,41737.93966526217,41696.14671114232,41654.3750292603,41612.63121781367,41570.91123888108,41529.21399520131,41487.539135650746,41445.88712839419,41404.2575491573,41362.64931530899,41321.06393375468,41279.499546465355,41237.95924040262,41196.44343984083,41154.94872132491,41113.479225187264,41072.031440191946,41030.60723899813,40989.20602176966,40947.82686680712,40906.47511411517,40865.14202949438,40823.831519194755,40782.543012640446,40741.278733614236,40700.03623888108,40658.818922635764,40617.62401977996,40576.450433052436,40535.29991807116,40494.17265039794,40453.06712312734,40411.98589653558,40370.92749297753,40329.89265859083,40288.881539676964,40247.88816713483,40206.9179980103,40165.971266385764,40125.047152972846,40084.14694522472,40043.27084796348,40002.41643258427,39961.5862008427,39920.773832514045,39879.987710674155,39839.22324145599,39798.48345330056,39757.76667837079,39717.07237535113,39676.402095037454,39635.7542281133,39595.12583391854,39554.52381788389,39513.945853815545,39473.3902738764,39432.85587839419,39392.343823150746,39351.85494206461,39311.38898642322,39270.945736774345,39230.52419826779,39190.12704822097,39149.75087780899,39109.398188787454,39069.06757666198,39028.76070926966,38988.47511411517,38948.21355629682,38907.975143375465,38867.76068000936,38827.570005266854,38787.402007256554,38747.25484257959,38707.13426088483,38667.03435159176,38626.95865519663,38586.90459679307,38546.87412219101,38506.86793363764,38466.88616280431,38426.923030781836,38386.98895423689,38347.07524286049,38307.18473490168,38267.315952715355,38227.468852411046,38187.64600889513,38147.84563728933,38108.06451896067,38068.307350187264,38028.570005266854,37988.854839653555,37949.16252633427,37909.49302141854,37869.84436446629,37830.21959854869,37790.61645599251,37751.037643375465,37711.47823033708,37671.94332279963,37632.43123829588,37592.937865753745,37553.4683988764,37514.020189606745,37474.59557876873,37435.19580992509,37395.8204295412,37356.46951076779,37317.14597963483,37277.8435744382,37238.56535287921,37199.307993913855,37160.07345798221,37120.86114524813,37081.66922694288,37042.50076076779,37003.354166666664,36964.227016034645,36925.12362476592,36886.04097904963,36846.981712312736,36807.948794475655,36768.941567181646,36729.95496839887,36690.99303604869,36652.053560978464,36613.1368065309,36574.24290437734,36535.37189840824,36496.52551498127,36457.701735135764,36418.9019926264,36380.125336493446,36341.37194229869,36302.6443556882,36263.93909468633,36225.2580758427,36186.597934222846,36147.96140566479,36109.34607619382,36070.75449145599,36032.184281367045,35993.639352176964,35955.1171875,35916.616792485955,35878.13828417603,35839.68467638108,35801.25231156367,35762.840209503745,35724.44995025749,35686.082572565545,35647.73696453652,35609.41182408708,35571.109272588954,35532.828373712546,35494.57086844569,35456.33519136236,35418.12321512173,35379.93040437734,35341.76341584738,35303.61607560862,35265.48968574438,35227.38967404026,35189.30906191479,35151.253511235955,35113.2228025515,35075.21822331461,35037.23536985019,34999.27522237827,34961.33655196629,34923.42047050562,34885.53025514981,34847.66071219569,34809.81478230337,34771.99344569288,34734.19430301966,34696.420748478464,34658.671875,34620.94469803371,34583.240914676964,34545.56055419007,34507.90380676498,34470.26897530431,34432.65712780899,34395.070210088954,34357.503979400746,34319.96131788389,34282.4416695927,34244.94260592228,34207.4650778324,34170.011060393255,34132.57955875468,34095.1722261236,34057.784556413855,34020.419183052436,33983.07159995318,33945.74795177903,33908.445707514045,33871.1641502809,33833.90465531367,33796.66594978933,33759.45087195693,33722.25952422753,33685.089185393255,33647.938860603936,33610.8167281133,33573.71578007959,33536.639556999064,33499.58905372191,33462.56105161517,33425.55538974719,33388.572858146064,33351.6130179073,33314.673235603936,33277.75871956929,33240.867845856745,33204.001155781836,33167.15442123127,33130.33147530431,33093.52871898408,33056.74790788857,33019.99044651217,32983.26034351592,32946.55221500468,32909.86509538857,32873.20166198502,32836.5588570927,32799.937543890446,32763.34000468165,32726.76419124532,32690.21027914326,32653.679965472846,32617.172270014045,32580.688758192882,32544.22799625468,32507.789281952246,32471.37268843633,32434.97730863764,32398.606566011236,32362.255925210673,32325.932247776218,32289.6329880618,32253.363676264045,32217.11478815543,32180.893463249064,32144.69538565075,32108.515171465355,32072.35789735487,32036.223826661986,32000.11382256554,31964.026319639514,31927.96332221442,31891.92188963015,31855.899637172286,31819.90386528558,31783.926922401686,31747.97321219569,31712.044651217228,31676.141678370786,31640.259056062732,31604.39911048689,31568.56091994382,31532.745098899813,31496.95382724719,31461.184647120786,31425.43369616105,31389.708040730337,31354.00536926498,31318.32408707865,31282.666198501873,31247.027577832396,31211.412116690073,31175.819112827714,31140.24945868446,31104.703490753745,31069.182525749064,31033.68289150281,30998.20471968633,30962.752092111423,30927.31887874532,30891.91099016854,30856.526904845505,30821.167588366105,30785.830890098314,30750.51711727528,30715.224777621723,30679.952174040263,30644.700374531836,30609.471295646068,30574.26416198502,30539.07732034176,30503.91463307584,30468.77494440543,30433.661999648877,30398.569083567414,30363.496474133895,30328.445546582396,30293.418232092696,30258.413155430713,30223.432481858614,30188.474821512173,30153.5391795412,30118.625234082396,30083.736262289327,30048.87027446161,30014.023642322096,29979.200403792136,29944.404333450373,29909.62802844101,29874.87567298689,29840.149344569287,29805.44616104869,29770.76496664326,29736.10548338015,29701.468515917604,29666.855702832396,29632.266575959737,29597.700506203182,29563.155006437268,29528.6326661985,29494.132344335205,29459.654070107677,29425.198326310863,29390.765873712546,29356.357253628277,29321.96958391854,29287.60467872191,29253.26237710674,29218.94139161985,29184.643156015918,29150.368226240636,29116.116295060863,29081.88600187266,29047.676761470037,29013.49135358146,28979.329251521536,28945.189153206928,28911.076852176968,28876.985662453182,28842.915379213482,28808.870055009364,28774.84528616573,28740.842696629214,28706.85921406835,28672.900675912922,28638.962663857677,28605.050313085205,28571.159731975655,28537.291637406368,28503.447931296818,28469.629857209737,28435.835557116105,28402.062792602996,28368.31184164326,28334.58267497659,28300.878394194755,28267.19446395131,28233.534834386704,28199.89540905899,28166.282361891386,28132.690074906368,28099.11952832397,28065.570766034645,28032.044168422286,27998.537131320223,27965.052844101123,27931.593559808054,27898.154845505618,27864.738047167604,27831.343969452246,27797.975318937268,27764.6287892088,27731.30613588483,27698.00706636236,27664.73062968165,27631.4765332397,27598.24694229869,27565.040042720037,27531.851957514045,27498.690045646068,27465.548045411986,27432.427785580523,27399.33198735955,27366.258851240636,27333.213541666668,27300.189650632023,27267.188845973782,27234.21166900749,27201.255222963482,27168.321365870786,27135.411136470037,27102.519897003745,27069.649359199437,27036.803590238764,27003.98111247659,26971.183067064605,26938.40538682116,26905.65167076311,26872.919168422286,26840.209313553372,26807.52348139045,26774.85993094569,26742.216160463482,26709.595373946628,26676.996547284645,26644.42102645131,26611.865358731273,26579.336464185395,26546.826910697564,26514.33908298221,26481.87498536985,26449.43413506554,26417.015156835205,26384.623654026218,26352.255895950373,26319.908386001873,26287.58346500468,26255.281732794945,26222.999648876405,26190.741748595505,26158.505764279027,26126.29378803839,26094.104576310863,26061.937953534645,26029.792602996255,25997.670909410113,25965.572170529027,25933.498244382023,25901.44291315543,25869.4102147706,25837.401451310863,25805.413067649813,25773.44594159644,25741.500292602996,25709.578563904495,25677.677624648877,25645.802595388577,25613.950447682586,25582.120084269663,25550.31305594569,25518.52672928371,25486.764469218164,25455.025427200373,25423.310320107677,25391.6172752809,25359.94864817416,25328.30407303371,25296.684105805245,25265.088497776218,25233.51555184925,25201.96399520131,25170.43600772472,25138.930667720037,25107.447814255618,25075.987198618914,25044.548689138577,25013.131642088014,24981.736101357677,24950.362271769663,24919.010577598314,24887.681969803372,24856.37346383427,24825.08832221442,24793.824482092696,24762.58263108614,24731.363486072096,24700.164969569287,24668.98759363296,24637.83207514045,24606.698823735955,24575.591058052436,24544.509041432586,24513.452130149813,24482.420587546818,24451.409834386704,24420.42259187734,24389.45546582397,24358.51498127341,24327.59137991573,24296.692313319287,24265.81488471442,24234.956767907304,24204.123668656368,24173.3125585206,24142.52277914326,24111.75724192416,24081.012186914795,24050.288111540263,24019.59069229869,23988.91551088483,23958.263986423222,23927.63587020131,23897.02727059925,23866.44200608614,23835.881671348314,23805.3438670412,23774.83144604401,23744.34042895599,23713.872322682586,23683.427463717228,23653.005296114232,23622.60481039326,23592.227732911986,23561.87191303839,23531.535682935395,23501.22344627809,23470.933110955055,23440.66864173689,23410.426059222846,23380.20464653558,23350.004974250936,23319.8280957397,23289.671626287454,23259.536897237827,23229.424640098314,23199.335483965355,23169.269911633895,23139.224294826778,23109.20325667135,23079.20624122191,23049.23503335674,23019.283400632023,22989.354239817414,22959.44867743446,22929.564518960673,22899.705114700373,22869.86734843165,22840.053034293072,22810.262172284645,22780.49465999532,22750.746298572096,22721.023013225655,22691.32183403558,22661.639454588014,22631.9805857912,22602.34375,22572.72964946161,22543.136528558054,22513.567635182586,22484.02267673221,22454.499590355805,22425.00004389045,22395.525968515918,22366.07361891386,22336.64526275749,22307.2381056882,22277.853830173222,22248.4922460206,22219.15158298221,22189.833845388577,22160.53992567884,22131.266970973782,22102.01622483614,22072.786385182586,22043.57724719101,22014.393390098314,21985.23051264045,21956.089492626405,21926.970608029027,21897.876638576778,21868.80408766386,21839.75462312734,21810.727469569287,21781.723621839887,21752.741280430713,21723.784146769663,21694.849719101123,21665.9374707397,21637.044841409177,21608.178502457864,21579.333289442882,21550.510797050563,21521.710747308054,21492.931662570223,21464.17519604401,21435.443278909177,21406.73371664326,21378.046553136704,21349.380193703182,21320.734726123595,21292.11171582397,21263.509026802436,21234.93289150281,21206.376697097377,21177.8436329588,21149.335630266854,21120.846632139514,21092.381729868914,21063.940396769663,21035.521667251873,21007.127296933522,20978.75476942884,20950.40174391386,20922.073136118914,20893.763942532772,20865.476094335205,20837.20945985487,20808.967433286518,20780.74686914794,20752.550971441946,20724.380047401686,20696.23125877809,20668.102806062732,20639.997234901686,20611.91337488296,20583.85140156835,20555.811417368914,20527.793905079587,20499.79694815075,20471.829105220037,20443.883134363296,20415.959518375468,20388.0587400515,20360.177800210673,20332.31786926498,20304.480220037454,20276.666812968164,20248.876360603932,20221.107721793072,20193.362081577714,20165.63661633895,20137.934632490636,20110.25693469101,20082.60140156835,20054.967447916668,20027.35927258895,19999.77428604869,19972.210557116105,19944.668290613296,19917.14769136236,19889.650632022473,19862.17522530431,19834.72496781367,19807.29604108146,19779.8905372191,19752.50708099251,19725.147164676968,19697.808271886704,19670.4884568118,19643.19300093633,19615.91720798221,19588.665028089887,19561.434808052436,19534.229327598314,19507.045558286518,19479.885636118914,19452.748902738764,19425.635621488764,19398.544300093632,19371.474419183054,19344.427653909177,19317.40586230103,19290.4025193118,19263.424171933522,19236.469847261236,19209.537372717696,19182.625592521068,19155.734192123127,19128.86598051264,19102.020921114232,19075.198852996255,19048.39730366339,19021.61900895365,18994.86450286751,18968.133105102996,18941.42661516854,18914.742458157772,18888.079112535113,18861.43793158942,18834.815074906368,18808.21607999766,18781.6424903441,18755.087656542604,18728.55601152856,18702.045258368446,18675.558388927904,18649.09038506554,18622.64345593399,18596.2186914794,18569.816559866573,18543.437178136704,18517.07991719335,18490.747066654963,18464.437851123595,18438.151590297286,18411.88913272472,18385.64758895131,18359.42700286751,18333.22890332397,18307.054109609082,18280.901831694755,18254.76904113998,18228.660734140918,18202.575974367977,18176.512296640918,18150.471281015918,18124.45433198736,18098.462671172754,18072.496115695223,18046.550510592228,18020.627282303372,17994.72575784176,17968.84442298689,17942.9862110838,17917.149461610486,17891.336822624064,17865.545777738764,17839.773620376873,17814.02464448736,17788.297804014514,17762.59231624532,17736.90672547987,17711.246459503745,17685.60796319054,17659.990731800095,17634.39793275983,17608.82579880618,17583.277797284645,17557.751302083332,17532.247863998127,17506.767761001873,17481.309778792136,17455.874795177904,17430.460827773877,17405.071526802436,17379.705246371723,17354.359696863296,17329.03571219569,17303.73296319054,17278.45246664326,17253.196351240636,17227.967016327246,17202.762201544945,17177.577781191478,17152.416937324437,17127.277043831928,17102.15968077013,17077.062222027154,17051.98643053605,17026.9316113647,17001.89897881554,16976.887172284645,16951.896118621255,16926.928831636236,16901.98516502809,16877.064643316946,16852.167888284177,16827.294709737827,16802.443995786518,16777.614378511236,16752.80671377575,16728.024980980805,16703.264769136236,16678.525771008895,16653.807928078182,16629.110933110955,16604.435349367977,16579.778733614232,16555.14530664794,16530.531169534177,16505.943469101123,16481.38027416901,16456.83732004916,16432.3164940309,16407.81895921114,16383.344693644663,16358.89290730337,16334.463687968166,16310.056084679307,16285.670155957398,16261.30349514279,16236.95974514279,16212.637325901218,16188.336288623595,16164.0566991456,16139.799003686798,16115.564877399345,16091.35712195693,16067.172138342698,16043.01131642088,16018.876104576311,15994.761521242977,15970.66917573736,15946.597466058052,15922.547986891386,15898.518470564139,15874.511038448034,15850.524637172284,15826.558491338952,15802.614100538389,15778.690155372191,15754.790174391386,15730.912723841293,15707.059076544943,15683.228661926498,15659.422043246723,15635.634831460675,15611.871474133895,15588.128379564607,15564.4101269897,15540.71248829588,15517.037621430243,15493.386067708334,15469.75553019663,15446.145014044943,15422.558900983146,15398.996591175093,15375.457711551966,15351.940360194289,15328.447331460675,15304.975633485486,15281.528901860955,15258.106331928839,15234.705078125,15211.32460644897,15187.96512903792,15164.62540232912,15141.306633309925,15118.011177434457,15094.73859579822,15071.489795470505,15048.26371576545,15025.060554190075,15001.87693849485,14978.717725889514,14955.577452013109,14932.460586376405,14909.366551088484,14886.295887464888,14863.24490139279,14840.217981917134,14817.213914735486,14794.233072916666,14771.274249473314,14748.337217638109,14725.422240753745,14702.530569698034,14679.659227235486,14656.809749531834,14633.983482560861,14611.179753335675,14588.396535580525,14565.634099953184,14542.89377048221,14520.175459386704,14497.478391268727,14474.804819171348,14452.154450491573,14429.52902621723,14406.924815660112,14384.339638927902,14361.776736598782,14339.235362535112,14316.717952656834,14294.225465238764,14271.754557291666,14249.304826486423,14226.87723841292,14204.471975948034,14182.092374765918,14159.733687382959,14137.395621196161,14115.079580699907,14092.78242772706,14070.505398525282,14048.249400163857,14026.012252750468,14003.798806179775,13981.608504506086,13959.440842989232,13937.297328534643,13915.180133719568,13893.081994674625,13871.006685978464,13848.955765742041,13826.92766122425,13804.918363764045,13782.930777446161,13760.965421640918,13739.019289852527,13717.09881934691,13695.20158883427,13673.328702890918,13651.47577247191,13629.644341058052,13607.834452539793,13586.050503277154,13564.287914033239,13542.548996371723,13520.831307057584,13499.133346500468,13477.45668744148,13455.800276509832,13434.16568644663,13412.554665554775,13390.967842930711,13369.40192679073,13347.85895804073,13326.336954295411,13304.83477440309,13283.35391795412,13261.893967989232,13240.46066684223,13219.048199028559,13197.658810276218,13176.292259187734,13154.94686329588,13133.624129506086,13112.323999297752,13091.04653119148,13069.789947624064,13048.55622366573,13027.345081343634,13006.154494382023,12984.983862944757,12963.83441596442,12942.709064840825,12921.606822038857,12900.526736598782,12879.469027972846,12858.432957338484,12837.419497600655,12816.427522237827,12795.459203827248,12774.513064723782,12753.589039091761,12732.685883368446,12711.803085498595,12690.942320634364,12670.103105980805,12649.289128335675,12628.49882227294,12607.730666257023,12586.986825550093,12566.26245025749,12545.557979283707,12524.877655372191,12504.217857560861,12483.579134480337,12462.96477059925,12442.370179365636,12421.797752808989,12401.249517205057,12380.723643785112,12360.218442766854,12339.735918480805,12319.278411750936,12298.844342521068,12278.431121254682,12258.037606800093,12237.664757432116,12217.313026685393,12196.982531601123,12176.67414267322,12156.388693820225,12136.124473314607,12115.882307759832,12095.660273291198,12075.461998185861,12055.2871386353,12035.132205348782,12014.999070985486,11994.887252750468,11974.7988573853,11954.732165847377,11934.690857619382,11914.671553136704,11894.6738573853,11874.698260475187,11854.747205641386,11834.817049976591,11814.907713014982,11795.019004564607,11775.150493036048,11755.3047460206,11735.48170499766,11715.678992567884,11695.895862593634,11676.136309105805,11656.399256788389,11636.684127750468,11616.992882432116,11597.322426556648,11577.673718398877,11558.04694815075,11538.442415730337,11518.859872425093,11499.298279494382,11479.757834445225,11460.238273934925,11440.741514513109,11421.267497659175,11401.817540086611,11382.388554833802,11362.979598256086,11343.591555477527,11324.222824496723,11304.877523700843,11285.553604868914,11266.250936329589,11246.971207865168,11227.716562792602,11208.483723958334,11189.276217228464,11170.090845915262,11150.92619820927,11131.78123536985,11112.658642029495,11093.557079529495,11074.47686241807,11055.41761031133,11036.380742333802,11017.362659468634,10998.367655664793,10979.399307993914,10960.451252340825,10941.525551556648,10922.620457338484,10903.737783824907,10884.876126521536,10866.038616280432,10847.221024988296,10828.4256934691,10809.652497366573,10790.90262903792,10772.170689957866,10753.463775749064,10734.77922372425,10716.115709854868,10697.475245786516,10678.856851299157,10660.257198033707,10641.679226650282,10623.120391502809,10604.585842404027,10586.07380179073,10567.582974894663,10549.116960732677,10530.673330699907,10512.24968545178,10493.84734170178,10475.470564138577,10457.11299596208,10438.778155723314,10420.463314899345,10402.17156045178,10383.901465941011,10365.653645833334,10347.425400866105,10329.218340355805,10311.032669124532,10292.870457338484,10274.728435159175,10256.606558696161,10238.510028967698,10220.43326457163,10202.378759948502,10184.342828300561,10166.329595330057,10148.337341994382,10130.366960732677,10112.42019253277,10094.497117860486,10076.59734170178,10058.717916081461,10040.858504506086,10023.022640156834,10005.20631437266,9987.41635943352,9969.650354049625,9951.902782654495,9934.175283824907,9916.470937207398,9898.789413623595,9881.129140332398,9863.489261470037,9845.8710644897,9828.276451310861,9810.704119850187,9793.153528792134,9775.622512874532,9758.113573852996,9740.62535843867,9723.159658824907,9705.71678224485,9688.296377574907,9670.895218867041,9653.516436973314,9636.15623536985,9618.818052141854,9601.500226767323,9584.202510533707,9566.926351825843,9549.671662862827,9532.438589946161,9515.227037979868,9498.038440718634,9480.872571395132,9463.72693556882,9446.602806062734,9429.500080465825,9412.418414969568,9395.36296670178,9378.329383192884,9361.314789618446,9344.322528967698,9327.355359023877,9310.413082279963,9293.492699555243,9276.592835615636,9259.71284673455]}},\"id\":\"e2cc42ab-a992-4694-b501-f49c2d34d4aa\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[2000]},\"y\":[191342.09809362935,190928.45632239382,190819.38573841698,190432.31998069497,190162.7368484556,190050.99722490346,189971.13561776062,189852.8823600386,189797.29186776062,189706.6475627413,189624.10762548263,189534.44992760618,189453.88887548263,189344.28607625482,189271.71971525098,189195.42627895752,189080.06069015444,189005.34652509654,188933.84833494207,188847.78680019305,188714.7730453668,188640.85967664092,188573.64442567568,188495.5366795367,188411.18472490346,188325.83699324325,188240.33313223938,188154.82504826254,188069.3778957529,187983.96730212355,187898.5933880309,187813.27195945947,187727.9984314672,187642.74034749035,187557.5185810811,187472.38018822393,187387.25760135136,187302.18255308882,187217.13429054053,187132.12065637065,187047.16698841698,186962.2303330116,186877.32191119692,186792.47152509654,186707.64780405405,186622.86812258686,186538.12391409266,186453.40986969112,186368.73636583012,186284.10412644787,186199.49565637065,186114.9489623552,186030.40395752896,185945.92543436293,185861.46633687257,185777.0242519305,185692.6306708494,185608.27618243243,185523.96887065636,185439.68448359074,185355.4248310811,185271.22152509654,185187.0155646718,185102.87439671814,185018.75639478763,184934.66083494207,184850.61003861003,184766.59568050192,184682.6097972973,184598.6549227799,184514.73998552124,184430.84881756757,184346.99625965251,184263.18098455598,184179.38670366796,184095.63163610038,184011.90202702704,183928.21102799228,183844.55152027027,183760.92133204633,183677.3239623552,183593.76242760618,183510.2384169884,183426.72502413127,183343.26544401544,183259.8186534749,183176.4152992278,183093.03233590734,183009.68979247104,182926.3734314672,182843.09181949808,182759.8384411197,182676.6176399614,182593.43351833976,182510.25929054053,182427.13175675675,182344.03486969112,182260.96850868725,182177.93110521237,182094.91879826254,182011.9416023166,181928.99239864864,181846.07372104248,181763.1833976834,181680.32299710426,181597.4971042471,181514.69461872586,181431.9185569498,181349.18400096524,181266.46163127414,181183.78462837837,181101.12801640926,181018.49891409266,180935.91312741314,180853.34712837837,180770.79958976834,180688.30610521237,180605.81768822393,180523.3676399614,180440.9403957529,180358.55212355213,180276.18158783784,180193.84640444015,180111.5320945946,180029.24806949808,179946.99070945947,179864.77364864864,179782.5785472973,179700.40395752896,179618.26990830115,179536.14937258686,179454.07034266408,179372.01218629343,179289.99119208494,179207.98166023166,179126.00494691118,179044.05984555985,178962.14527027027,178880.2561534749,178798.38597972973,178716.54741795367,178634.72840250965,178552.95511583012,178471.201496139,178389.46681949808,178307.77171814672,178226.09688706565,178144.44594594595,178062.82613416988,177981.23371138997,177899.6673503861,177818.12258687257,177736.6135376448,177655.1263272201,177573.6607142857,177492.22502413127,177410.82468629343,177329.43822393822,177248.08361486485,177166.7602557915,177085.45656370657,177004.1820704633,176922.93110521237,176841.7035472973,176760.5102557915,176679.34712837837,176598.1919642857,176517.07915057914,176435.98745173746,176354.91928088802,176273.86812258686,176192.85569498068,176111.86305501932,176030.8975627413,175949.9597007722,175869.05115830115,175788.1661438224,175707.30067567568,175626.46645752896,175545.6480453668,175464.86329633204,175384.10183397683,175303.37994691118,175222.65576737453,175141.98250482624,175061.31853281852,174980.68351833976,174900.0748069498,174819.48455598456,174738.93255308882,174658.40407818533,174577.89032335908,174497.4185569498,174416.94799710426,174336.51218629343,174256.10629826254,174175.7216457529,174095.371742278,174015.02859555985,173934.71899131275,173854.44823841698,173774.17748552124,173693.93701737453,173613.72972972973,173533.5510376448,173453.37874034749,173373.23938223938,173293.12922297296,173213.04452220077,173132.97586872586,173052.940757722,172972.9165057915,172892.93967181467,172812.9671814672,172733.02702702704,172653.10798745175,172573.21187258686,172493.34797297296,172413.503257722,172333.6818291506,172253.88549710426,172174.10581563707,172094.35967664092,172014.63863416988,171934.93653474902,171855.25663610038,171775.60798745175,171695.9786438224,171616.3811534749,171536.80007239382,171457.24083011583,171377.7035472973,171298.1929295367,171218.70258204633,171139.2515685328,171059.80658783784,170980.3918918919,170901.00711872586,170821.6410472973,170742.29548745175,170662.9728523166,170583.68267374518,170504.40986969112,170425.16023166024,170345.9358108108,170266.73250482624,170187.55176158302,170108.39708011583,170029.26363416988,169950.1475627413,169871.07335907337,169792.00748069497,169712.98214285713,169633.95234073358,169554.97019787645,169476.0008445946,169397.04500482624,169318.1304295367,169239.24638030888,169160.3696911197,169081.5143581081,169002.67953667953,168923.88501447876,168845.10714285713,168766.34350868725,168687.61196911198,168608.9091457529,168530.2171814672,168451.55489864864,168372.91795366796,168294.30755308882,168215.7088561776,168137.13573841698,168058.58892374518,167980.0650337838,167901.56262065636,167823.07890926642,167744.62451737453,167666.1958252896,167587.7841457529,167509.3947876448,167431.0230453668,167352.69027509654,167274.37391409266,167196.08361486485,167117.80779440154,167039.55441602317,166961.32625482624,166883.12608590734,166804.9419642857,166726.79041988417,166648.6406853282,166570.53607625482,166492.43822393822,166414.37029440154,166336.3326496139,166258.30586389962,166180.31069015444,166102.3334942085,166024.37693050192,165946.45668436293,165868.54259169885,165790.66228281852,165712.8009169884,165634.9646476834,165557.15130308882,165479.35847007722,165401.57927123553,165323.83373552124,165246.12077702704,165168.4190395753,165090.7385376448,165013.07963320464,164935.44353281852,164857.82420366796,164780.24613899612,164702.66795366796,164625.13163610038,164547.6065395753,164470.1097972973,164392.63622104248,164315.1849662162,164237.75386100388,164160.33916505793,164082.9457046332,164005.58602799228,163928.24770752896,163850.92084942086,163773.61365830115,163696.34640444015,163619.09749034749,163541.85847007722,163464.65069980695,163387.47550675675,163310.30791505793,163233.17652027027,163156.05272683396,163078.96271718148,163001.89080598456,162924.84073359074,162847.82323841698,162770.81430984556,162693.83240830115,162616.88091216216,162539.9366554054,162463.02087355213,162386.13163610038,162309.25953185328,162232.41023166024,162155.5855453668,162078.7841457529,162002.0012065637,161925.2487934363,161848.51218629343,161771.79090250965,161695.09555984556,161618.434242278,161541.77738899612,161465.1550434363,161388.5493484556,161311.96657818533,161235.41180019305,161158.86751930503,161082.35907335908,161005.86836389962,160929.39876930503,160852.95113416988,160776.53474903476,160700.1294642857,160623.76134169885,160547.4009411197,160471.07046332047,160394.75434362935,160318.46766409266,160242.1989623552,160165.95209942086,160089.72261100388,160013.52787162163,159937.34736969112,159861.1883445946,159785.05164092663,159708.9431708494,159632.8494208494,159556.7795608108,159480.73648648648,159404.71488899612,159328.71681949808,159252.74215733592,159176.78499034749,159100.85291988417,159024.9388272201,158949.04367760618,158873.1791747104,158797.32709942086,158721.49891409266,158645.71126930503,158569.9313465251,158494.17398648648,158418.4436534749,158342.73262548263,158267.04476351352,158191.3833252896,158115.74565637065,158040.11570945947,157964.5185810811,157888.94751447876,157813.38513513515,157737.8507480695,157662.3350627413,157586.8412162162,157511.3651061776,157435.92048745175,157360.50108590734,157285.10086872586,157209.7216457529,157134.3623310811,157059.03125,156983.7319015444,156908.43822393822,156833.1648166023,156757.92615830115,156682.69944498068,156607.49819015444,156532.31648166024,156457.15637065636,156382.02232142858,156306.91373069497,156231.8198600386,156156.75144787645,156081.70499517376,156006.67965733592,155931.66662644787,155856.68967181467,155781.72936776062,155706.78100868725,155631.88127413127,155556.97888513515,155482.10352316604,155407.25627413127,155332.4320704633,155257.6340492278,155182.85617760618,155108.09314671814,155033.3511100386,154958.63791023166,154883.95222007722,154809.2799227799,154734.62319015444,154660.00361969112,154585.39575289574,154510.81611969112,154436.25398166024,154361.71778474902,154287.19968629343,154212.71573359074,154138.2445704633,154063.79922779923,153989.36570945947,153914.97055984556,153840.5756515444,153766.21814671814,153691.88863416988,153617.56515444015,153543.2655646718,153469.00494691118,153394.7442084942,153320.52123552124,153246.3181708494,153172.1192084942,153097.96862934364,153023.81611969112,152949.69823841698,152875.6011100386,152801.5225627413,152727.46850868725,152653.43532818533,152579.4247104247,152505.44208494207,152431.47647200772,152357.5353523166,152283.61836389962,152209.72104247104,152135.8445945946,152061.98938223938,151988.15444015444,151914.34109555985,151840.56599903476,151766.7935569498,151693.05320945947,151619.3354247104,151545.6340492278,151471.96971525098,151398.30622586873,151324.67338320464,151251.06310328186,151177.482746139,151103.91843629343,151030.37729247104,150956.861003861,150883.34978281852,150809.8765685328,150736.41976351352,150662.98708976834,150589.57661679536,150516.17869208494,150442.8207046332,150369.47586872586,150296.1574565637,150222.84809362935,150149.57504826254,150076.3248069498,150003.08940637065,149929.87874034749,149856.68677606178,149783.52087355213,149710.3758445946,149637.2554295367,149564.14973455598,149491.0645511583,149418.0061534749,149344.96862934364,149271.9559604247,149198.95837355213,149125.9884169884,149053.03909266408,148980.1048503861,148907.19353281852,148834.31020752896,148761.44353281852,148688.60171332047,148615.77750965251,148542.98081563707,148470.20330598456,148397.45378861003,148324.71368243243,148252.0098938224,148179.32637548263,148106.66252413127,148034.00663610038,147961.38972007722,147888.78800675675,147816.20837355213,147743.65516409266,147671.1258445946,147598.6064189189,147526.1147442085,147453.64876930503,147381.20571911198,147308.7795608108,147236.3753619691,147164.00048262547,147091.64201254825,147019.3063465251,146946.99070945947,146874.70427123553,146802.43556949808,146730.18967181467,146657.96090733592,146585.75591216216,146513.56599903476,146441.4005791506,146369.26447876447,146297.15407818533,146225.05562258686,146152.9884169884,146080.92941602317,146008.9050434363,145936.88887548263,145864.90721525098,145792.9390685328,145720.99987934364,145649.0751689189,145577.17941602317,145505.30369208494,145433.45234073358,145361.62391409266,145289.8166023166,145218.0399372587,145146.27811293435,145074.54777992278,145002.83156370657,144931.14949324325,144859.49288127414,144787.84845559846,144716.22598938225,144644.63018822393,144573.04790057914,144501.48262548263,144429.94920366796,144358.42869208494,144286.93231177607,144215.4498069498,144143.99239864864,144072.56515444015,144001.15311293435,143929.76351351352,143858.39840733592,143787.0568291506,143715.73262548263,143644.4354488417,143573.15818050192,143501.89901061775,143430.6694015444,143359.45041023166,143288.25458494207,143217.08578667953,143145.9395511583,143074.81358590734,143003.7113899614,142932.63272200772,142861.5739623552,142790.5435569498,142719.54090250965,142648.5526061776,142577.58530405405,142506.63694498068,142435.71561293435,142364.80586389962,142293.9289333977,142223.08361486485,142152.23696911198,142081.42374517376,142010.63597972973,141939.86136583012,141869.12065637065,141798.4000965251,141727.7001689189,141657.0189430502,141586.3666747104,141515.73081563707,141445.11872586873,141374.53052606178,141303.96090733592,141233.40769787645,141162.8806708494,141092.3840492278,141021.89044401544,140951.43098455598,140880.99650096524,140810.58433880308,140740.19461872586,140669.8251689189,140599.47381756757,140529.15226833976,140458.84375,140388.56020752896,140318.29765926642,140248.06274131275,140177.8416988417,140107.6488899614,140037.4716457529,139967.31841216216,139897.19461872586,139827.0780646718,139756.98057432432,139686.9049227799,139616.8618484556,139546.8383204633,139476.8367519305,139406.85472972973,139336.89949324325,139266.96199324325,139197.0456081081,139127.15250965251,139057.28221525098,138987.42796814672,138917.6040057915,138847.80067567568,138778.02654440154,138708.26242760618,138638.5337837838,138568.82046332047,138499.12970559846,138429.46380308882,138359.81877413127,138290.19341216216,138220.58819980695,138151.01785714287,138081.46030405405,138011.93569015444,137942.42290057914,137872.93038127414,137803.4629584942,137734.01291023166,137664.57866795367,137595.1820704633,137525.8041747104,137456.4429295367,137387.10750482624,137317.79198841698,137248.49288127414,137179.22888513515,137109.96319980695,137040.74107142858,136971.54331563707,136902.35171332047,136833.1919642857,136764.04922779923,136694.93327702704,136625.83880308882,136556.76303088802,136487.70656370657,136418.67748552124,136349.67121138997,136280.6919642857,136211.72236969112,136142.78185328186,136073.8589527027,136004.96368243243,135936.08458011583,135867.2240588803,135798.3918918919,135729.58747586873,135660.7997104247,135592.0366795367,135523.29621138997,135454.59025096524,135385.89032335908,135317.20813223938,135248.5526061776,135179.9251930502,135111.3227557915,135042.72550675675,134974.16469594595,134905.6221042471,134837.09568050192,134768.59278474902,134700.1167953668,134631.66373069497,134563.23612451737,134494.82384169885,134426.43810328186,134358.06479247104,134289.71850868725,134221.39708011583,134153.08880308882,134084.8169642857,134016.55851833976,133948.32625482624,133880.11776061775,133811.92953667953,133743.7590492278,133675.62644787645,133607.5013272201,133539.40842181467,133471.33433880308,133403.2800434363,133335.25337837837,133267.24336389962,133199.25953185328,133131.2911438224,133063.34230212355,132995.4218146718,132927.51773648648,132859.64128861003,132791.78100868725,132723.9458252896,132656.1303088803,132588.33687258686,132520.5611727799,132452.81225868725,132385.08071911198,132317.38091216216,132249.7030646718,132182.04584942086,132114.40311293435,132046.7928330116,131979.19835907337,131911.62994691118,131844.0814430502,131776.5583976834,131709.05694980695,131641.57637548263,131574.12439671814,131506.69727316604,131439.28366312743,131371.90444015444,131304.53716216216,131237.18689671814,131169.86112451737,131102.55562258686,131035.27485521235,130968.00542953669,130900.7652027027,130833.54621138996,130766.34628378379,130699.17241795367,130632.01266891892,130564.88187741312,130497.7684604247,130430.67507239382,130363.60448841698,130296.55924227799,130229.53149131274,130162.52907818533,130095.54633204633,130028.60002413127,129961.67615830115,129894.76870173746,129827.89406370657,129761.02980212355,129694.19087837837,129627.37512065638,129560.58458011583,129493.8055019305,129427.04862451738,129360.31020752896,129293.59809362935,129226.91457528957,129160.24276061777,129093.60171332046,129026.97912644787,128960.36776061777,128893.78921332046,128827.22671332046,128760.68810328185,128694.1722972973,128627.67386583012,128561.2076496139,128494.7684604247,128428.34206081081,128361.93930984556,128295.56406853283,128229.2088561776,128162.87258687259,128096.56213803089,128030.27159749034,127964.00422297297,127897.75072393822,127831.53293918919,127765.33373552124,127699.15685328185,127633.00048262549,127566.8585907336,127500.7508445946,127434.65986969112,127368.59206081081,127302.54838320463,127236.51809845559,127170.513996139,127104.53305984556,127038.57625482626,126972.63972007722,126906.72442084942,126840.82963320463,126774.96199324324,126709.1065395753,126643.28426640926,126577.48286679537,126511.70016891892,126445.9383445946,126380.20451254827,126314.48745173746,126248.79548745173,126183.11763996139,126117.47043918919,126051.83445945945,125986.22357625482,125920.63525579151,125855.06262065638,125789.51737451738,125723.99179536679,125658.49674227799,125593.01785714286,125527.5633445946,125462.14490830115,125396.74324324324,125331.36148648648,125265.99481177607,125200.66421332046,125135.34495656371,125070.05393339768,125004.79090250966,124939.54440154441,124874.31611969112,124809.10714285714,124743.92724420849,124678.75591216216,124613.61776061777,124548.49638030888,124483.39587355213,124418.3289092664,124353.27569980695,124288.2388996139,124223.23178088803,124158.2438465251,124093.28342181467,124028.33059845559,123963.40263030888,123898.50036196911,123833.6241554054,123768.77594111969,123703.94196428571,123639.14008204633,123574.35243725868,123509.58687258688,123444.84942084942,123380.13477316602,123315.4284507722,123250.74927606178,123186.09423262549,123121.46187258688,123056.85762548262,122992.27171814672,122927.71030405405,122863.1591457529,122798.64913127413,122734.1500965251,122669.6813465251,122605.22900579151,122540.7882480695,122476.37958494209,122411.99674227799,122347.63187741312,122283.29379826254,122218.97466216216,122154.6690395753,122090.39756274132,122026.13791023166,121961.91276544401,121897.6953426641,121833.51809845559,121769.34604247104,121705.20547779923,121641.079753861,121576.97719594595,121512.89297779923,121448.84157818533,121384.81141409266,121320.79379826254,121256.80803571429,121192.8338561776,121128.87741312741,121064.95740830115,121001.05272683398,120937.1731418919,120873.32191119691,120809.48419401544,120745.67386583012,120681.88441119691,120618.11522683398,120554.36414092664,120490.64708011583,120426.9473938224,120363.27352799228,120299.61377895753,120235.97586872587,120172.36667471043,120108.77606177607,120045.20523648648,119981.65673262549,119918.13127413127,119854.62174227799,119791.15094111969,119727.68424227799,119664.24722490348,119600.83361486487,119537.44486003861,119474.06889478765,119410.73129826254,119347.39659749034,119284.10883204633,119220.82818532818,119157.57094594595,119094.32927123552,119031.12355212355,118967.93303571429,118904.76496138996,118841.61788127413,118778.49746621621,118715.40142374518,118652.32516891892,118589.2722007722,118526.23660714286,118463.22719594595,118400.24227799228,118337.27280405405,118274.329753861,118211.39587355213,118148.48455598456,118085.60955598456,118022.7438465251,117959.90166505791,117897.0739623552,117834.28438706564,117771.50301640926,117708.74722490348,117646.00916988417,117583.3026061776,117520.61438223938,117457.93774131274,117395.28269787645,117332.65528474904,117270.05320945945,117207.4716457529,117144.91421332046,117082.38887548262,117019.89201254827,116957.40842181467,116894.95065154441,116832.51134169885,116770.09495656371,116707.69473938223,116645.32058397683,116582.9638030888,116520.63127413127,116458.31117277993,116396.02521718146,116333.7450530888,116271.50241312741,116209.28342181467,116147.08735521235,116084.90492277993,116022.75132722007,115960.62186293436,115898.5168918919,115836.42808880309,115774.36546814672,115712.32323841698,115650.30489864865,115588.31213803089,115526.33928571429,115464.40190637065,115402.47212837837,115340.57432432432,115278.69582528957,115216.84978281854,115155.00953185328,115093.1953426641,115031.41131756757,114969.64527027027,114907.90250965251,114846.18291505791,114784.47900579151,114722.79693532818,114661.14756274132,114599.51170366796,114537.888996139,114476.3010376448,114414.72502413127,114353.16952220077,114291.6369449807,114230.12656853283,114168.63163610038,114107.16276544401,114045.7146476834,113984.28293918919,113922.88103281854,113861.49517374518,113800.13380791506,113738.795246139,113677.47828185328,113616.17772683398,113554.91059362935,113493.66264478765,113432.4465492278,113371.2421573359,113310.05924227799,113248.91312741312,113187.77208011583,113126.66107625482,113065.57625482626,113004.51206563707,112943.46850868726,112882.44932432432,112821.46223455599,112760.49987934362,112699.54898648648,112638.62801640926,112577.73033301158,112516.8552123552,112455.99034749034,112395.16228281854,112334.35376447876,112273.5703426641,112212.79597007722,112152.05851833976,112091.32806467182,112030.62475868726,111969.94353281854,111909.28185328185,111848.64864864865,111788.0382480695,111727.43363899614,111666.8548503861,111606.29428088803,111545.75820463321,111485.23624517374,111424.73974420849,111364.25796332046,111303.79717664093,111243.36196911197,111182.9518581081,111122.56310328185,111062.19968629343,111001.85678088803,110941.54017857143,110881.25060328185,110820.98298745173,110760.73684845559,110700.5098938224,110640.30972490348,110580.12487934362,110519.95982142857,110459.83506274132,110399.71923262549,110339.62608590734,110279.55164092664,110219.50482625482,110159.47430019305,110099.47236969112,110039.49288127413,109979.53680019305,109919.5999034749,109859.68713803089,109799.79548745173,109739.92121138996,109680.06491312741,109620.23322876448,109560.43038127413,109500.6418918919,109440.88887548262,109381.15311293436,109321.43448359074,109261.74131274132,109202.06298262549,109142.41879826254,109082.77956081081,109023.1760376448,108963.59881756757,108904.05296814672,108844.53052606178,108785.03052606178,108725.55200289575,108666.10050675676,108606.66807432432,108547.24770752896,108487.87053571429,108428.50120656371,108369.15890444015,108309.84037162163,108250.53969594595,108191.26170366796,108131.99951737451,108072.76677123552,108013.55272683398,107954.36969111969,107895.20608108108,107836.06117277993,107776.93979247104,107717.84206081081,107658.77328667954,107599.71621621621,107540.67941602317,107481.6714527027,107422.68182915058,107363.70958011583,107304.7701496139,107245.8466457529,107186.94027509652,107128.05646718146,107069.18882722007,107010.34978281854,106951.54391891892,106892.75675675676,106833.98757239382,106775.23636583012,106716.51291023166,106657.81032818533,106599.14177123552,106540.4880550193,106481.8581081081,106423.25627413127,106364.66698841698,106306.10050675676,106247.55320945945,106189.02944015444,106130.52039092664,106072.03848938223,106013.56527509652,105955.1340492278,105896.71730212355,105838.3273407336,105779.95559845559,105721.6007480695,105663.2734073359,105604.96923262549,105546.68424227799,105488.42169401544,105430.18098455599,105371.96404440154,105313.7750965251,105255.6048503861,105197.45933880309,105139.32589285714,105081.2249034749,105023.14406370657,104965.09061293436,104907.0497104247,104849.04597007722,104791.06262065638,104733.10135135135,104675.15974903475,104617.23166023166,104559.33892374518,104501.4716457529,104443.61233108108,104385.7841457529,104327.97104247104,104270.19136100386,104212.42507239382,104154.68038127413,104096.96187258688,104039.26894305019,103981.59616312741,103923.93870656371,103866.30646718146,103808.69691119691,103751.11076254827,103693.54452220077,103635.99806949806,103578.48105694981,103520.97598938223,103463.49770752896,103406.04126447876,103348.60726351352,103291.20451254827,103233.82504826254,103176.45789092664,103119.11631274132,103061.79633204633,103004.49770752896,102947.21826737451,102889.95704633204,102832.72357625482,102775.51001447876,102718.32516891892,102661.15757722007,102604.02099420849,102546.90625,102489.81792953669,102432.74263996139,102375.6944980695,102318.67374517374,102261.67169401544,102204.69027509652,102147.73455598456,102090.80115830115,102033.88658301158,101976.99867277993,101920.12463803089,101863.2771476834,101806.43979247104,101749.64177123552,101692.85291988417,101636.08506274132,101579.34314671815,101522.61583011583,101465.92579633204,101409.24372586873,101352.60026544401,101295.96730212355,101239.36522683398,101182.78342181467,101126.22767857143,101069.68737934362,101013.18110521235,100956.68593146717,100900.21681949806,100843.76616795367,100787.33349420849,100730.93532818533,100674.56406853283,100618.20692567568,100561.87825772201,100505.57082528957,100449.28776544401,100393.03100868726,100336.78667953669,100280.56913610038,100224.36824324324,100168.18581081081,100112.02992277993,100055.9054054054,99999.79343629343,99943.70547779923,99887.64370173746,99831.59531853283,99775.58168436293,99719.58252895753,99663.6048503861,99607.65347490348,99551.71657818533,99495.80272683398,99439.91807432432,99384.04790057916,99328.20608108108,99272.37970559846,99216.57782335907,99160.80610521235,99105.04295366796,99049.31430984556,98993.61136583012,98937.92519305019,98882.2684604247,98826.6311534749,98771.01339285714,98715.41976351352,98659.84423262549,98604.29536679537,98548.7652027027,98493.25977316602,98437.77907818533,98382.31599903475,98326.8758445946,98271.46730212355,98216.07432432432,98160.70716698842,98105.35098938223,98050.02123552124,97994.71609555985,97939.42193532818,97884.15938706564,97828.91710907336,97773.69594594595,97718.49650096525,97663.32347972973,97608.16807432432,97553.03607625482,97497.92724420849,97442.8495415058,97387.79186776062,97332.75036196911,97277.74324324324,97222.74963803089,97167.79307432432,97112.85472972973,97057.94413610038,97003.05127895753,96948.1755550193,96893.33771718146,96838.51797779923,96783.71283783784,96728.93786196911,96674.18158783784,96619.43219111969,96564.71778474904,96510.02364864865,96455.34905888031,96400.69847972973,96346.06708494209,96291.45511583012,96236.86969111969,96182.29572876448,96127.7561534749,96073.2298503861,96018.72345559846,95964.24179536679,95909.77931949806,95855.34712837837,95800.94642857143,95746.5682915058,95692.21537162163,95637.8869449807,95583.5785472973,95529.29198841698,95475.03499034749,95420.78378378379,95366.56382722007,95312.35557432432,95258.17989864865,95204.0213561776,95149.8864623552,95095.77244208494,95041.67893339768,94987.60328185328,94933.56370656371,94879.53728281854,94825.53474903475,94771.54983108108,94717.60231660232,94663.6661438224,94609.76001447876,94555.87198359074,94502.01966698842,94448.18219111969,94394.36257239382,94340.58494208494,94286.8145511583,94233.06889478765,94179.35472972973,94125.64683880309,94071.96923262549,94018.30248552124,93964.66264478765,93911.05863899614,93857.46766409266,93803.90226833976,93750.35376447876,93696.8293918919,93643.33108108108,93589.84616312741,93536.37777509652,93482.9494449807,93429.53269787645,93376.14044401544,93322.76411679537,93269.42531370657,93216.10798745173,93162.81382722007,93109.53499034749,93056.28438706564,93003.05574324324,92949.85195463321,92896.66807432432,92843.51013513513,92790.37391409266,92737.2590492278,92684.1690395753,92631.10183397683,92578.05538127413,92525.02063223938,92472.01218629343,92419.03366312741,92366.06805019305,92313.12536196911,92260.2076496139,92207.31817084942,92154.45137548262,92101.60231660232,92048.7853523166,91995.98757239382,91943.2146476834,91890.46766409266,91837.73467664093,91785.02787162163,91732.34447393822,91679.68520752896,91627.04584942084,91574.42567567568,91521.83928571429,91469.26363416988,91416.7109073359,91364.17905405405,91311.67664092664,91259.19063706564,91206.72092181467,91154.27980212355,91101.86317567568,91049.47055984556,90997.09749034749,90944.74843146717,90892.42820945945,90840.12258687259,90787.84447393822,90735.59326737451,90683.3536438224,90631.14973455599,90578.96319980695,90526.80115830115,90474.65407818533,90422.54041988417,90370.43979247104,90318.36691602317,90266.31346525096,90214.28800675676,90162.2804054054,90110.29210907336,90058.32915057916,90006.38537644787,89954.45982142857,89902.56575772201,89850.68472490348,89798.83940637065,89747.00941119691,89695.20041023166,89643.42193532818,89591.65842181467,89539.92133204633,89488.21513030888,89436.52569980695,89384.85243725868,89333.2035472973,89281.57987451738,89229.97007722007,89178.38501447876,89126.8186534749,89075.28426640926,89023.78004343629,88972.29862451738,88920.82577220077,88869.39394305019,88817.96597490348,88766.56696428571,88715.18581081081,88663.83035714286,88612.4950530888,88561.18448359074,88509.90637065638,88458.6463561776,88407.40637065638,88356.18930984556,88304.99577702703,88253.81961872587,88202.66566119691,88151.54391891892,88100.43496621621,88049.3565395753,87998.2870415058,87947.25856660232,87896.2385376448,87845.24903474904,87794.28800675676,87743.34857625482,87692.4260376448,87641.52871621621,87590.65818050194,87539.80658783784,87488.98250482626,87438.1714527027,87387.38875482626,87336.62922297297,87285.89333976834,87235.1883445946,87184.49843146717,87133.82673745173,87083.17808880309,87032.55176158302,86981.9494449807,86931.35460907336,86880.80091698842,86830.26532335907,86779.75929054055,86729.26942567568,86678.81189671815,86628.37451737451,86577.95523648648,86527.55936293436,86477.19280888031,86426.84761100386,86376.52304536679,86326.22273166024,86275.93786196911,86225.6895511583,86175.45909749034,86125.24891409266,86075.05610521235,86024.88972007722,85974.75193050194,85924.63429054055,85874.5283542471,85824.4588561776,85774.41131756757,85724.38670366796,85674.3902027027,85624.41638513513,85574.45451254827,85524.52594111969,85474.60183397683,85424.71609555985,85374.8536438224,85325.00760135135,85275.18496621621,85225.38175675676,85175.60147200772,85125.84073359074,85076.09833494209,85026.37753378379,84976.68725868726,84927.01049710425,84877.36546814672,84827.74565637065,84778.14876930501,84728.57480694981,84679.0234073359,84629.49360521235,84579.97840250966,84530.49457046331,84481.04162644787,84431.60111003861,84382.18556949806,84332.78945463321,84283.41891891892,84234.07251447876,84184.75542953669,84135.4638030888,84086.19606660232,84036.94799710425,83987.72538610038,83938.52980212355,83889.33868243243,83840.18508687259,83791.04838320463,83741.93979247104,83692.84652509652,83643.78028474904,83594.73419401544,83545.70692567568,83496.69992760618,83447.71778474904,83398.75856660232,83349.82203185328,83300.90275096525,83252.01737451738,83203.15890444015,83154.31696428571,83105.49034749034,83056.6965492278,83007.92977799228,82959.1747707529,82910.45903716216,82861.75343870657,82813.07547055985,82764.42284025096,82715.78812741312,82667.17199565638,82618.59079391892,82570.02244208494,82521.4782215251,82472.96120897683,82424.47152509652,82376.01037644787,82327.57384169885,82279.1549831081,82230.76284990348,82182.3914695946,82134.0390323359,82085.70626206564,82037.39406370657,81989.10623793436,81940.83445945945,81892.59598214286,81844.3684242278,81796.17326254827,81748.00030164093,81699.85659990348,81651.73093629343,81603.62988658302,81555.55568291506,81507.51212596525,81459.47834218146,81411.47339527027,81363.49318291506,81315.53070704633,81267.5842784749,81219.66234314672,81171.75645511583,81123.87506032818,81076.01634893822,81028.19262789575,80980.39038368726,80932.60376447876,80884.83856177607,80837.10183397683,80789.39165057916,80741.71138996139,80694.04247104247,80646.39714044401,80598.77189913127,80551.16729005791,80503.5822876448,80456.02726833976,80408.48316843629,80360.97339527027,80313.4835907336,80266.013996139,80218.57408301158,80171.16143822393,80123.78106901544,80076.42452944015,80029.09097490348,79981.77298503861,79934.47683397683,79887.2051761583,79839.95071187259,79792.72152509652,79745.51309121621,79698.31521476834,79651.15353523166,79604.00488658302,79556.88760859074,79509.78137065638,79462.71573359074,79415.67090974904,79368.65510376448,79321.65522442084,79274.67151303089,79227.71555260618,79180.78734314672,79133.87699083012,79086.99318291506,79040.13272200772,78993.28589527027,78946.47629102317,78899.6759773166,78852.91801399614,78806.16716940154,78759.44787644787,78712.75723938223,78666.08566602317,78619.4486003861,78572.83711389962,78526.236003861,78479.6710907336,78433.10961631274,78386.57462596525,78340.06201737451,78293.57191119691,78247.10913368726,78200.67706322393,78154.26164333976,78107.87023407336,78061.49535472973,78015.15594835907,77968.82740106178,77922.53227557916,77876.25343870657,77830.00512789575,77783.7726230695,77737.57124758688,77691.3943050193,77645.23654681467,77599.10056708494,77552.99348455599,77506.90371621621,77460.84224179537,77414.79446187259,77368.77364864865,77322.78137065638,77276.81274131274,77230.85551399614,77184.92247828185,77139.01634893822,77093.13272200772,77047.27045125482,77001.4379222973,76955.62886100386,76909.84242277993,76864.07969353283,76818.33542471043,76772.62276785714,76726.92284025096,76681.25820463321,76635.61341698842,76589.99402750966,76544.39309845559,76498.81925675676,76453.26948600386,76407.7442084942,76362.23962355213,76316.75971283784,76271.30109797297,76225.8585907336,76180.43816361004,76135.03112934362,76089.6443050193,76044.28686052124,75998.95511583012,75953.64991554055,75908.37397442084,75863.12427606178,75817.89171090734,75772.68822393822,75727.51224662163,75682.35008445945,75637.21597490348,75592.1032215251,75547.00796332046,75501.93532818533,75456.89665781854,75411.8786800193,75366.88338561777,75321.9198238417,75276.970378861,75232.05164092664,75187.16385135135,75142.29422055985,75097.43743967182,75052.61341698842,75007.80978523166,74963.02799227799,74918.25536920849,74873.51574565638,74828.80423503861,74784.11697635135,74739.45415057916,74694.81636100386,74650.1911800193,74605.59562017374,74561.01254826254,74516.4638030888,74471.94576496139,74427.43864623552,74382.95873552124,74338.50796332046,74294.07408301158,74249.66698841698,74205.28661920849,74160.92694256757,74116.59284507722,74072.27992277993,74027.99076978765,73983.7179657336,73939.47442084942,73895.25054295367,73851.05121862935,73806.88471283784,73762.73576254827,73718.60877171815,73674.50211148648,73630.43026061777,73586.37524131274,73542.34755067568,73498.35261824324,73454.36299469112,73410.40220801158,73366.46157094595,73322.54361727799,73278.66089527027,73234.80236486487,73190.96374276062,73147.16173986487,73103.36890685328,73059.60961631274,73015.86944980695,72972.15106177607,72928.44787644787,72884.77847490348,72841.1344715251,72797.50585183398,72753.90534507722,72710.33669160232,72666.77702702703,72623.25265444015,72579.74812982626,72536.27660472973,72492.82679777993,72449.39629584942,72405.98503861004,72362.60189430501,72319.23751206564,72275.89092664093,72232.57263513513,72189.28758445945,72146.01236727799,72102.76345318533,72059.53468870657,72016.33451978765,71973.16101592664,71930.0065757722,71886.87282818533,71843.77020994209,71800.68629343629,71757.63254102317,71714.60780646717,71671.59393098456,71628.61999276062,71585.67181467182,71542.74414816602,71499.83928571429,71456.951496139,71414.0950168919,71371.25235279923,71328.43201013513,71285.64074565638,71242.8742157336,71200.12228523166,71157.3984073359,71114.70203909266,71072.02853523166,71029.38410955599,70986.75748069499,70944.15812017374,70901.58783783784,70859.03118967182,70816.50066361004,70773.99064913127,70731.49885376448,70689.03384411197,70646.59338803089,70604.19154198842,70561.80483832046,70519.43629343629,70477.09266409266,70434.76948600386,70392.47122345559,70350.1916023166,70307.93677606178,70265.70318532818,70223.50802364865,70181.33451978765,70139.18478523166,70097.06756756757,70054.97641167954,70012.90124276062,69970.84706805019,69928.82341940154,69886.81038851352,69844.82842664093,69802.87433638996,69760.93490588803,69719.0164092664,69677.13441119691,69635.27799227799,69593.44298986487,69551.623371139,69509.84368967182,69468.07450530888,69426.33994932432,69384.6192688224,69342.92736486487,69301.26206563707,69259.62264720077,69218.00138754827,69176.40558638996,69134.8371742278,69093.29367760618,69051.77606177607,69010.2833011583,68968.80206322393,68927.35430743243,68885.92790781854,68844.51490106178,68803.13459218146,68761.78637789575,68720.45421090734,68679.15401785714,68637.87928330115,68596.62572393822,68555.39400337837,68514.1932311776,68473.01465974904,68431.85563465251,68390.72351592664,68349.61359797297,68308.53191361004,68267.46651785714,68226.42863175676,68185.40968870657,68144.42320222007,68103.45276303089,68062.50729971043,68021.59610279923,67980.69908301158,67939.82631515444,67898.97586872587,67858.15401785714,67817.34966216216,67776.56515444015,67735.81509411197,67695.09031129343,67654.3947273166,67613.72617036679,67573.06690395753,67532.44974662163,67491.84429295367,67451.26405646717,67410.72979005791,67370.20608108108,67329.69932432432,67289.2195945946,67248.77443291506,67208.34893822393,67167.9473334942,67127.57601351352,67087.22230936293,67046.90196669885,67006.60285955599,66966.32577220077,66926.07474662163,66885.83548503861,66845.63368725868,66805.44600627413,66765.2948238417,66725.16439430501,66685.05501930501,66644.97411920849,66604.9034145753,66564.86589044401,66524.84079391892,66484.83994932432,66444.86848455599,66404.92181467182,66364.9942084942,66325.09320704633,66285.22345559846,66245.37590492278,66205.55109797297,66165.75995415058,66125.98093629343,66086.23316843629,66046.51665057916,66006.82076496139,65967.14098696911,65927.49595801158,65887.89520994209,65848.3125,65808.74933638996,65769.21573359074,65729.69673021235]}},\"id\":\"2438f108-1f03-4af3-9d67-b21fca67fb46\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"83fc9330-4363-4ebe-9ac1-9c57b10cabad\",\"type\":\"PanTool\"},{\"id\":\"ebdff63a-b289-43af-bb08-3c2216e11507\",\"type\":\"WheelZoomTool\"},{\"id\":\"899ed59b-29b4-438c-a11b-0983ac43c2fe\",\"type\":\"BoxZoomTool\"},{\"id\":\"a0915a30-1a97-4038-9764-5f5dacfd8f93\",\"type\":\"SaveTool\"},{\"id\":\"dbd704ed-1a63-4643-9023-a72a7433c4b4\",\"type\":\"ResetTool\"},{\"id\":\"d8c677ad-b725-401e-b04b-066938ad61da\",\"type\":\"HelpTool\"}]},\"id\":\"5a0c46ac-3440-443c-8c16-603296cbdea2\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null},\"id\":\"efcf03d2-841a-44cb-b788-6209d3fc85c9\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"f2f5227e-f4ba-4eb0-bae6-b6618cde81c5\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null},\"id\":\"c53f7c7b-b558-40ed-bad1-e5453a2e3156\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"3eccc43c-2a7c-4900-a806-f297579d6ea1\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"11410c9b-2888-4423-93cb-0b93e7ec3da1\",\"type\":\"LinearScale\"},{\"attributes\":{\"plot\":{\"id\":\"1fabf660-d6e0-4b43-8981-eb79113c59b3\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"9316cf81-94c8-440a-892e-b4ef9140e93a\",\"type\":\"BasicTicker\"}},\"id\":\"a01a5196-c5a0-4925-b2d8-2d350bb4fcbb\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"db6e52e2-3aad-4243-8fc9-0adac1477824\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1fabf660-d6e0-4b43-8981-eb79113c59b3\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"9316cf81-94c8-440a-892e-b4ef9140e93a\",\"type\":\"BasicTicker\"}},\"id\":\"0ccc61d9-1bbb-4c2f-9af1-521055da86c2\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"9316cf81-94c8-440a-892e-b4ef9140e93a\",\"type\":\"BasicTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"688a17e9-a9ef-4694-b482-03ba4ef3e8ac\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1fabf660-d6e0-4b43-8981-eb79113c59b3\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"f2f5227e-f4ba-4eb0-bae6-b6618cde81c5\",\"type\":\"BasicTicker\"}},\"id\":\"bfb4a1b1-c8a6-46d6-9987-4b5763109c9a\",\"type\":\"LinearAxis\"}],\"root_ids\":[\"1fabf660-d6e0-4b43-8981-eb79113c59b3\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.14\"}};\n",
       "  var render_items = [{\"docid\":\"a2a382e3-7430-4f8c-b29b-2a73e49e69f7\",\"elementid\":\"1754392e-78aa-4b31-97c7-3ff8a63ddc3d\",\"modelid\":\"1fabf660-d6e0-4b43-8981-eb79113c59b3\"}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1fabf660-d6e0-4b43-8981-eb79113c59b3"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = figure(plot_width=500, plot_height=250)\n",
    "x = np.linspace(1,len(res.history['loss']),len(res.history['loss']))\n",
    "p.line(x, res.history['loss'], color='blue')\n",
    "p.line(x, res.history['val_loss'], color='red')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(test_x)\n",
    "yhat = yhat.reshape(yhat.shape[0])\n",
    "y = test_y.reshape(test_y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"b505fe34-7683-4961-8385-c2600534e7fe\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"c08eb008-6f39-4176-99c1-212d804d8018\":{\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"31593688-854c-4379-9492-e27bcaec5314\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"9ad41159-6d2f-48af-8f3f-61fb8308a418\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"408fa69e-3a7b-4763-b4c3-640e2d5fed80\",\"type\":\"SaveTool\"},{\"attributes\":{\"overlay\":{\"id\":\"52957bd0-6615-44ec-98cf-4181b8059bb7\",\"type\":\"BoxAnnotation\"}},\"id\":\"455f9edc-50ca-4c61-8a9e-c709e4dfcae6\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"fff0519b-5657-49b0-820e-f58daed4d57e\",\"type\":\"Title\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":{\"__ndarray__\":\"AAAAAAAA8D8AAAAAAAAAQAAAAAAAAAhAAAAAAAAAEEAAAAAAAAAUQAAAAAAAABhAAAAAAAAAHEAAAAAAAAAgQAAAAAAAACJAAAAAAAAAJEAAAAAAAAAmQAAAAAAAAChAAAAAAAAAKkAAAAAAAAAsQAAAAAAAAC5AAAAAAAAAMEAAAAAAAAAxQAAAAAAAADJAAAAAAAAAM0AAAAAAAAA0QAAAAAAAADVAAAAAAAAANkAAAAAAAAA3QAAAAAAAADhAAAAAAAAAOUAAAAAAAAA6QAAAAAAAADtAAAAAAAAAPEAAAAAAAAA9QAAAAAAAAD5AAAAAAAAAP0AAAAAAAABAQAAAAAAAgEBAAAAAAAAAQUAAAAAAAIBBQAAAAAAAAEJAAAAAAACAQkAAAAAAAABDQAAAAAAAgENAAAAAAAAAREAAAAAAAIBEQAAAAAAAAEVAAAAAAACARUAAAAAAAABGQAAAAAAAgEZAAAAAAAAAR0AAAAAAAIBHQAAAAAAAAEhAAAAAAACASEAAAAAAAABJQAAAAAAAgElAAAAAAAAASkAAAAAAAIBKQAAAAAAAAEtAAAAAAACAS0AAAAAAAABMQAAAAAAAgExAAAAAAAAATUAAAAAAAIBNQAAAAAAAAE5AAAAAAACATkAAAAAAAABPQAAAAAAAgE9AAAAAAAAAUEAAAAAAAEBQQAAAAAAAgFBAAAAAAADAUEAAAAAAAABRQAAAAAAAQFFAAAAAAACAUUAAAAAAAMBRQAAAAAAAAFJAAAAAAABAUkAAAAAAAIBSQAAAAAAAwFJAAAAAAAAAU0AAAAAAAEBTQAAAAAAAgFNAAAAAAADAU0AAAAAAAABUQAAAAAAAQFRAAAAAAACAVEAAAAAAAMBUQAAAAAAAAFVAAAAAAABAVUAAAAAAAIBVQAAAAAAAwFVAAAAAAAAAVkAAAAAAAEBWQAAAAAAAgFZAAAAAAADAVkAAAAAAAABXQAAAAAAAQFdAAAAAAACAV0AAAAAAAMBXQAAAAAAAAFhAAAAAAABAWEAAAAAAAIBYQAAAAAAAwFhAAAAAAAAAWUAAAAAAAEBZQAAAAAAAgFlAAAAAAADAWUAAAAAAAABaQAAAAAAAQFpAAAAAAACAWkAAAAAAAMBaQAAAAAAAAFtAAAAAAABAW0AAAAAAAIBbQAAAAAAAwFtAAAAAAAAAXEAAAAAAAEBcQAAAAAAAgFxAAAAAAADAXEAAAAAAAABdQAAAAAAAQF1AAAAAAACAXUAAAAAAAMBdQAAAAAAAAF5AAAAAAABAXkAAAAAAAIBeQAAAAAAAwF5AAAAAAAAAX0AAAAAAAEBfQAAAAAAAgF9AAAAAAADAX0AAAAAAAABgQAAAAAAAIGBAAAAAAABAYEAAAAAAAGBgQAAAAAAAgGBAAAAAAACgYEAAAAAAAMBgQAAAAAAA4GBAAAAAAAAAYUAAAAAAACBhQAAAAAAAQGFAAAAAAABgYUAAAAAAAIBhQAAAAAAAoGFAAAAAAADAYUAAAAAAAOBhQAAAAAAAAGJAAAAAAAAgYkAAAAAAAEBiQAAAAAAAYGJAAAAAAACAYkAAAAAAAKBiQAAAAAAAwGJAAAAAAADgYkAAAAAAAABjQAAAAAAAIGNAAAAAAABAY0AAAAAAAGBjQAAAAAAAgGNAAAAAAACgY0AAAAAAAMBjQAAAAAAA4GNAAAAAAAAAZEAAAAAAACBkQAAAAAAAQGRAAAAAAABgZEAAAAAAAIBkQAAAAAAAoGRAAAAAAADAZEAAAAAAAOBkQAAAAAAAAGVAAAAAAAAgZUAAAAAAAEBlQAAAAAAAYGVAAAAAAACAZUAAAAAAAKBlQAAAAAAAwGVAAAAAAADgZUAAAAAAAABmQAAAAAAAIGZAAAAAAABAZkAAAAAAAGBmQAAAAAAAgGZAAAAAAACgZkAAAAAAAMBmQAAAAAAA4GZAAAAAAAAAZ0AAAAAAACBnQAAAAAAAQGdAAAAAAABgZ0AAAAAAAIBnQAAAAAAAoGdAAAAAAADAZ0AAAAAAAOBnQAAAAAAAAGhAAAAAAAAgaEAAAAAAAEBoQAAAAAAAYGhAAAAAAACAaEAAAAAAAKBoQAAAAAAAwGhAAAAAAADgaEAAAAAAAABpQAAAAAAAIGlAAAAAAABAaUAAAAAAAGBpQAAAAAAAgGlAAAAAAACgaUAAAAAAAMBpQAAAAAAA4GlAAAAAAAAAakAAAAAAACBqQAAAAAAAQGpAAAAAAABgakAAAAAAAIBqQAAAAAAAoGpAAAAAAADAakAAAAAAAOBqQAAAAAAAAGtAAAAAAAAga0AAAAAAAEBrQAAAAAAAYGtAAAAAAACAa0AAAAAAAKBrQAAAAAAAwGtAAAAAAADga0AAAAAAAABsQAAAAAAAIGxAAAAAAABAbEAAAAAAAGBsQAAAAAAAgGxAAAAAAACgbEAAAAAAAMBsQAAAAAAA4GxAAAAAAAAAbUAAAAAAACBtQAAAAAAAQG1AAAAAAABgbUAAAAAAAIBtQAAAAAAAoG1AAAAAAADAbUAAAAAAAOBtQAAAAAAAAG5AAAAAAAAgbkAAAAAAAEBuQAAAAAAAYG5AAAAAAACAbkAAAAAAAKBuQAAAAAAAwG5AAAAAAADgbkAAAAAAAABvQAAAAAAAIG9AAAAAAABAb0AAAAAAAGBvQAAAAAAAgG9AAAAAAACgb0AAAAAAAMBvQAAAAAAA4G9AAAAAAAAAcEAAAAAAABBwQAAAAAAAIHBAAAAAAAAwcEA=\",\"dtype\":\"float64\",\"shape\":[259]},\"y\":{\"__ndarray__\":\"WShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXEOMbllDJ4xXQ9AKUkMVA1VD4Z5PQ+GeT0Phnk9D4Z5PQ+CeT0Phnk9D4Z5PQ+9VUUOLlVBDlLdQQ5nHVEPEXVRD90tVQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDb4BbQ1koXENZKFxDWShcQ1koXENZKFxD6a5VQ1fzV0O4E1dDQYRXQ/H0UkPhnk9DK55PQw+eT0Phnk9D4Z5PQ+GeT0Phnk9D4Z5PQ+GeT0Phnk9D4Z5PQ+GeT0OxFlFD4Z5PQ+GeT0Phnk9DqbZRQx5JUkPBSlJDHn5RQ1DPVEOtUVtDTTxbQ0nOW0PDB1hDPppXQ7eJU0MzNFRDLPJSQx9+U0NpFFFDdgRRQ6vXU0Phnk9D4Z5PQ+GeT0Phnk9D4Z5PQ+GeT0Phnk9DiSVSQ0qRVUP3UFlDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxDWShcQ1koXENZKFxD4Z5PQ+GeT0Phnk9D4Z5PQ+GeT0Phnk9D4J5PQ+GeT0Phnk9D4Z5PQ9ieT0N/nk9D3Z5PQ9+eT0PLnk9D055PQ9+eT0PLl09Dx8MnQxeCTUOM8CZDoCY3Q2TsIEOxVyJD1jcnQ1ZLL0MtaE1DWpdPQ8qXT0P0b09DSFxPQy2NT0MnVE9DcJ5PQ8KeT0O9nk9DsZ5PQ4+eT0PEnk9DcpxPQ+obT0NlMihDfBhPQx0dT0OrmE9DOJNPQ05gT0OvTDRDqcElQ/CSI0N+fttCjB2aQqjYqUJeBQlDzHAVQwa4I0OYdhxDJCGBQiRjgUIrnYBCl46AQpCOgEI+jIBCBoaAQlKQgELuJYBC7iWAQu4lgELuJYBC7iWAQu4lgELuJYBC7iWAQu4lgELuJYBC7iWAQu4lgELuJYBC7iWAQu4lgELuJYBC7iWAQg==\",\"dtype\":\"float32\",\"shape\":[259]}}},\"id\":\"c2669d62-9c4e-49f6-aa17-61f5395f225b\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"data_source\":{\"id\":\"35ac0022-d2c5-4e66-a07f-c3038f668bc4\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"e5c1da4c-bf63-49b0-9f34-71da5aa1ad7d\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"eedc1258-ca9b-4438-8e10-d4d664dac8d3\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"c9c20a16-a419-440a-b04f-d0b7d9b4e078\",\"type\":\"CDSView\"}},\"id\":\"ac5651cf-b454-46bc-b45a-71be9bcd61f9\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_color\":\"red\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"e5c1da4c-bf63-49b0-9f34-71da5aa1ad7d\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"eedc1258-ca9b-4438-8e10-d4d664dac8d3\",\"type\":\"Line\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\"],\"data\":{\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[259]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[259]}}},\"id\":\"35ac0022-d2c5-4e66-a07f-c3038f668bc4\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"source\":{\"id\":\"35ac0022-d2c5-4e66-a07f-c3038f668bc4\",\"type\":\"ColumnDataSource\"}},\"id\":\"c9c20a16-a419-440a-b04f-d0b7d9b4e078\",\"type\":\"CDSView\"},{\"attributes\":{\"below\":[{\"id\":\"3f5ca6e4-70e8-41b0-96f3-59b8ed586f63\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"fff399fc-ff21-4057-a0c0-6e218f107ecd\",\"type\":\"LinearAxis\"}],\"plot_height\":250,\"plot_width\":500,\"renderers\":[{\"id\":\"3f5ca6e4-70e8-41b0-96f3-59b8ed586f63\",\"type\":\"LinearAxis\"},{\"id\":\"d814f9f7-ba7a-4bb5-9584-bf387326c7d5\",\"type\":\"Grid\"},{\"id\":\"fff399fc-ff21-4057-a0c0-6e218f107ecd\",\"type\":\"LinearAxis\"},{\"id\":\"8463349b-b67d-4cbc-950b-5a07a603a9ca\",\"type\":\"Grid\"},{\"id\":\"52957bd0-6615-44ec-98cf-4181b8059bb7\",\"type\":\"BoxAnnotation\"},{\"id\":\"3ec7db8a-2523-4aa1-bd8f-9394b8ff515b\",\"type\":\"GlyphRenderer\"},{\"id\":\"ac5651cf-b454-46bc-b45a-71be9bcd61f9\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"fff0519b-5657-49b0-820e-f58daed4d57e\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"c7e21fa5-1c0c-44ea-bea3-295deffecba8\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"abcc9b74-a9c5-4a19-ae59-d2f20f0b701a\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"aeb507b4-c27d-4cdd-88a7-65c0cfe68977\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"95dcb3f4-6b06-47ce-adc2-2a4f55e14bf3\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"c9187c54-24c1-4ec1-ad82-40a65ea3c8fc\",\"type\":\"LinearScale\"}},\"id\":\"3a8f77c0-1d61-4bc4-a12a-15247467aba4\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"0cfcda50-3dad-4f02-9ae2-97b3305080f7\",\"type\":\"PanTool\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"8c13dcdc-afa5-444c-b106-8673d2ef1d68\",\"type\":\"Line\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"0cfcda50-3dad-4f02-9ae2-97b3305080f7\",\"type\":\"PanTool\"},{\"id\":\"1c9de602-17f0-459c-8e5a-c590a04b2db4\",\"type\":\"WheelZoomTool\"},{\"id\":\"455f9edc-50ca-4c61-8a9e-c709e4dfcae6\",\"type\":\"BoxZoomTool\"},{\"id\":\"408fa69e-3a7b-4763-b4c3-640e2d5fed80\",\"type\":\"SaveTool\"},{\"id\":\"9ad41159-6d2f-48af-8f3f-61fb8308a418\",\"type\":\"ResetTool\"},{\"id\":\"31593688-854c-4379-9492-e27bcaec5314\",\"type\":\"HelpTool\"}]},\"id\":\"c7e21fa5-1c0c-44ea-bea3-295deffecba8\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null},\"id\":\"abcc9b74-a9c5-4a19-ae59-d2f20f0b701a\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null},\"id\":\"95dcb3f4-6b06-47ce-adc2-2a4f55e14bf3\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"2a88196a-ac1f-44ae-b2cf-b3cccf646249\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"3a8f77c0-1d61-4bc4-a12a-15247467aba4\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"2a88196a-ac1f-44ae-b2cf-b3cccf646249\",\"type\":\"BasicTicker\"}},\"id\":\"d814f9f7-ba7a-4bb5-9584-bf387326c7d5\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"aeb507b4-c27d-4cdd-88a7-65c0cfe68977\",\"type\":\"LinearScale\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"3a8f77c0-1d61-4bc4-a12a-15247467aba4\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"911e7e24-7eb0-4633-90e9-6720403963b8\",\"type\":\"BasicTicker\"}},\"id\":\"8463349b-b67d-4cbc-950b-5a07a603a9ca\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"55ea38a7-6ce9-4671-acbb-fdb01164c832\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"3a8f77c0-1d61-4bc4-a12a-15247467aba4\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"2a88196a-ac1f-44ae-b2cf-b3cccf646249\",\"type\":\"BasicTicker\"}},\"id\":\"3f5ca6e4-70e8-41b0-96f3-59b8ed586f63\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"55ea38a7-6ce9-4671-acbb-fdb01164c832\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"911e7e24-7eb0-4633-90e9-6720403963b8\",\"type\":\"BasicTicker\"},{\"attributes\":{\"source\":{\"id\":\"c2669d62-9c4e-49f6-aa17-61f5395f225b\",\"type\":\"ColumnDataSource\"}},\"id\":\"31d506b4-2e27-4e3e-a6cb-c17876996417\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"c2669d62-9c4e-49f6-aa17-61f5395f225b\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"7121b4f6-5371-4aaf-a2b3-8ce4d57038c9\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"8c13dcdc-afa5-444c-b106-8673d2ef1d68\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"31d506b4-2e27-4e3e-a6cb-c17876996417\",\"type\":\"CDSView\"}},\"id\":\"3ec7db8a-2523-4aa1-bd8f-9394b8ff515b\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"formatter\":{\"id\":\"59aedd81-5fda-4095-8448-8399723d955a\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"3a8f77c0-1d61-4bc4-a12a-15247467aba4\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"911e7e24-7eb0-4633-90e9-6720403963b8\",\"type\":\"BasicTicker\"}},\"id\":\"fff399fc-ff21-4057-a0c0-6e218f107ecd\",\"type\":\"LinearAxis\"},{\"attributes\":{\"line_color\":\"blue\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"7121b4f6-5371-4aaf-a2b3-8ce4d57038c9\",\"type\":\"Line\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"52957bd0-6615-44ec-98cf-4181b8059bb7\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"c9187c54-24c1-4ec1-ad82-40a65ea3c8fc\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1c9de602-17f0-459c-8e5a-c590a04b2db4\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"59aedd81-5fda-4095-8448-8399723d955a\",\"type\":\"BasicTickFormatter\"}],\"root_ids\":[\"3a8f77c0-1d61-4bc4-a12a-15247467aba4\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.14\"}};\n",
       "  var render_items = [{\"docid\":\"c08eb008-6f39-4176-99c1-212d804d8018\",\"elementid\":\"b505fe34-7683-4961-8385-c2600534e7fe\",\"modelid\":\"3a8f77c0-1d61-4bc4-a12a-15247467aba4\"}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "3a8f77c0-1d61-4bc4-a12a-15247467aba4"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = figure(plot_width=500, plot_height=250)\n",
    "x = np.linspace(1,test_y.shape[0],test_y.shape[0])\n",
    "p.line(x, yhat, color='blue')\n",
    "p.line(x, y, color='red')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So it fails epically with a lookback of 1 timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
